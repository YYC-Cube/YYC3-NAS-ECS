# LLM Service Environment Variables
NODE_ENV=production
PORT=3002
SERVICE_NAME=llm.0379.email

# AI Service Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_BASE_URL=https://api.openai.com/v1
MODEL_NAME=gpt-4
MAX_TOKENS=4000
TEMPERATURE=0.7

# Rate Limiting
LLM_RATE_LIMIT=50
REQUEST_TIMEOUT=60000

# Cache
REDIS_URL=redis://localhost:6379/2
CACHE_TTL=3600

# Logging
LOG_LEVEL=info
LOG_FILE=/www/app/llm/logs/app.log