# YYCÂ³ NAS-ECS LLMæœåŠ¡ä½¿ç”¨ç¤ºä¾‹

**åˆ›å»ºæ—¥æœŸ**: 2026-01-25  
**ä½œè€…**: YYCÂ³ Team  
**ç‰ˆæœ¬**: 1.0.0

---

## ğŸ“‹ ç›®å½•

1. [å¿«é€Ÿå…¥é—¨](#å¿«é€Ÿå…¥é—¨)
2. [åŸºç¡€ä½¿ç”¨ç¤ºä¾‹](#åŸºç¡€ä½¿ç”¨ç¤ºä¾‹)
3. [é«˜çº§ä½¿ç”¨ç¤ºä¾‹](#é«˜çº§ä½¿ç”¨ç¤ºä¾‹)
4. [APIä½¿ç”¨ç¤ºä¾‹](#apiä½¿ç”¨ç¤ºä¾‹)
5. [æç¤ºè¯æ¨¡æ¿ç¤ºä¾‹](#æç¤ºè¯æ¨¡æ¿ç¤ºä¾‹)
6. [å¤šæ¨¡æ€æ”¯æŒç¤ºä¾‹](#å¤šæ¨¡æ€æ”¯æŒç¤ºä¾‹)
7. [æ•…éšœæ’æŸ¥ç¤ºä¾‹](#æ•…éšœæ’æŸ¥ç¤ºä¾‹)
8. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## å¿«é€Ÿå…¥é—¨

### 1. è®¿é—®LLMæœåŠ¡

**æ­¥éª¤**:
1. ç™»å½•YYCÂ³ NAS-ECSç³»ç»Ÿ
2. ç‚¹å‡»å·¦ä¾§å¯¼èˆªæ çš„"AIæœåŠ¡" > "LLMå¯¹è¯"
3. è¿›å…¥AIæ™ºèƒ½åŠ©æ‰‹ç•Œé¢

**ç•Œé¢è¯´æ˜**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AIæ™ºèƒ½åŠ©æ‰‹              [æ–°å¯¹è¯] [è®¾ç½®] [æ¨¡å‹]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å¯¹è¯å†å²                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ğŸ’¬ ç³»ç»Ÿä¼˜åŒ–å»ºè®®                   â”‚   â”‚
â”‚  â”‚ æ—¶é—´: 2026-01-25 10:30          â”‚   â”‚
â”‚  â”‚ é¢„è§ˆ: å»ºè®®ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢...       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ğŸ’¬ ä»£ç ç”Ÿæˆ                       â”‚   â”‚
â”‚  â”‚ æ—¶é—´: 2026-01-25 09:15          â”‚   â”‚
â”‚  â”‚ é¢„è§ˆ: ç”Ÿæˆæ–‡ä»¶ä¸Šä¼ åŠŸèƒ½çš„ä»£ç ...     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å½“å‰å¯¹è¯                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ç”¨æˆ·: å¸®æˆ‘ä¼˜åŒ–ä¸€ä¸‹NASç³»ç»Ÿæ€§èƒ½      â”‚   â”‚
â”‚  â”‚ AI: æˆ‘æ¥å¸®æ‚¨åˆ†æNASç³»ç»Ÿæ€§èƒ½...     â”‚   â”‚
â”‚  â”‚ ç”¨æˆ·: å…·ä½“åº”è¯¥æ€ä¹ˆåšï¼Ÿ              â”‚   â”‚
â”‚  â”‚ AI: ä»¥ä¸‹æ˜¯å…·ä½“çš„ä¼˜åŒ–å»ºè®®...         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [è¾“å…¥æ¶ˆæ¯...]                     [å‘é€]    â”‚
â”‚  [ğŸ“ é™„ä»¶] [ğŸ¤ è¯­éŸ³] [ğŸ“‹ æ¨¡æ¿]           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. é€‰æ‹©æ¨¡å‹

**å¯ç”¨æ¨¡å‹**:
- **qwen:7b** - è½»é‡çº§æ¨¡å‹ï¼Œé€‚åˆå¿«é€Ÿå“åº”
- **qwen:14b** - ä¸­ç­‰è§„æ¨¡æ¨¡å‹ï¼Œå¹³è¡¡æ€§èƒ½å’Œè´¨é‡
- **qwen:72b** - å¤§è§„æ¨¡æ¨¡å‹ï¼Œé€‚åˆå¤æ‚ä»»åŠ¡
- **llama3:8b** - è½»é‡çº§æ¨¡å‹ï¼Œé€šç”¨æ€§å¼º
- **llama3:70b** - å¤§è§„æ¨¡æ¨¡å‹ï¼Œé«˜è´¨é‡è¾“å‡º

**é€‰æ‹©å»ºè®®**:
- ç®€å•é—®ç­”: qwen:7b æˆ– llama3:8b
- ä»£ç ç”Ÿæˆ: qwen:14b
- æ–‡æ¡£åˆ†æ: qwen:72b æˆ– llama3:70b
- å®æ—¶å¯¹è¯: qwen:7b

### 3. å‘é€æ¶ˆæ¯

**æ­¥éª¤**:
1. åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥æ¶ˆæ¯
2. é€‰æ‹©æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
3. ç‚¹å‡»"å‘é€"æŒ‰é’®
4. ç­‰å¾…AIå“åº”

**æ¶ˆæ¯æ ¼å¼**:
```
ç”¨æˆ·: å¸®æˆ‘åˆ†æä¸€ä¸‹NASç³»ç»Ÿçš„æ€§èƒ½
AI: æˆ‘æ¥å¸®æ‚¨åˆ†æNASç³»ç»Ÿçš„æ€§èƒ½çŠ¶å†µã€‚è®©æˆ‘æŸ¥çœ‹ä¸€ä¸‹å½“å‰çš„ç›‘æ§æ•°æ®...

æ ¹æ®ç›‘æ§æ•°æ®ï¼Œæˆ‘å‘ç°ä»¥ä¸‹æƒ…å†µï¼š
1. CPUä½¿ç”¨ç‡å¹³å‡ä¸º45%ï¼Œå¤„äºæ­£å¸¸èŒƒå›´
2. å†…å­˜ä½¿ç”¨ç‡ä¸º62%ï¼Œå»ºè®®ä¼˜åŒ–å†…å­˜ä½¿ç”¨
3. ç£ç›˜I/Oè¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢

ä¼˜åŒ–å»ºè®®ï¼š
- å¯ç”¨æ•°æ®åº“æŸ¥è¯¢ç¼“å­˜
- ä¼˜åŒ–å¤§æ–‡ä»¶ä¼ è¾“æœºåˆ¶
- å¢åŠ å†…å­˜å®¹é‡æˆ–ä¼˜åŒ–å†…å­˜ä½¿ç”¨

éœ€è¦æˆ‘è¯¦ç»†è¯´æ˜æŸä¸ªä¼˜åŒ–æ–¹æ¡ˆå—ï¼Ÿ
```

### 4. æŸ¥çœ‹å¯¹è¯å†å²

**æ­¥éª¤**:
1. ç‚¹å‡»"å†å²"æŒ‰é’®
2. é€‰æ‹©è¦æŸ¥çœ‹çš„å¯¹è¯
3. æŸ¥çœ‹å®Œæ•´å¯¹è¯å†…å®¹
4. å¯ä»¥ç»§ç»­å¯¹è¯æˆ–å¯¼å‡ºå¯¹è¯

---

## åŸºç¡€ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: å‘é€ç®€å•æ¶ˆæ¯

```typescript
// å‘é€ç®€å•æ¶ˆæ¯
const sendMessage = async (message: string, model?: string) => {
  try {
    const response = await fetch('/api/v2/llm/chat', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${token}`,
      },
      body: JSON.stringify({
        model: model || 'qwen:7b',
        messages: [
          {
            role: 'user',
            content: message,
          },
        ],
        stream: false,
      }),
    });

    const data = await response.json();

    if (data.success) {
      console.log('AIå“åº”:', data.data);
      return data.data;
    }
  } catch (error) {
    console.error('å‘é€æ¶ˆæ¯å¤±è´¥:', error);
  }
};

// ä½¿ç”¨ç¤ºä¾‹
const response = await sendMessage('å¸®æˆ‘åˆ†æä¸€ä¸‹NASç³»ç»Ÿçš„æ€§èƒ½');
console.log('AIå“åº”:', response.message);
```

**è¯·æ±‚ç¤ºä¾‹**:
```json
{
  "model": "qwen:7b",
  "messages": [
    {
      "role": "user",
      "content": "å¸®æˆ‘åˆ†æä¸€ä¸‹NASç³»ç»Ÿçš„æ€§èƒ½"
    }
  ],
  "stream": false
}
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": {
    "message": "æˆ‘æ¥å¸®æ‚¨åˆ†æNASç³»ç»Ÿçš„æ€§èƒ½çŠ¶å†µã€‚è®©æˆ‘æŸ¥çœ‹ä¸€ä¸‹å½“å‰çš„ç›‘æ§æ•°æ®...\n\næ ¹æ®ç›‘æ§æ•°æ®ï¼Œæˆ‘å‘ç°ä»¥ä¸‹æƒ…å†µï¼š\n1. CPUä½¿ç”¨ç‡å¹³å‡ä¸º45%ï¼Œå¤„äºæ­£å¸¸èŒƒå›´\n2. å†…å­˜ä½¿ç”¨ç‡ä¸º62%ï¼Œå»ºè®®ä¼˜åŒ–å†…å­˜ä½¿ç”¨\n3. ç£ç›˜I/Oè¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢\n\nä¼˜åŒ–å»ºè®®ï¼š\n- å¯ç”¨æ•°æ®åº“æŸ¥è¯¢ç¼“å­˜\n- ä¼˜åŒ–å¤§æ–‡ä»¶ä¼ è¾“æœºåˆ¶\n- å¢åŠ å†…å­˜å®¹é‡æˆ–ä¼˜åŒ–å†…å­˜ä½¿ç”¨\n\néœ€è¦æˆ‘è¯¦ç»†è¯´æ˜æŸä¸ªä¼˜åŒ–æ–¹æ¡ˆå—ï¼Ÿ",
    "model": "qwen:7b",
    "tokens": 256,
    "finishReason": "stop"
  }
}
```

### ç¤ºä¾‹2: å¤šè½®å¯¹è¯

```typescript
// å¤šè½®å¯¹è¯
const multiTurnChat = async () => {
  const messages: Message[] = [];

  // ç¬¬ä¸€è½®
  const response1 = await sendMessageWithHistory(messages, 'å¸®æˆ‘åˆ†æä¸€ä¸‹NASç³»ç»Ÿçš„æ€§èƒ½');
  messages.push({ role: 'user', content: 'å¸®æˆ‘åˆ†æä¸€ä¸‹NASç³»ç»Ÿçš„æ€§èƒ½' });
  messages.push({ role: 'assistant', content: response1.message });
  console.log('ç¬¬ä¸€è½®å“åº”:', response1.message);

  // ç¬¬äºŒè½®
  const response2 = await sendMessageWithHistory(messages, 'å…·ä½“åº”è¯¥æ€ä¹ˆåšï¼Ÿ');
  messages.push({ role: 'user', content: 'å…·ä½“åº”è¯¥æ€ä¹ˆåšï¼Ÿ' });
  messages.push({ role: 'assistant', content: response2.message });
  console.log('ç¬¬äºŒè½®å“åº”:', response2.message);

  // ç¬¬ä¸‰è½®
  const response3 = await sendMessageWithHistory(messages, 'è¯·ç»™å‡ºè¯¦ç»†çš„ä»£ç ç¤ºä¾‹');
  messages.push({ role: 'user', content: 'è¯·ç»™å‡ºè¯¦ç»†çš„ä»£ç ç¤ºä¾‹' });
  messages.push({ role: 'assistant', content: response3.message });
  console.log('ç¬¬ä¸‰è½®å“åº”:', response3.message);
};

const sendMessageWithHistory = async (messages: Message[], content: string) => {
  try {
    const response = await fetch('/api/v2/llm/chat', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${token}`,
      },
      body: JSON.stringify({
        model: 'qwen:7b',
        messages: [...messages, { role: 'user', content }],
        stream: false,
      }),
    });

    const data = await response.json();
    return data.data;
  } catch (error) {
    console.error('å‘é€æ¶ˆæ¯å¤±è´¥:', error);
  }
};

multiTurnChat();
```

### ç¤ºä¾‹3: æµå¼å“åº”

```typescript
// æµå¼å“åº”
const streamMessage = async (message: string) => {
  try {
    const response = await fetch('/api/v2/llm/chat', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${token}`,
      },
      body: JSON.stringify({
        model: 'qwen:7b',
        messages: [
          {
            role: 'user',
            content: message,
          },
        ],
        stream: true,
      }),
    });

    const reader = response.body?.getReader();
    const decoder = new TextDecoder();
    let fullResponse = '';

    while (true) {
      const { done, value } = await reader!.read();
      
      if (done) break;

      const chunk = decoder.decode(value);
      const lines = chunk.split('\n');

      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = JSON.parse(line.slice(6));
          if (data.choices && data.choices[0].delta.content) {
            const content = data.choices[0].delta.content;
            fullResponse += content;
            console.log('å®æ—¶è¾“å‡º:', content);
          }
        }
      }
    }

    console.log('å®Œæ•´å“åº”:', fullResponse);
    return fullResponse;
  } catch (error) {
    console.error('æµå¼å“åº”å¤±è´¥:', error);
  }
};

// ä½¿ç”¨ç¤ºä¾‹
streamMessage('å¸®æˆ‘å†™ä¸€ä¸ªPythonè„šæœ¬ï¼Œç”¨äºæ‰¹é‡å¤„ç†æ–‡ä»¶');
```

---

## é«˜çº§ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: ä½¿ç”¨æç¤ºè¯æ¨¡æ¿

```typescript
// ä½¿ç”¨æç¤ºè¯æ¨¡æ¿
const useTemplate = async (templateName: string, variables: Record<string, string>) => {
  try {
    const response = await fetch('/api/v2/llm/template', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${token}`,
      },
      body: JSON.stringify({
        template: templateName,
        variables,
      }),
    });

    const data = await response.json();

    if (data.success) {
      console.log('æ¨¡æ¿å“åº”:', data.data);
      return data.data;
    }
  } catch (error) {
    console.error('ä½¿ç”¨æ¨¡æ¿å¤±è´¥:', error);
  }
};

// ä½¿ç”¨ç¤ºä¾‹ - ä»£ç ç”Ÿæˆæ¨¡æ¿
const codeResponse = await useTemplate('code-generation', {
  language: 'Python',
  function: 'æ–‡ä»¶ä¸Šä¼ ',
  description: 'å®ç°ä¸€ä¸ªæ”¯æŒæ–­ç‚¹ç»­ä¼ çš„æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½',
});

console.log('ç”Ÿæˆçš„ä»£ç :', codeResponse.message);

// ä½¿ç”¨ç¤ºä¾‹ - æ–‡æ¡£åˆ†ææ¨¡æ¿
const docResponse = await useTemplate('document-analysis', {
  document: 'è¿™æ˜¯ä¸€ä»½ç³»ç»Ÿæ¶æ„æ–‡æ¡£...',
  analysisType: 'summary',
});

console.log('æ–‡æ¡£æ‘˜è¦:', docResponse.message);
```

**è¯·æ±‚ç¤ºä¾‹**:
```json
{
  "template": "code-generation",
  "variables": {
    "language": "Python",
    "function": "æ–‡ä»¶ä¸Šä¼ ",
    "description": "å®ç°ä¸€ä¸ªæ”¯æŒæ–­ç‚¹ç»­ä¼ çš„æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½"
  }
}
```

### ç¤ºä¾‹2: è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯

```typescript
// è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯
const chatWithSystemPrompt = async (systemPrompt: string, userMessage: string) => {
  try {
    const response = await fetch('/api/v2/llm/chat', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${token}`,
      },
      body: JSON.stringify({
        model: 'qwen:7b',
        messages: [
          {
            role: 'system',
            content: systemPrompt,
          },
          {
            role: 'user',
            content: userMessage,
          },
        ],
        stream: false,
      }),
    });

    const data = await response.json();
    return data.data;
  } catch (error) {
    console.error('å‘é€æ¶ˆæ¯å¤±è´¥:', error);
  }
};

// ä½¿ç”¨ç¤ºä¾‹ - è®¾ç½®ä¸ºä»£ç ä¸“å®¶
const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„è½¯ä»¶å·¥ç¨‹å¸ˆï¼Œæ“…é•¿ï¼š
- ç¼–å†™é«˜è´¨é‡ã€å¯ç»´æŠ¤çš„ä»£ç 
- ä»£ç å®¡æŸ¥å’Œä¼˜åŒ–å»ºè®®
- è§£å†³æŠ€æœ¯éš¾é¢˜
- æ¶æ„è®¾è®¡å’Œæœ€ä½³å®è·µ

è¯·ç”¨ä¸“ä¸šã€å‡†ç¡®çš„æ–¹å¼å›ç­”é—®é¢˜ï¼Œå¿…è¦æ—¶æä¾›ä»£ç ç¤ºä¾‹ã€‚`;

const response = await chatWithSystemPrompt(
  systemPrompt,
  'å¸®æˆ‘è®¾è®¡ä¸€ä¸ªå¾®æœåŠ¡æ¶æ„'
);

console.log('AIå“åº”:', response.message);
```

### ç¤ºä¾‹3: è°ƒæ•´æ¨¡å‹å‚æ•°

```typescript
// è°ƒæ•´æ¨¡å‹å‚æ•°
const chatWithParameters = async (message: string, parameters: ModelParameters) => {
  try {
    const response = await fetch('/api/v2/llm/chat', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${token}`,
      },
      body: JSON.stringify({
        model: 'qwen:7b',
        messages: [
          {
            role: 'user',
            content: message,
          },
        ],
        temperature: parameters.temperature || 0.7,
        max_tokens: parameters.maxTokens || 2048,
        top_p: parameters.topP || 0.9,
        frequency_penalty: parameters.frequencyPenalty || 0,
        presence_penalty: parameters.presencePenalty || 0,
        stream: false,
      }),
    });

    const data = await response.json();
    return data.data;
  } catch (error) {
    console.error('å‘é€æ¶ˆæ¯å¤±è´¥:', error);
  }
};

// ä½¿ç”¨ç¤ºä¾‹ - åˆ›æ„æ€§å›ç­”
const creativeResponse = await chatWithParameters('å†™ä¸€ä¸ªç§‘å¹»æ•…äº‹', {
  temperature: 0.9,      // æ›´é«˜çš„æ¸©åº¦ï¼Œæ›´éšæœº
  maxTokens: 1024,
  topP: 0.95,
  frequencyPenalty: 0.5,
  presencePenalty: 0.5,
});

console.log('åˆ›æ„å›ç­”:', creativeResponse.message);

// ä½¿ç”¨ç¤ºä¾‹ - ç²¾ç¡®æ€§å›ç­”
const preciseResponse = await chatWithParameters('è®¡ç®— 123 * 456', {
  temperature: 0.1,      // æ›´ä½çš„æ¸©åº¦ï¼Œæ›´ç¡®å®š
  maxTokens: 256,
  topP: 0.5,
  frequencyPenalty: 0,
  presencePenalty: 0,
});

console.log('ç²¾ç¡®å›ç­”:', preciseResponse.message);
```

### ç¤ºä¾‹4: å¯¹è¯å¯¼å‡º

```typescript
// å¯¼å‡ºå¯¹è¯
const exportConversation = async (conversationId: string, format: string) => {
  try {
    const response = await fetch(`/api/v2/llm/conversation/${conversationId}/export`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${token}`,
      },
      body: JSON.stringify({ format }),
    });

    const data = await response.json();

    if (data.success) {
      console.log('å¯¼å‡ºæˆåŠŸ:', data.data);
      return data.data;
    }
  } catch (error) {
    console.error('å¯¼å‡ºå¯¹è¯å¤±è´¥:', error);
  }
};

// ä½¿ç”¨ç¤ºä¾‹ - å¯¼å‡ºä¸ºMarkdown
const markdownExport = await exportConversation('conv-001', 'markdown');
console.log('Markdownå†…å®¹:', markdownExport.content);

// ä½¿ç”¨ç¤ºä¾‹ - å¯¼å‡ºä¸ºJSON
const jsonExport = await exportConversation('conv-001', 'json');
console.log('JSONå†…å®¹:', jsonExport.content);

// ä½¿ç”¨ç¤ºä¾‹ - å¯¼å‡ºä¸ºPDF
const pdfExport = await exportConversation('conv-001', 'pdf');
console.log('PDFä¸‹è½½é“¾æ¥:', pdfExport.downloadUrl);
```

---

## APIä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: JavaScript/TypeScript

```typescript
// åˆ›å»ºLLM APIå®¢æˆ·ç«¯
class LLMAPI {
  private baseUrl: string;
  private token: string;

  constructor(baseUrl: string, token: string) {
    this.baseUrl = baseUrl;
    this.token = token;
  }

  private async request<T>(
    endpoint: string,
    options: RequestInit = {}
  ): Promise<T> {
    const url = `${this.baseUrl}${endpoint}`;
    const response = await fetch(url, {
      ...options,
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.token}`,
        ...options.headers,
      },
    });

    const data = await response.json();
    
    if (!data.success) {
      throw new Error(data.error?.message || 'è¯·æ±‚å¤±è´¥');
    }

    return data.data;
  }

  // å‘é€æ¶ˆæ¯
  async sendMessage(message: string, model?: string): Promise<ChatResponse> {
    return this.request<ChatResponse>('/api/v2/llm/chat', {
      method: 'POST',
      body: JSON.stringify({
        model: model || 'qwen:7b',
        messages: [{ role: 'user', content: message }],
        stream: false,
      }),
    });
  }

  // æµå¼æ¶ˆæ¯
  async streamMessage(
    message: string,
    onChunk: (chunk: string) => void,
    model?: string
  ): Promise<string> {
    const response = await fetch(`${this.baseUrl}/api/v2/llm/chat`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.token}`,
      },
      body: JSON.stringify({
        model: model || 'qwen:7b',
        messages: [{ role: 'user', content: message }],
        stream: true,
      }),
    });

    const reader = response.body?.getReader();
    const decoder = new TextDecoder();
    let fullResponse = '';

    while (true) {
      const { done, value } = await reader!.read();
      
      if (done) break;

      const chunk = decoder.decode(value);
      const lines = chunk.split('\n');

      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = JSON.parse(line.slice(6));
          if (data.choices && data.choices[0].delta.content) {
            const content = data.choices[0].delta.content;
            fullResponse += content;
            onChunk(content);
          }
        }
      }
    }

    return fullResponse;
  }

  // ä½¿ç”¨æ¨¡æ¿
  async useTemplate(
    templateName: string,
    variables: Record<string, string>
  ): Promise<ChatResponse> {
    return this.request<ChatResponse>('/api/v2/llm/template', {
      method: 'POST',
      body: JSON.stringify({ template: templateName, variables }),
    });
  }

  // è·å–å¯¹è¯å†å²
  async getConversationHistory(conversationId: string): Promise<Conversation> {
    return this.request<Conversation>(`/api/v2/llm/conversation/${conversationId}`);
  }

  // å¯¼å‡ºå¯¹è¯
  async exportConversation(
    conversationId: string,
    format: string
  ): Promise<ExportResult> {
    return this.request<ExportResult>(
      `/api/v2/llm/conversation/${conversationId}/export`,
      {
        method: 'POST',
        body: JSON.stringify({ format }),
      }
    );
  }

  // è·å–å¯ç”¨æ¨¡å‹
  async getModels(): Promise<Model[]> {
    return this.request<Model[]>('/api/v2/llm/models');
  }
}

// ä½¿ç”¨ç¤ºä¾‹
const api = new LLMAPI('http://localhost:6000', 'your-token-here');

// å‘é€æ¶ˆæ¯
const response = await api.sendMessage('å¸®æˆ‘åˆ†æä¸€ä¸‹NASç³»ç»Ÿçš„æ€§èƒ½');
console.log('AIå“åº”:', response.message);

// æµå¼æ¶ˆæ¯
await api.streamMessage('å¸®æˆ‘å†™ä¸€ä¸ªPythonè„šæœ¬', (chunk) => {
  console.log('å®æ—¶è¾“å‡º:', chunk);
});

// ä½¿ç”¨æ¨¡æ¿
const templateResponse = await api.useTemplate('code-generation', {
  language: 'Python',
  function: 'æ–‡ä»¶ä¸Šä¼ ',
});
console.log('æ¨¡æ¿å“åº”:', templateResponse.message);

// è·å–å¯¹è¯å†å²
const history = await api.getConversationHistory('conv-001');
console.log('å¯¹è¯å†å²:', history);

// å¯¼å‡ºå¯¹è¯
const exportResult = await api.exportConversation('conv-001', 'markdown');
console.log('å¯¼å‡ºç»“æœ:', exportResult);

// è·å–å¯ç”¨æ¨¡å‹
const models = await api.getModels();
console.log('å¯ç”¨æ¨¡å‹:', models);
```

### ç¤ºä¾‹2: Python

```python
import requests
from typing import Dict, Any, List, Optional, Callable

class LLMAPI:
    def __init__(self, base_url: str, token: str):
        self.base_url = base_url
        self.token = token
        self.headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {token}'
        }

    def _request(self, endpoint: str, method: str = 'GET', data: Dict = None) -> Any:
        url = f'{self.base_url}{endpoint}'
        response = requests.request(
            method,
            url,
            headers=self.headers,
            json=data
        )
        
        result = response.json()
        
        if not result.get('success'):
            raise Exception(result.get('error', {}).get('message', 'è¯·æ±‚å¤±è´¥'))
        
        return result.get('data')

    def send_message(self, message: str, model: str = None) -> Dict:
        """å‘é€æ¶ˆæ¯"""
        return self._request(
            '/api/v2/llm/chat',
            method='POST',
            data={
                'model': model or 'qwen:7b',
                'messages': [{'role': 'user', 'content': message}],
                'stream': False
            }
        )

    def stream_message(self, message: str, on_chunk: Callable, model: str = None) -> str:
        """æµå¼æ¶ˆæ¯"""
        response = requests.post(
            f'{self.base_url}/api/v2/llm/chat',
            headers=self.headers,
            json={
                'model': model or 'qwen:7b',
                'messages': [{'role': 'user', 'content': message}],
                'stream': True
            },
            stream=True
        )
        
        full_response = ''
        for line in response.iter_lines():
            if line.startswith('data: '):
                data = json.loads(line[6:])
                if 'choices' in data and 'delta' in data['choices'][0]:
                    content = data['choices'][0]['delta'].get('content', '')
                    full_response += content
                    on_chunk(content)
        
        return full_response

    def use_template(self, template_name: str, variables: Dict) -> Dict:
        """ä½¿ç”¨æ¨¡æ¿"""
        return self._request(
            '/api/v2/llm/template',
            method='POST',
            data={
                'template': template_name,
                'variables': variables
            }
        )

    def get_conversation_history(self, conversation_id: str) -> Dict:
        """è·å–å¯¹è¯å†å²"""
        return self._request(f'/api/v2/llm/conversation/{conversation_id}')

    def export_conversation(self, conversation_id: str, format: str) -> Dict:
        """å¯¼å‡ºå¯¹è¯"""
        return self._request(
            f'/api/v2/llm/conversation/{conversation_id}/export',
            method='POST',
            data={'format': format}
        )

    def get_models(self) -> List[Dict]:
        """è·å–å¯ç”¨æ¨¡å‹"""
        return self._request('/api/v2/llm/models')

# ä½¿ç”¨ç¤ºä¾‹
api = LLMAPI('http://localhost:6000', 'your-token-here')

# å‘é€æ¶ˆæ¯
response = api.send_message('å¸®æˆ‘åˆ†æä¸€ä¸‹NASç³»ç»Ÿçš„æ€§èƒ½')
print(f'AIå“åº”: {response["message"]}')

# æµå¼æ¶ˆæ¯
def on_chunk(chunk):
    print(f'å®æ—¶è¾“å‡º: {chunk}')

full_response = api.stream_message('å¸®æˆ‘å†™ä¸€ä¸ªPythonè„šæœ¬', on_chunk)
print(f'å®Œæ•´å“åº”: {full_response}')

# ä½¿ç”¨æ¨¡æ¿
template_response = api.use_template('code-generation', {
    'language': 'Python',
    'function': 'æ–‡ä»¶ä¸Šä¼ '
})
print(f'æ¨¡æ¿å“åº”: {template_response["message"]}')

# è·å–å¯¹è¯å†å²
history = api.get_conversation_history('conv-001')
print(f'å¯¹è¯å†å²: {history}')

# å¯¼å‡ºå¯¹è¯
export_result = api.export_conversation('conv-001', 'markdown')
print(f'å¯¼å‡ºç»“æœ: {export_result}')

# è·å–å¯ç”¨æ¨¡å‹
models = api.get_models()
print(f'å¯ç”¨æ¨¡å‹: {models}')
```

### ç¤ºä¾‹3: cURL

```bash
# å‘é€æ¶ˆæ¯
curl -X POST \
  -H "Authorization: Bearer your-token-here" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen:7b",
    "messages": [
      {
        "role": "user",
        "content": "å¸®æˆ‘åˆ†æä¸€ä¸‹NASç³»ç»Ÿçš„æ€§èƒ½"
      }
    ],
    "stream": false
  }' \
  http://localhost:6000/api/v2/llm/chat

# æµå¼æ¶ˆæ¯
curl -X POST \
  -H "Authorization: Bearer your-token-here" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen:7b",
    "messages": [
      {
        "role": "user",
        "content": "å¸®æˆ‘å†™ä¸€ä¸ªPythonè„šæœ¬"
      }
    ],
    "stream": true
  }' \
  http://localhost:6000/api/v2/llm/chat

# ä½¿ç”¨æ¨¡æ¿
curl -X POST \
  -H "Authorization: Bearer your-token-here" \
  -H "Content-Type: application/json" \
  -d '{
    "template": "code-generation",
    "variables": {
      "language": "Python",
      "function": "æ–‡ä»¶ä¸Šä¼ ",
      "description": "å®ç°ä¸€ä¸ªæ”¯æŒæ–­ç‚¹ç»­ä¼ çš„æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½"
    }
  }' \
  http://localhost:6000/api/v2/llm/template

# è·å–å¯¹è¯å†å²
curl -X GET \
  -H "Authorization: Bearer your-token-here" \
  http://localhost:6000/api/v2/llm/conversation/conv-001

# å¯¼å‡ºå¯¹è¯
curl -X POST \
  -H "Authorization: Bearer your-token-here" \
  -H "Content-Type: application/json" \
  -d '{"format": "markdown"}' \
  http://localhost:6000/api/v2/llm/conversation/conv-001/export

# è·å–å¯ç”¨æ¨¡å‹
curl -X GET \
  -H "Authorization: Bearer your-token-here" \
  http://localhost:6000/api/v2/llm/models
```

---

## æç¤ºè¯æ¨¡æ¿ç¤ºä¾‹

### ç¤ºä¾‹1: ä»£ç ç”Ÿæˆæ¨¡æ¿

```typescript
// ä»£ç ç”Ÿæˆæ¨¡æ¿
const codeGenerationTemplate = {
  name: 'code-generation',
  description: 'ç”Ÿæˆé«˜è´¨é‡çš„ä»£ç ',
  template: `ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„è½¯ä»¶å·¥ç¨‹å¸ˆï¼Œæ“…é•¿ç¼–å†™é«˜è´¨é‡ã€å¯ç»´æŠ¤çš„ä»£ç ã€‚

è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚ç”Ÿæˆ{{language}}ä»£ç ï¼š

åŠŸèƒ½æè¿°ï¼š{{function}}
è¯¦ç»†è¯´æ˜ï¼š{{description}}

è¦æ±‚ï¼š
1. ä»£ç åº”è¯¥æ¸…æ™°ã€æ˜“è¯»ã€æœ‰è‰¯å¥½çš„æ³¨é‡Š
2. éµå¾ª{{language}}çš„æœ€ä½³å®è·µå’Œç¼–ç è§„èŒƒ
3. åŒ…å«å¿…è¦çš„é”™è¯¯å¤„ç†
4. è€ƒè™‘æ€§èƒ½å’Œå®‰å…¨æ€§
5. æä¾›ä½¿ç”¨ç¤ºä¾‹

è¯·ç”Ÿæˆå®Œæ•´çš„ä»£ç ï¼ŒåŒ…æ‹¬å¿…è¦çš„å¯¼å…¥å’Œé…ç½®ã€‚`,
  variables: {
    language: 'ç¼–ç¨‹è¯­è¨€',
    function: 'åŠŸèƒ½åç§°',
    description: 'åŠŸèƒ½è¯¦ç»†æè¿°',
  },
};

// ä½¿ç”¨ç¤ºä¾‹
const variables = {
  language: 'Python',
  function: 'æ–‡ä»¶ä¸Šä¼ ',
  description: 'å®ç°ä¸€ä¸ªæ”¯æŒæ–­ç‚¹ç»­ä¼ çš„æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½',
};

const response = await useTemplate('code-generation', variables);
console.log('ç”Ÿæˆçš„ä»£ç :', response.message);
```

### ç¤ºä¾‹2: æ–‡æ¡£åˆ†ææ¨¡æ¿

```typescript
// æ–‡æ¡£åˆ†ææ¨¡æ¿
const documentAnalysisTemplate = {
  name: 'document-analysis',
  description: 'åˆ†ææ–‡æ¡£å†…å®¹',
  template: `è¯·åˆ†æä»¥ä¸‹æ–‡æ¡£ï¼š

æ–‡æ¡£å†…å®¹ï¼š
{{document}}

åˆ†æç±»å‹ï¼š{{analysisType}}

è¯·æä¾›ï¼š
1. {{analysisType}}æ‘˜è¦
2. å…³é”®è¦ç‚¹
3. ä¸»è¦ç»“è®º
4. å¯è¡Œæ€§å»ºè®®ï¼ˆå¦‚é€‚ç”¨ï¼‰
5. é£é™©æç¤ºï¼ˆå¦‚é€‚ç”¨ï¼‰`,
  variables: {
    document: 'æ–‡æ¡£å†…å®¹',
    analysisType: 'åˆ†æç±»å‹ï¼ˆsummary/analysis/feasibility/riskï¼‰',
  },
};

// ä½¿ç”¨ç¤ºä¾‹
const variables = {
  document: 'è¿™æ˜¯ä¸€ä»½ç³»ç»Ÿæ¶æ„æ–‡æ¡£...',
  analysisType: 'summary',
};

const response = await useTemplate('document-analysis', variables);
console.log('æ–‡æ¡£æ‘˜è¦:', response.message);
```

### ç¤ºä¾‹3: ä»£ç å®¡æŸ¥æ¨¡æ¿

```typescript
// ä»£ç å®¡æŸ¥æ¨¡æ¿
const codeReviewTemplate = {
  name: 'code-review',
  description: 'å®¡æŸ¥ä»£ç è´¨é‡',
  template: `è¯·å®¡æŸ¥ä»¥ä¸‹ä»£ç ï¼š

ä»£ç ï¼š
\`\`\`{{language}}
{{code}}
\`\`\`

è¯·ä»ä»¥ä¸‹æ–¹é¢è¿›è¡Œå®¡æŸ¥ï¼š
1. ä»£ç è´¨é‡å’Œå¯è¯»æ€§
2. æ½œåœ¨çš„bugå’Œé—®é¢˜
3. æ€§èƒ½ä¼˜åŒ–å»ºè®®
4. å®‰å…¨æ€§é—®é¢˜
5. æœ€ä½³å®è·µéµå¾ªæƒ…å†µ
6. æ”¹è¿›å»ºè®®

è¯·æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®å’Œä¿®æ”¹åçš„ä»£ç ç¤ºä¾‹ã€‚`,
  variables: {
    language: 'ç¼–ç¨‹è¯­è¨€',
    code: 'ä»£ç å†…å®¹',
  },
};

// ä½¿ç”¨ç¤ºä¾‹
const variables = {
  language: 'TypeScript',
  code: `
function processData(data: any[]) {
  const result = [];
  for (let i = 0; i < data.length; i++) {
    result.push(data[i].value);
  }
  return result;
}
  `,
};

const response = await useTemplate('code-review', variables);
console.log('å®¡æŸ¥ç»“æœ:', response.message);
```

---

## å¤šæ¨¡æ€æ”¯æŒç¤ºä¾‹

### ç¤ºä¾‹1: å›¾åƒåˆ†æ

```typescript
// å›¾åƒåˆ†æ
const analyzeImage = async (imageUrl: string, question: string) => {
  try {
    const response = await fetch('/api/v2/llm/vision', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${token}`,
      },
      body: JSON.stringify({
        model: 'llava:7b',
        image: imageUrl,
        question,
      }),
    });

    const data = await response.json();

    if (data.success) {
      console.log('å›¾åƒåˆ†æç»“æœ:', data.data);
      return data.data;
    }
  } catch (error) {
    console.error('å›¾åƒåˆ†æå¤±è´¥:', error);
  }
};

// ä½¿ç”¨ç¤ºä¾‹
const analysis = await analyzeImage(
  'https://example.com/image.jpg',
  'è¯·æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹'
);

console.log('å›¾åƒæè¿°:', analysis.description);
```

### ç¤ºä¾‹2: æ–‡æ¡£åˆ†æ

```typescript
// æ–‡æ¡£åˆ†æ
const analyzeDocument = async (fileUrl: string, question: string) => {
  try {
    const response = await fetch('/api/v2/llm/document', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${token}`,
      },
      body: JSON.stringify({
        model: 'qwen:14b',
        document: fileUrl,
        question,
      }),
    });

    const data = await response.json();

    if (data.success) {
      console.log('æ–‡æ¡£åˆ†æç»“æœ:', data.data);
      return data.data;
    }
  } catch (error) {
    console.error('æ–‡æ¡£åˆ†æå¤±è´¥:', error);
  }
};

// ä½¿ç”¨ç¤ºä¾‹
const analysis = await analyzeDocument(
  'https://example.com/document.pdf',
  'è¯·æ€»ç»“è¿™ä»½æ–‡æ¡£çš„ä¸»è¦å†…å®¹'
);

console.log('æ–‡æ¡£æ‘˜è¦:', analysis.summary);
```

---

## æ•…éšœæ’æŸ¥ç¤ºä¾‹

### ç¤ºä¾‹1: æ£€æŸ¥LLMæœåŠ¡çŠ¶æ€

```typescript
// æ£€æŸ¥LLMæœåŠ¡çŠ¶æ€
const checkLLMService = async () => {
  try {
    const response = await fetch('/api/v2/llm/health');
    const data = await response.json();

    if (data.success) {
      const health = data.data;
      console.log('LLMæœåŠ¡çŠ¶æ€:', health);
      
      // æ£€æŸ¥å„é¡¹æœåŠ¡çŠ¶æ€
      if (health.ollama === 'healthy') {
        console.log('âœ… OllamaæœåŠ¡æ­£å¸¸');
      } else {
        console.log('âŒ OllamaæœåŠ¡å¼‚å¸¸');
      }
      
      if (health.redis === 'healthy') {
        console.log('âœ… RedisæœåŠ¡æ­£å¸¸');
      } else {
        console.log('âŒ RedisæœåŠ¡å¼‚å¸¸');
      }
      
      if (health.api === 'healthy') {
        console.log('âœ… APIæœåŠ¡æ­£å¸¸');
      } else {
        console.log('âŒ APIæœåŠ¡å¼‚å¸¸');
      }
      
      return health;
    }
  } catch (error) {
    console.error('æ£€æŸ¥LLMæœåŠ¡çŠ¶æ€å¤±è´¥:', error);
  }
};

checkLLMService();
```

### ç¤ºä¾‹2: æŸ¥çœ‹æ¨¡å‹çŠ¶æ€

```typescript
// æŸ¥çœ‹æ¨¡å‹çŠ¶æ€
const getModelStatus = async (modelName: string) => {
  try {
    const response = await fetch(`/api/v2/llm/model/${modelName}/status`);
    const data = await response.json();

    if (data.success) {
      console.log('æ¨¡å‹çŠ¶æ€:', data.data);
      return data.data;
    }
  } catch (error) {
    console.error('æŸ¥çœ‹æ¨¡å‹çŠ¶æ€å¤±è´¥:', error);
  }
};

// ä½¿ç”¨ç¤ºä¾‹
const modelStatus = await getModelStatus('qwen:7b');
console.log('æ¨¡å‹çŠ¶æ€:', modelStatus);
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": {
    "name": "qwen:7b",
    "status": "loaded",
    "size": "4.7GB",
    "parameters": "7B",
    "quantization": "Q4_K_M",
    "memoryUsage": "5.2GB",
    "lastUsed": "2026-01-25T10:30:00Z"
  }
}
```

### ç¤ºä¾‹3: ä¸‹è½½æ¨¡å‹

```typescript
// ä¸‹è½½æ¨¡å‹
const downloadModel = async (modelName: string) => {
  try {
    const response = await fetch(`/api/v2/llm/model/${modelName}/download`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${token}`,
      },
    });

    const data = await response.json();

    if (data.success) {
      console.log('æ¨¡å‹ä¸‹è½½å·²å¯åŠ¨:', data.data);
      return data.data;
    }
  } catch (error) {
    console.error('ä¸‹è½½æ¨¡å‹å¤±è´¥:', error);
  }
};

// ä½¿ç”¨ç¤ºä¾‹
const downloadResult = await downloadModel('qwen:14b');
console.log('ä¸‹è½½ç»“æœ:', downloadResult);
```

---

## æœ€ä½³å®è·µ

### 1. é€‰æ‹©åˆé€‚çš„æ¨¡å‹

**å»ºè®®**:
- ç®€å•é—®ç­”: ä½¿ç”¨è½»é‡çº§æ¨¡å‹ï¼ˆqwen:7b, llama3:8bï¼‰
- ä»£ç ç”Ÿæˆ: ä½¿ç”¨ä¸­ç­‰è§„æ¨¡æ¨¡å‹ï¼ˆqwen:14bï¼‰
- æ–‡æ¡£åˆ†æ: ä½¿ç”¨å¤§è§„æ¨¡æ¨¡å‹ï¼ˆqwen:72b, llama3:70bï¼‰
- å®æ—¶å¯¹è¯: ä½¿ç”¨è½»é‡çº§æ¨¡å‹ä»¥è·å¾—å¿«é€Ÿå“åº”

**ç¤ºä¾‹**:
```typescript
const modelSelection = {
  simpleQA: 'qwen:7b',
  codeGeneration: 'qwen:14b',
  documentAnalysis: 'qwen:72b',
  realTimeChat: 'qwen:7b',
};
```

### 2. ä¼˜åŒ–æç¤ºè¯

**å»ºè®®**:
- æ˜ç¡®æŒ‡å®šä»»åŠ¡å’ŒæœŸæœ›
- æä¾›è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
- ä½¿ç”¨ç»“æ„åŒ–çš„æç¤ºè¯æ ¼å¼
- é¿å…æ¨¡ç³Šå’Œæ­§ä¹‰çš„è¡¨è¿°
- åŒ…å«ç¤ºä¾‹å’Œçº¦æŸæ¡ä»¶

**ç¤ºä¾‹**:
```typescript
const goodPrompt = `ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„è½¯ä»¶å·¥ç¨‹å¸ˆã€‚

ä»»åŠ¡ï¼šç¼–å†™ä¸€ä¸ªPythonå‡½æ•°ï¼Œç”¨äºå¤„ç†CSVæ–‡ä»¶ã€‚

è¦æ±‚ï¼š
1. å‡½æ•°åº”è¯¥æ¥å—æ–‡ä»¶è·¯å¾„ä½œä¸ºå‚æ•°
2. ä½¿ç”¨pandasåº“è¯»å–CSVæ–‡ä»¶
3. å¤„ç†ç¼ºå¤±å€¼ï¼ˆç”¨å¹³å‡å€¼å¡«å……ï¼‰
4. è¿”å›å¤„ç†åçš„DataFrame
5. åŒ…å«é”™è¯¯å¤„ç†
6. æ·»åŠ è¯¦ç»†çš„æ³¨é‡Š

è¯·æä¾›å®Œæ•´çš„ä»£ç å’Œç¤ºä¾‹ç”¨æ³•ã€‚`;

const badPrompt = 'å†™ä¸€ä¸ªå¤„ç†CSVæ–‡ä»¶çš„å‡½æ•°';
```

### 3. ä½¿ç”¨æµå¼å“åº”

**ä¼˜åŠ¿**:
- æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ
- å®æ—¶åé¦ˆ
- å‡å°‘ç­‰å¾…æ—¶é—´

**ç¤ºä¾‹**:
```typescript
// ä½¿ç”¨æµå¼å“åº”
await streamMessage('å¸®æˆ‘å†™ä¸€ä¸ªPythonè„šæœ¬', (chunk) => {
  console.log('å®æ—¶è¾“å‡º:', chunk);
});
```

### 4. ç®¡ç†å¯¹è¯å†å²

**å»ºè®®**:
- å®šæœŸæ¸…ç†ä¸é‡è¦çš„å¯¹è¯
- ä¸ºé‡è¦å¯¹è¯æ·»åŠ æ ‡ç­¾
- å¯¼å‡ºé‡è¦å¯¹è¯
- ä½¿ç”¨å¯¹è¯æœç´¢åŠŸèƒ½

**ç¤ºä¾‹**:
```typescript
// å¯¼å‡ºé‡è¦å¯¹è¯
const importantConversations = ['conv-001', 'conv-005', 'conv-010'];

for (const convId of importantConversations) {
  await exportConversation(convId, 'markdown');
}
```

### 5. ç›‘æ§æ¨¡å‹æ€§èƒ½

**å»ºè®®**:
- ç›‘æ§å“åº”æ—¶é—´
- ç›‘æ§tokenä½¿ç”¨é‡
- ç›‘æ§å†…å­˜ä½¿ç”¨
- å®šæœŸè¯„ä¼°æ¨¡å‹æ•ˆæœ

**ç¤ºä¾‹**:
```typescript
// ç›‘æ§æ¨¡å‹æ€§èƒ½
const startTime = Date.now();
const response = await sendMessage('æµ‹è¯•æ¶ˆæ¯');
const endTime = Date.now();

const responseTime = endTime - startTime;
console.log(`å“åº”æ—¶é—´: ${responseTime}ms`);
console.log(`Tokenä½¿ç”¨é‡: ${response.tokens}`);
```

---

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼Ÿ

**A**: æ ¹æ®ä»»åŠ¡å¤æ‚åº¦å’Œå“åº”é€Ÿåº¦è¦æ±‚é€‰æ‹©æ¨¡å‹ã€‚ç®€å•ä»»åŠ¡ä½¿ç”¨è½»é‡çº§æ¨¡å‹ï¼Œå¤æ‚ä»»åŠ¡ä½¿ç”¨å¤§è§„æ¨¡æ¨¡å‹ã€‚

### Q2: å¦‚ä½•æé«˜å“åº”é€Ÿåº¦ï¼Ÿ

**A**: 1. ä½¿ç”¨è½»é‡çº§æ¨¡å‹ï¼›2. å¯ç”¨æµå¼å“åº”ï¼›3. ä¼˜åŒ–æç¤ºè¯é•¿åº¦ï¼›4. ä½¿ç”¨ç¼“å­˜ã€‚

### Q3: å¦‚ä½•å‡å°‘tokenä½¿ç”¨é‡ï¼Ÿ

**A**: 1. ä¼˜åŒ–æç¤ºè¯é•¿åº¦ï¼›2. é¿å…é‡å¤ä¿¡æ¯ï¼›3. ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºï¼›4. è®¾ç½®max_tokensé™åˆ¶ã€‚

### Q4: å¦‚ä½•å¤„ç†æ•æ„Ÿä¿¡æ¯ï¼Ÿ

**A**: ä¸è¦åœ¨å¯¹è¯ä¸­å‘é€æ•æ„Ÿä¿¡æ¯ï¼Œå¦‚å¯†ç ã€å¯†é’¥ç­‰ã€‚ä½¿ç”¨è„±æ•æ•°æ®æˆ–å ä½ç¬¦ã€‚

### Q5: å¦‚ä½•è‡ªå®šä¹‰æ¨¡å‹è¡Œä¸ºï¼Ÿ

**A**: ä½¿ç”¨ç³»ç»Ÿæç¤ºè¯è®¾ç½®æ¨¡å‹çš„è§’è‰²å’Œè¡Œä¸ºï¼Œè°ƒæ•´temperatureã€top_pç­‰å‚æ•°æ§åˆ¶è¾“å‡ºé£æ ¼ã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0  
**æœ€åæ›´æ–°**: 2026-01-25  
**ç»´æŠ¤å›¢é˜Ÿ**: YYCÂ³ Team

---

<div align="center">

> ã€Œ***YanYuCloudCube***ã€
> ã€Œ***<admin@0379.email>***ã€
> ã€Œ***Words Initiate Quadrants, Language Serves as Core for the Future***ã€
> ã€Œ***All things converge in the cloud pivot; Deep stacks ignite a new era of intelligence***ã€

</div>
