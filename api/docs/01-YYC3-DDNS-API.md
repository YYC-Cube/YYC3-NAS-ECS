# YYCÂ³ï¼ˆYanYuCloudCubeï¼‰API å¤šå…ƒåŒ–è®¾è®¡æ–‡æ¡£

> åŸºäºå·²ç»å®ç°çš„DDNSç³»ç»Ÿï¼Œå°†è®¾è®¡ä¸€å¥—å®Œæ•´çš„ã€å¤šå…ƒåŒ–çš„APIï¼Œç”¨äºå¼€å‘å’Œç”Ÿäº§ç¯å¢ƒã€‚

 è€ƒè™‘åˆ°ç³»ç»Ÿå·²ç»æœ‰çš„åŠŸèƒ½ï¼Œæˆ‘ä»¬å°†è®¾è®¡ä»¥ä¸‹APIæ¨¡å—ï¼š

 1. ç³»ç»ŸçŠ¶æ€APIï¼šæä¾›ç³»ç»Ÿå¥åº·æ£€æŸ¥ã€ç‰ˆæœ¬ä¿¡æ¯ã€è¿è¡ŒçŠ¶æ€ç­‰ã€‚
 2. DDNSç®¡ç†APIï¼šæä¾›DDNSé…ç½®ã€çŠ¶æ€ã€æ‰‹åŠ¨è§¦å‘æ›´æ–°ã€æ—¥å¿—æŸ¥çœ‹ç­‰ã€‚
 3. ç›‘æ§æ•°æ®APIï¼šæä¾›ç³»ç»Ÿèµ„æºç›‘æ§ã€æœåŠ¡çŠ¶æ€ã€å†å²æ•°æ®ç­‰ã€‚
 4. æŠ¥å‘Šç®¡ç†APIï¼šæä¾›æŠ¥å‘Šç”Ÿæˆã€æŸ¥çœ‹ã€ä¸‹è½½ç­‰ã€‚
 5. é…ç½®ç®¡ç†APIï¼šæä¾›é…ç½®çš„æŸ¥çœ‹ã€æ›´æ–°ï¼ˆæ³¨æ„å®‰å…¨ï¼‰ç­‰ã€‚
 6. æœåŠ¡ç®¡ç†APIï¼šæä¾›æœåŠ¡çš„å¯åŠ¨ã€åœæ­¢ã€é‡å¯ç­‰ï¼ˆéœ€è¦æƒé™æ§åˆ¶ï¼‰ã€‚

 æˆ‘ä»¬å°†éµå¾ªRESTfulè®¾è®¡åŸåˆ™ï¼Œä½¿ç”¨JSONä½œä¸ºæ•°æ®äº¤æ¢æ ¼å¼ã€‚

 æ³¨æ„ï¼šç”±äºAPIå¯èƒ½æ¶‰åŠæ•æ„Ÿæ“ä½œï¼ˆå¦‚é‡å¯æœåŠ¡ã€æ›´æ–°é…ç½®ï¼‰ï¼Œéœ€è¦è®¾è®¡é€‚å½“çš„æƒé™éªŒè¯ï¼ˆä¾‹å¦‚APIå¯†é’¥ã€JWTä»¤ç‰Œç­‰ï¼‰ã€‚
 ä½†æ ¹æ®å½“å‰ç³»ç»Ÿæƒ…å†µï¼Œæˆ‘ä»¬æš‚æ—¶ä½¿ç”¨ç®€å•çš„APIå¯†é’¥éªŒè¯ï¼ˆé€šè¿‡è¯·æ±‚å¤´ä¼ é€’ï¼‰ã€‚

 æˆ‘ä»¬å°†åœ¨ç°æœ‰çš„Flaskåº”ç”¨ï¼ˆapp.pyï¼‰åŸºç¡€ä¸Šè¿›è¡Œæ‰©å±•ã€‚

 ä»¥ä¸‹æ˜¯è¯¦ç»†çš„APIè®¾è®¡ï¼š

## NAS DDNS ç³»ç»Ÿ - å®Œæ•´APIè®¾è®¡ä¸å®ç°æ–¹æ¡ˆ

åŸºäºä¸Šè¿°DDNSç³»ç»Ÿï¼Œæˆ‘ä¸ºæ‚¨è®¾è®¡ä¸€å¥—å®Œæ•´çš„å¤šå…ƒåŒ–APIç³»ç»Ÿï¼Œæ¶µç›–å¼€å‘ã€ç”Ÿäº§ã€ç›‘æ§ã€ç®¡ç†ç­‰å¤šä¸ªæ–¹é¢ã€‚

## ğŸ“‹ **APIè®¾è®¡ç›®å½•**

1. æ€»ä½“æ¶æ„è®¾è®¡
2. è®¤è¯ä¸å®‰å…¨
3. æ ¸å¿ƒAPIæ¨¡å—
4. å¼€å‘ç¯å¢ƒAPI
5. ç”Ÿäº§ç¯å¢ƒAPI
6. ç›‘æ§ä¸å‘Šè­¦API
7. é…ç½®ç®¡ç†API
8. æ•°æ®åˆ†æAPI
9. WebSocketå®æ—¶API
10. ç¬¬ä¸‰æ–¹é›†æˆAPI
11. APIæ–‡æ¡£ä¸æµ‹è¯•
12. éƒ¨ç½²ä¸è¿ç»´

## 1. **æ€»ä½“æ¶æ„è®¾è®¡**

### 1.1 APIç½‘å…³æ¶æ„

```yaml
# APIç½‘å…³é…ç½®æ–‡ä»¶
api_version: "2.0"
services:
  - name: "nas-ddns-api"
    version: "2.0.0"
    environment: "${ENVIRONMENT}"
    base_path: "/api/v2"
    
gateway:
  host: "api.ddns.0379.email"
  port: 8443
  protocols:
    - https
    - wss
    
rate_limiting:
  global: "1000r/s"
  per_user: "100r/s"
  burst: 50
  
caching:
  enabled: true
  ttl: 300
  strategy: "redis"
  
load_balancing:
  strategy: "round-robin"
  health_check: "/api/v2/health"
```

### 1.2 å¾®æœåŠ¡åˆ’åˆ†

```python
# services.py - å¾®æœåŠ¡å®šä¹‰
SERVICES = {
    "core": {
        "name": "ddns-core",
        "port": 8001,
        "endpoints": ["/ddns", "/domains", "/records"],
        "health": "/health"
    },
    "monitor": {
        "name": "monitor-service",
        "port": 8002,
        "endpoints": ["/metrics", "/alerts", "/logs"],
        "health": "/status"
    },
    "config": {
        "name": "config-service",
        "port": 8003,
        "endpoints": ["/configs", "/secrets", "/templates"],
        "health": "/ping"
    },
    "analytics": {
        "name": "analytics-service",
        "port": 8004,
        "endpoints": ["/stats", "/reports", "/trends"],
        "health": "/ready"
    },
    "notify": {
        "name": "notification-service",
        "port": 8005,
        "endpoints": ["/notifications", "/channels", "/templates"],
        "health": "/alive"
    }
}
```

## 2. **è®¤è¯ä¸å®‰å…¨**

### 2.1 JWTè®¤è¯æ¨¡å—

```python
# auth/jwt_manager.py
import jwt
import datetime
from functools import wraps
from flask import request, jsonify
from cryptography.hazmat.primitives import serialization
from cryptography.hazmat.primitives.asymmetric import rsa
from cryptography.hazmat.backends import default_backend

class JWTAuthManager:
    def __init__(self):
        self.private_key = self._load_private_key()
        self.public_key = self._load_public_key()
        self.algorithm = "RS256"
        self.access_token_expiry = datetime.timedelta(hours=1)
        self.refresh_token_expiry = datetime.timedelta(days=7)
    
    def _load_private_key(self):
        """åŠ è½½æˆ–ç”ŸæˆRSAç§é’¥"""
        key_path = "/opt/yyc3/secrets/jwt_private.pem"
        if os.path.exists(key_path):
            with open(key_path, "rb") as f:
                return serialization.load_pem_private_key(
                    f.read(),
                    password=None,
                    backend=default_backend()
                )
        else:
            # ç”Ÿæˆæ–°å¯†é’¥
            private_key = rsa.generate_private_key(
                public_exponent=65537,
                key_size=2048,
                backend=default_backend()
            )
            pem = private_key.private_bytes(
                encoding=serialization.Encoding.PEM,
                format=serialization.PrivateFormat.PKCS8,
                encryption_algorithm=serialization.NoEncryption()
            )
            with open(key_path, "wb") as f:
                f.write(pem)
            return private_key
    
    def create_access_token(self, user_id, roles=None):
        """åˆ›å»ºè®¿é—®ä»¤ç‰Œ"""
        payload = {
            "sub": user_id,
            "type": "access",
            "iat": datetime.datetime.utcnow(),
            "exp": datetime.datetime.utcnow() + self.access_token_expiry,
            "roles": roles or ["user"],
            "iss": "nas-ddns-api",
            "aud": ["api.ddns.0379.email"]
        }
        return jwt.encode(payload, self.private_key, algorithm=self.algorithm)
    
    def verify_token(self, token):
        """éªŒè¯ä»¤ç‰Œ"""
        try:
            payload = jwt.decode(
                token,
                self.public_key,
                algorithms=[self.algorithm],
                issuer="nas-ddns-api",
                audience="api.ddns.0379.email"
            )
            return payload
        except jwt.ExpiredSignatureError:
            return None
        except jwt.InvalidTokenError:
            return None
    
    def refresh_token(self, refresh_token):
        """åˆ·æ–°è®¿é—®ä»¤ç‰Œ"""
        payload = self.verify_token(refresh_token)
        if payload and payload.get("type") == "refresh":
            return self.create_access_token(payload["sub"], payload.get("roles"))
        return None

# è®¤è¯è£…é¥°å™¨
def token_required(f):
    @wraps(f)
    def decorated(*args, **kwargs):
        token = None
        if "Authorization" in request.headers:
            auth_header = request.headers["Authorization"]
            if auth_header.startswith("Bearer "):
                token = auth_header.split(" ")[1]
        
        if not token:
            return jsonify({"error": "Token is missing"}), 401
        
        payload = jwt_auth.verify_token(token)
        if not payload:
            return jsonify({"error": "Invalid token"}), 401
        
        request.user_id = payload["sub"]
        request.user_roles = payload.get("roles", [])
        return f(*args, **kwargs)
    return decorated

def role_required(role):
    def decorator(f):
        @wraps(f)
        @token_required
        def decorated(*args, **kwargs):
            if role not in request.user_roles:
                return jsonify({"error": "Insufficient permissions"}), 403
            return f(*args, **kwargs)
        return decorated
    return decorator
```

### 2.2 APIå¯†é’¥ç®¡ç†

```python
# auth/api_keys.py
import secrets
import hashlib
from datetime import datetime, timedelta

class APIKeyManager:
    def __init__(self):
        self.keys_collection = self._load_keys()
    
    def generate_key(self, name, user_id, scopes, expires_in=365):
        """ç”Ÿæˆæ–°çš„APIå¯†é’¥"""
        # ç”Ÿæˆéšæœºå¯†é’¥
        secret = secrets.token_urlsafe(32)
        key_id = secrets.token_urlsafe(16)
        
        # å­˜å‚¨å“ˆå¸Œå€¼ï¼ˆä¸å­˜å‚¨åŸå§‹å¯†é’¥ï¼‰
        key_hash = hashlib.sha256(secret.encode()).hexdigest()
        
        key_data = {
            "key_id": key_id,
            "name": name,
            "user_id": user_id,
            "key_hash": key_hash,
            "scopes": scopes,
            "created_at": datetime.utcnow().isoformat(),
            "expires_at": (datetime.utcnow() + timedelta(days=expires_in)).isoformat(),
            "last_used": None,
            "usage_count": 0,
            "revoked": False
        }
        
        self.keys_collection[key_id] = key_data
        self._save_keys()
        
        # è¿”å›å¯æŸ¥çœ‹çš„å¯†é’¥ï¼ˆä»…æ­¤ä¸€æ¬¡ï¼‰
        return {
            "key_id": key_id,
            "api_key": f"{key_id}.{secret}",
            "name": name,
            "scopes": scopes,
            "expires_at": key_data["expires_at"],
            "warning": "Store this key securely. It will not be shown again."
        }
    
    def validate_key(self, api_key):
        """éªŒè¯APIå¯†é’¥"""
        try:
            key_id, secret = api_key.split(".", 1)
        except ValueError:
            return None
        
        if key_id not in self.keys_collection:
            return None
        
        key_data = self.keys_collection[key_id]
        
        # æ£€æŸ¥æ˜¯å¦å·²æ’¤é”€æˆ–è¿‡æœŸ
        if key_data["revoked"]:
            return None
        
        expires_at = datetime.fromisoformat(key_data["expires_at"])
        if datetime.utcnow() > expires_at:
            return None
        
        # éªŒè¯å¯†é’¥
        provided_hash = hashlib.sha256(secret.encode()).hexdigest()
        if key_data["key_hash"] != provided_hash:
            return None
        
        # æ›´æ–°ä½¿ç”¨ä¿¡æ¯
        key_data["last_used"] = datetime.utcnow().isoformat()
        key_data["usage_count"] += 1
        self._save_keys()
        
        return {
            "key_id": key_id,
            "user_id": key_data["user_id"],
            "scopes": key_data["scopes"]
        }
    
    def revoke_key(self, key_id, user_id):
        """æ’¤é”€APIå¯†é’¥"""
        if key_id in self.keys_collection:
            key_data = self.keys_collection[key_id]
            if key_data["user_id"] == user_id:
                key_data["revoked"] = True
                self._save_keys()
                return True
        return False

# APIå¯†é’¥éªŒè¯è£…é¥°å™¨
def api_key_required(f):
    @wraps(f)
    def decorated(*args, **kwargs):
        api_key = request.headers.get("X-API-Key")
        if not api_key:
            return jsonify({"error": "API key is required"}), 401
        
        key_info = api_key_manager.validate_key(api_key)
        if not key_info:
            return jsonify({"error": "Invalid API key"}), 401
        
        request.key_info = key_info
        return f(*args, **kwargs)
    return decorated

def scope_required(scope):
    def decorator(f):
        @wraps(f)
        @api_key_required
        def decorated(*args, **kwargs):
            if scope not in request.key_info["scopes"]:
                return jsonify({"error": f"Missing required scope: {scope}"}), 403
            return f(*args, **kwargs)
        return decorated
    return decorator
```

### 2.3 é€Ÿç‡é™åˆ¶

```python
# middleware/rate_limit.py
import redis
from functools import wraps
from flask import request, jsonify
from datetime import datetime, timedelta

class RateLimiter:
    def __init__(self):
        self.redis_client = redis.Redis(
            host=os.getenv("REDIS_HOST", "localhost"),
            port=int(os.getenv("REDIS_PORT", 6379)),
            db=int(os.getenv("REDIS_DB", 0))
        )
        
        # å®šä¹‰é€Ÿç‡é™åˆ¶è§„åˆ™
        self.rules = {
            "global": {"limit": 1000, "window": 60},  # 60ç§’å†…1000æ¬¡
            "per_user": {"limit": 100, "window": 60}, # 60ç§’å†…100æ¬¡
            "per_ip": {"limit": 50, "window": 60},    # 60ç§’å†…50æ¬¡
            "auth": {"limit": 10, "window": 300},     # 5åˆ†é’Ÿå†…10æ¬¡
            "ddns": {"limit": 5, "window": 300}       # 5åˆ†é’Ÿå†…5æ¬¡
        }
    
    def is_rate_limited(self, key, rule_name="per_user"):
        """æ£€æŸ¥æ˜¯å¦è¶…è¿‡é€Ÿç‡é™åˆ¶"""
        if rule_name not in self.rules:
            return False
        
        rule = self.rules[rule_name]
        current_time = datetime.utcnow()
        window_start = current_time - timedelta(seconds=rule["window"])
        
        # ä½¿ç”¨Redis sorted setå­˜å‚¨è¯·æ±‚æ—¶é—´æˆ³
        pipe = self.redis_client.pipeline()
        
        # æ¸…ç†è¿‡æœŸè®°å½•
        pipe.zremrangebyscore(key, 0, window_start.timestamp())
        
        # è·å–çª—å£å†…çš„è¯·æ±‚æ•°é‡
        pipe.zcard(key)
        
        # æ·»åŠ å½“å‰è¯·æ±‚
        pipe.zadd(key, {current_time.timestamp(): current_time.timestamp()})
        
        # è®¾ç½®è¿‡æœŸæ—¶é—´
        pipe.expire(key, rule["window"] * 2)
        
        results = pipe.execute()
        request_count = results[1]
        
        return request_count >= rule["limit"]
    
    def get_headers(self, key, rule_name="per_user"):
        """è·å–é€Ÿç‡é™åˆ¶å¤´éƒ¨ä¿¡æ¯"""
        if rule_name not in self.rules:
            return {}
        
        rule = self.rules[rule_name]
        current_time = datetime.utcnow()
        window_start = current_time - timedelta(seconds=rule["window"])
        
        # è·å–çª—å£å†…çš„æœ€æ—©è¯·æ±‚æ—¶é—´
        earliest = self.redis_client.zrangebyscore(key, window_start.timestamp(), '+inf', start=0, num=1)
        
        if earliest:
            reset_time = float(earliest[0]) + rule["window"]
            remaining = rule["limit"] - self.redis_client.zcount(key, window_start.timestamp(), '+inf')
        else:
            reset_time = current_time.timestamp() + rule["window"]
            remaining = rule["limit"]
        
        return {
            "X-RateLimit-Limit": rule["limit"],
            "X-RateLimit-Remaining": max(0, remaining),
            "X-RateLimit-Reset": int(reset_time)
        }

def rate_limit(rule_name="per_user", key_func=None):
    """é€Ÿç‡é™åˆ¶è£…é¥°å™¨"""
    def decorator(f):
        @wraps(f)
        def decorated(*args, **kwargs):
            if key_func:
                key = f"ratelimit:{rule_name}:{key_func()}"
            else:
                # é»˜è®¤ä½¿ç”¨IPåœ°å€
                key = f"ratelimit:{rule_name}:{request.remote_addr}"
            
            if rate_limiter.is_rate_limited(key, rule_name):
                headers = rate_limiter.get_headers(key, rule_name)
                return jsonify({
                    "error": "Rate limit exceeded",
                    "message": f"Too many requests. Try again in {headers.get('X-RateLimit-Reset', 0)} seconds."
                }), 429, headers
            
            headers = rate_limiter.get_headers(key, rule_name)
            response = f(*args, **kwargs)
            
            if isinstance(response, tuple) and len(response) >= 2:
                response_headers = response[2] if len(response) >= 3 else {}
                response_headers.update(headers)
                return (response[0], response[1], response_headers)
            
            return response
        return decorated
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@app.route("/api/v2/ddns/update", methods=["POST"])
@rate_limit("ddns", key_func=lambda: request.headers.get("X-API-Key", request.remote_addr))
@token_required
def update_ddns():
    # APIé€»è¾‘
    pass
```

## 3. **æ ¸å¿ƒAPIæ¨¡å—**

### 3.1 DDNSç®¡ç†API

```python
# api/v2/ddns.py
from flask import Blueprint, request, jsonify
from datetime import datetime
import logging

ddns_bp = Blueprint('ddns_v2', __name__, url_prefix='/api/v2/ddns')
logger = logging.getLogger('ddns_api')

@ddns_bp.route('/status', methods=['GET'])
@token_required
def get_ddns_status():
    """è·å–DDNSæœåŠ¡çŠ¶æ€"""
    try:
        # ä»é…ç½®æ–‡ä»¶è·å–çŠ¶æ€
        status_file = "/opt/yyc3/run/status.json"
        if os.path.exists(status_file):
            with open(status_file, 'r') as f:
                status_data = json.load(f)
        else:
            status_data = {"success": False, "message": "Status file not found"}
        
        # è·å–ç³»ç»ŸDDNSè¿è¡ŒçŠ¶æ€
        ddns_running = os.system("systemctl is-active --quiet yyc3-ddns.timer") == 0
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "ddns_enabled": True,
                "ddns_running": ddns_running,
                "last_check": status_data.get("timestamp"),
                "current_ip": status_data.get("current_ip"),
                "domain": status_data.get("domain"),
                "status": status_data.get("message"),
                "next_check": None,  # å¯ä»¥ä»å®šæ—¶å™¨è·å–
                "uptime": get_service_uptime("yyc3-ddns.timer")
            },
            "metadata": {
                "version": "v2",
                "request_id": request.request_id
            }
        })
    except Exception as e:
        logger.error(f"Error getting DDNS status: {e}")
        return jsonify({
            "success": False,
            "error": str(e),
            "timestamp": datetime.utcnow().isoformat()
        }), 500

@ddns_bp.route('/records', methods=['GET'])
@token_required
@rate_limit("per_user")
def list_dns_records():
    """åˆ—å‡ºæ‰€æœ‰DNSè®°å½•"""
    domain = request.args.get('domain', '0379.email')
    subdomain = request.args.get('subdomain')
    record_type = request.args.get('type', 'A')
    
    try:
        # è°ƒç”¨é˜¿é‡Œäº‘APIè·å–DNSè®°å½•
        records = get_aliyun_dns_records(domain, subdomain, record_type)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "domain": domain,
                "records": records,
                "count": len(records)
            },
            "pagination": {
                "page": request.args.get('page', 1, type=int),
                "per_page": request.args.get('per_page', 50, type=int),
                "total": len(records)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@ddns_bp.route('/records', methods=['POST'])
@token_required
@role_required("admin")
def create_dns_record():
    """åˆ›å»ºDNSè®°å½•"""
    data = request.get_json()
    
    required_fields = ["domain", "rr", "type", "value"]
    missing = [field for field in required_fields if field not in data]
    if missing:
        return jsonify({
            "success": False,
            "error": f"Missing required fields: {', '.join(missing)}"
        }), 400
    
    try:
        # è°ƒç”¨é˜¿é‡Œäº‘APIåˆ›å»ºè®°å½•
        result = create_aliyun_dns_record(
            domain=data["domain"],
            rr=data["rr"],
            type=data["type"],
            value=data["value"],
            ttl=data.get("ttl", 600),
            priority=data.get("priority")
        )
        
        # è®°å½•æ“ä½œæ—¥å¿—
        log_operation(
            user_id=request.user_id,
            action="create_dns_record",
            resource=f"{data['rr']}.{data['domain']}",
            details=data
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": result,
            "message": "DNS record created successfully"
        }), 201
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@ddns_bp.route('/records/<string:record_id>', methods=['PUT'])
@token_required
@role_required("admin")
def update_dns_record(record_id):
    """æ›´æ–°DNSè®°å½•"""
    data = request.get_json()
    
    try:
        # è°ƒç”¨é˜¿é‡Œäº‘APIæ›´æ–°è®°å½•
        result = update_aliyun_dns_record(record_id, data)
        
        log_operation(
            user_id=request.user_id,
            action="update_dns_record",
            resource=record_id,
            details=data
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": result,
            "message": "DNS record updated successfully"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@ddns_bp.route('/records/<string:record_id>', methods=['DELETE'])
@token_required
@role_required("admin")
def delete_dns_record(record_id):
    """åˆ é™¤DNSè®°å½•"""
    try:
        # è°ƒç”¨é˜¿é‡Œäº‘APIåˆ é™¤è®°å½•
        result = delete_aliyun_dns_record(record_id)
        
        log_operation(
            user_id=request.user_id,
            action="delete_dns_record",
            resource=record_id
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "message": "DNS record deleted successfully"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@ddns_bp.route('/manual-update', methods=['POST'])
@token_required
@role_required("admin")
@rate_limit("ddns")
def manual_ddns_update():
    """æ‰‹åŠ¨è§¦å‘DDNSæ›´æ–°"""
    force = request.args.get('force', 'false').lower() == 'true'
    
    try:
        # æ‰§è¡ŒDDNSæ›´æ–°è„šæœ¬
        result = run_ddns_update(force=force)
        
        log_operation(
            user_id=request.user_id,
            action="manual_ddns_update",
            resource="ddns",
            details={"force": force, "result": result}
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": result,
            "message": "DDNS update triggered successfully"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@ddns_bp.route('/history', methods=['GET'])
@token_required
def get_update_history():
    """è·å–DDNSæ›´æ–°å†å²"""
    try:
        # ä»æ—¥å¿—æ–‡ä»¶è¯»å–å†å²è®°å½•
        history = get_ddns_update_history(
            limit=request.args.get('limit', 100, type=int),
            offset=request.args.get('offset', 0, type=int)
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "history": history,
                "count": len(history)
            },
            "pagination": {
                "limit": request.args.get('limit', 100, type=int),
                "offset": request.args.get('offset', 0, type=int),
                "total": get_total_history_count()
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500
```

### 3.2 åŸŸåç®¡ç†API

```python
# api/v2/domains.py
from flask import Blueprint, request, jsonify

domains_bp = Blueprint('domains_v2', __name__, url_prefix='/api/v2/domains')

@domains_bp.route('', methods=['GET'])
@token_required
def list_domains():
    """åˆ—å‡ºæ‰€æœ‰ç®¡ç†çš„åŸŸå"""
    try:
        domains = get_managed_domains()
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "domains": domains,
                "count": len(domains)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@domains_bp.route('/<string:domain>/status', methods=['GET'])
@token_required
def get_domain_status(domain):
    """è·å–åŸŸåçŠ¶æ€"""
    try:
        # æ£€æŸ¥åŸŸåè§£æ
        resolution_status = check_domain_resolution(domain)
        
        # è·å–SSLè¯ä¹¦çŠ¶æ€
        ssl_status = check_ssl_certificate(domain)
        
        # è·å–WHOISä¿¡æ¯
        whois_info = get_whois_info(domain)
        
        # æ£€æŸ¥DNSè®°å½•
        dns_records = get_dns_records_for_domain(domain)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "domain": domain,
                "resolution": resolution_status,
                "ssl": ssl_status,
                "whois": whois_info,
                "dns_records": {
                    "count": len(dns_records),
                    "records": dns_records[:10]  # åªè¿”å›å‰10æ¡
                },
                "health_score": calculate_domain_health_score(
                    resolution_status, ssl_status, dns_records
                )
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@domains_bp.route('/<string:domain>/dnssec', methods=['GET'])
@token_required
@role_required("admin")
def get_dnssec_status(domain):
    """è·å–DNSSECçŠ¶æ€"""
    try:
        dnssec_status = check_dnssec_status(domain)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "domain": domain,
                "dnssec_enabled": dnssec_status.get("enabled", False),
                "status": dnssec_status.get("status"),
                "algorithm": dnssec_status.get("algorithm"),
                "digest": dnssec_status.get("digest"),
                "public_key": dnssec_status.get("public_key"),
                "flags": dnssec_status.get("flags")
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@domains_bp.route('/<string:domain>/transfer', methods=['POST'])
@token_required
@role_required("admin")
def initiate_domain_transfer(domain):
    """åˆå§‹åŒ–åŸŸåè½¬ç§»"""
    data = request.get_json()
    
    try:
        # éªŒè¯è½¬ç§»æˆæƒç 
        auth_code = data.get("auth_code")
        if not auth_code:
            return jsonify({
                "success": False,
                "error": "Authorization code is required"
            }), 400
        
        # å¯åŠ¨åŸŸåè½¬ç§»æµç¨‹
        transfer_result = initiate_domain_transfer_to_aliyun(domain, auth_code)
        
        log_operation(
            user_id=request.user_id,
            action="initiate_domain_transfer",
            resource=domain,
            details={"status": "initiated"}
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": transfer_result,
            "message": "Domain transfer initiated"
        }), 202
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500
```

## 4. **å¼€å‘ç¯å¢ƒAPI**

### 4.1 å¼€å‘å·¥å…·API

```python
# api/v2/dev/tools.py
from flask import Blueprint, request, jsonify

dev_bp = Blueprint('dev_v2', __name__, url_prefix='/api/v2/dev')

@dev_bp.route('/test-dns', methods=['POST'])
@api_key_required
@scope_required("dev:tools")
def test_dns_resolution():
    """æµ‹è¯•DNSè§£æï¼ˆå¼€å‘å·¥å…·ï¼‰"""
    data = request.get_json()
    
    domain = data.get('domain')
    record_type = data.get('type', 'A')
    nameserver = data.get('nameserver')
    
    if not domain:
        return jsonify({
            "success": False,
            "error": "Domain is required"
        }), 400
    
    try:
        results = []
        
        # æµ‹è¯•ä¸åŒè§£ææ–¹å¼
        if nameserver:
            # æŒ‡å®šDNSæœåŠ¡å™¨
            results.append({
                "method": "specific_nameserver",
                "nameserver": nameserver,
                "results": dns_query_with_nameserver(domain, record_type, nameserver)
            })
        
        # æµ‹è¯•å…¬å…±DNS
        public_dns_servers = [
            {"name": "Google", "server": "8.8.8.8"},
            {"name": "Cloudflare", "server": "1.1.1.1"},
            {"name": "OpenDNS", "server": "208.67.222.222"},
            {"name": "AliDNS", "server": "223.5.5.5"}
        ]
        
        for dns_server in public_dns_servers:
            try:
                results.append({
                    "method": "public_dns",
                    "name": dns_server["name"],
                    "server": dns_server["server"],
                    "results": dns_query_with_nameserver(domain, record_type, dns_server["server"])
                })
            except Exception as e:
                results.append({
                    "method": "public_dns",
                    "name": dns_server["name"],
                    "server": dns_server["server"],
                    "error": str(e)
                })
        
        # æµ‹è¯•æœ¬åœ°è§£æ
        try:
            results.append({
                "method": "local_resolver",
                "results": dns_query_local(domain, record_type)
            })
        except Exception as e:
            results.append({
                "method": "local_resolver",
                "error": str(e)
            })
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "domain": domain,
                "type": record_type,
                "tests": results,
                "summary": {
                    "total_tests": len(results),
                    "successful": len([r for r in results if "error" not in r]),
                    "failed": len([r for r in results if "error" in r])
                }
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@dev_bp.route('/trace-dns', methods=['POST'])
@api_key_required
@scope_required("dev:tools")
def trace_dns_resolution():
    """DNSè§£æè¿½è¸ªï¼ˆå¼€å‘å·¥å…·ï¼‰"""
    data = request.get_json()
    
    domain = data.get('domain')
    if not domain:
        return jsonify({
            "success": False,
            "error": "Domain is required"
        }), 400
    
    try:
        # æ‰§è¡ŒDNSè¿½è¸ª
        trace_results = perform_dns_trace(domain)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "domain": domain,
                "trace": trace_results,
                "analysis": analyze_dns_trace(trace_results)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@dev_bp.route('/validate-config', methods=['POST'])
@api_key_required
@scope_required("dev:tools")
def validate_configuration():
    """éªŒè¯é…ç½®æ–‡ä»¶ï¼ˆå¼€å‘å·¥å…·ï¼‰"""
    data = request.get_json()
    
    config_content = data.get('config')
    config_type = data.get('type', 'yaml')
    
    if not config_content:
        return jsonify({
            "success": False,
            "error": "Config content is required"
        }), 400
    
    try:
        validation_results = []
        
        # YAMLéªŒè¯
        if config_type == 'yaml':
            try:
                import yaml
                parsed = yaml.safe_load(config_content)
                validation_results.append({
                    "type": "yaml_syntax",
                    "valid": True,
                    "message": "YAML syntax is valid"
                })
                
                # æ£€æŸ¥å¿…è¦å­—æ®µ
                required_fields = ['domain', 'aliyun']
                missing = []
                for field in required_fields:
                    if field not in parsed:
                        missing.append(field)
                
                if missing:
                    validation_results.append({
                        "type": "required_fields",
                        "valid": False,
                        "message": f"Missing required fields: {', '.join(missing)}"
                    })
                else:
                    validation_results.append({
                        "type": "required_fields",
                        "valid": True,
                        "message": "All required fields present"
                    })
                
            except yaml.YAMLError as e:
                validation_results.append({
                    "type": "yaml_syntax",
                    "valid": False,
                    "message": str(e)
                })
        
        # JSONéªŒè¯
        elif config_type == 'json':
            try:
                import json
                parsed = json.loads(config_content)
                validation_results.append({
                    "type": "json_syntax",
                    "valid": True,
                    "message": "JSON syntax is valid"
                })
            except json.JSONDecodeError as e:
                validation_results.append({
                    "type": "json_syntax",
                    "valid": False,
                    "message": str(e)
                })
        
        # æµ‹è¯•é˜¿é‡Œäº‘å‡­æ®
        if 'aliyun' in locals().get('parsed', {}):
            try:
                test_aliyun_credentials(parsed['aliyun'])
                validation_results.append({
                    "type": "aliyun_credentials",
                    "valid": True,
                    "message": "Aliyun credentials are valid"
                })
            except Exception as e:
                validation_results.append({
                    "type": "aliyun_credentials",
                    "valid": False,
                    "message": f"Aliyun credentials error: {str(e)}"
                })
        
        # æ€»ä½“è¯„ä¼°
        is_valid = all(r["valid"] for r in validation_results)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "config_type": config_type,
                "valid": is_valid,
                "validations": validation_results,
                "summary": {
                    "total_checks": len(validation_results),
                    "passed": len([r for r in validation_results if r["valid"]]),
                    "failed": len([r for r in validation_results if not r["valid"]])
                }
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@dev_bp.route('/simulate-dns', methods=['POST'])
@api_key_required
@scope_required("dev:tools")
def simulate_dns_update():
    """æ¨¡æ‹ŸDNSæ›´æ–°ï¼ˆå¼€å‘å·¥å…·ï¼‰"""
    data = request.get_json()
    
    domain = data.get('domain')
    subdomain = data.get('subdomain', '@')
    new_ip = data.get('new_ip')
    
    if not domain or not new_ip:
        return jsonify({
            "success": False,
            "error": "Domain and new_ip are required"
        }), 400
    
    try:
        # æ¨¡æ‹ŸDNSæ›´æ–°æµç¨‹
        simulation_results = simulate_dns_update_process(
            domain=domain,
            subdomain=subdomain,
            new_ip=new_ip
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": simulation_results,
            "note": "This is a simulation. No actual DNS records were modified."
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500
```

### 4.2 è°ƒè¯•ä¸æ—¥å¿—API

```python
# api/v2/dev/debug.py
from flask import Blueprint, request, jsonify

debug_bp = Blueprint('debug_v2', __name__, url_prefix='/api/v2/debug')

@debug_bp.route('/logs', methods=['GET'])
@token_required
@role_required("admin")
def get_debug_logs():
    """è·å–è°ƒè¯•æ—¥å¿—"""
    log_type = request.args.get('type', 'ddns')
    lines = request.args.get('lines', 100, type=int)
    level = request.args.get('level')
    search = request.args.get('search')
    
    try:
        logs = fetch_debug_logs(
            log_type=log_type,
            lines=lines,
            level=level,
            search_term=search
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "log_type": log_type,
                "lines": lines,
                "total_entries": len(logs),
                "logs": logs
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@debug_bp.route('/metrics/current', methods=['GET'])
@token_required
@role_required("admin")
def get_current_metrics():
    """è·å–å½“å‰ç³»ç»ŸæŒ‡æ ‡"""
    try:
        metrics = collect_system_metrics()
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": metrics
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@debug_bp.route('/metrics/historical', methods=['GET'])
@token_required
@role_required("admin")
def get_historical_metrics():
    """è·å–å†å²ç³»ç»ŸæŒ‡æ ‡"""
    time_range = request.args.get('range', '1h')
    resolution = request.args.get('resolution', '1m')
    
    try:
        metrics = fetch_historical_metrics(
            time_range=time_range,
            resolution=resolution
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "time_range": time_range,
                "resolution": resolution,
                "metrics": metrics
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@debug_bp.route('/api-calls', methods=['GET'])
@token_required
@role_required("admin")
def get_api_call_statistics():
    """è·å–APIè°ƒç”¨ç»Ÿè®¡"""
    try:
        stats = get_api_statistics(
            period=request.args.get('period', '24h'),
            endpoint=request.args.get('endpoint'),
            user_id=request.args.get('user_id')
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": stats
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@debug_bp.route('/cache/status', methods=['GET'])
@token_required
@role_required("admin")
def get_cache_status():
    """è·å–ç¼“å­˜çŠ¶æ€"""
    try:
        cache_stats = get_cache_statistics()
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": cache_stats
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@debug_bp.route('/cache/clear', methods=['POST'])
@token_required
@role_required("admin")
def clear_cache():
    """æ¸…é™¤ç¼“å­˜"""
    cache_type = request.args.get('type', 'all')
    
    try:
        result = clear_system_cache(cache_type)
        
        log_operation(
            user_id=request.user_id,
            action="clear_cache",
            resource="cache",
            details={"type": cache_type}
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": result,
            "message": f"Cache cleared: {cache_type}"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500
```

## 5. **ç”Ÿäº§ç¯å¢ƒAPI**

### 5.1 é«˜å¯ç”¨æ€§API

```python
# api/v2/production/ha.py
from flask import Blueprint, request, jsonify
import threading
import time

ha_bp = Blueprint('ha_v2', __name__, url_prefix='/api/v2/ha')

@ha_bp.route('/status', methods=['GET'])
@api_key_required
@scope_required("production:monitor")
def get_ha_status():
    """è·å–é«˜å¯ç”¨æ€§çŠ¶æ€"""
    try:
        # æ£€æŸ¥æ‰€æœ‰æœåŠ¡å®ä¾‹
        instances = get_service_instances()
        
        # æ£€æŸ¥è´Ÿè½½å‡è¡¡å™¨çŠ¶æ€
        lb_status = get_load_balancer_status()
        
        # æ£€æŸ¥æ•°æ®åº“å¤åˆ¶çŠ¶æ€
        db_replication = get_database_replication_status()
        
        # æ£€æŸ¥å­˜å‚¨å†—ä½™
        storage_redundancy = get_storage_redundancy_status()
        
        # è®¡ç®—æ•´ä½“å¥åº·åº¦
        overall_health = calculate_ha_health_score(
            instances, lb_status, db_replication, storage_redundancy
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "overall_health": overall_health,
                "status": "healthy" if overall_health >= 0.9 else "degraded",
                "instances": instances,
                "load_balancer": lb_status,
                "database": db_replication,
                "storage": storage_redundancy,
                "recommendations": generate_ha_recommendations(
                    instances, lb_status, db_replication, storage_redundancy
                )
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@ha_bp.route('/failover', methods=['POST'])
@api_key_required
@scope_required("production:admin")
def initiate_failover():
    """å¯åŠ¨æ•…éšœè½¬ç§»"""
    data = request.get_json()
    
    target_instance = data.get('target_instance')
    reason = data.get('reason', 'manual')
    
    try:
        # éªŒè¯ç›®æ ‡å®ä¾‹
        if not validate_target_instance(target_instance):
            return jsonify({
                "success": False,
                "error": f"Invalid target instance: {target_instance}"
            }), 400
        
        # æ‰§è¡Œæ•…éšœè½¬ç§»
        failover_result = perform_failover(
            target_instance=target_instance,
            reason=reason
        )
        
        # è®°å½•æ•…éšœè½¬ç§»
        log_failover_event(
            user_id=request.key_info["user_id"],
            from_instance=get_current_primary(),
            to_instance=target_instance,
            reason=reason,
            result=failover_result
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": failover_result,
            "message": f"Failover to {target_instance} completed"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@ha_bp.route('/backup/status', methods=['GET'])
@api_key_required
@scope_required("production:monitor")
def get_backup_status():
    """è·å–å¤‡ä»½çŠ¶æ€"""
    try:
        backup_status = get_backup_status_info()
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": backup_status
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@ha_bp.route('/backup/now', methods=['POST'])
@api_key_required
@scope_required("production:admin")
def trigger_backup_now():
    """ç«‹å³è§¦å‘å¤‡ä»½"""
    backup_type = request.args.get('type', 'full')
    
    try:
        # å¼‚æ­¥æ‰§è¡Œå¤‡ä»½
        backup_job_id = trigger_immediate_backup(backup_type)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "job_id": backup_job_id,
                "type": backup_type,
                "status": "started",
                "message": "Backup job started"
            }
        }), 202
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@ha_bp.route('/recovery/test', methods=['POST'])
@api_key_required
@scope_required("production:admin")
def test_recovery():
    """æµ‹è¯•æ¢å¤æµç¨‹"""
    data = request.get_json()
    
    backup_id = data.get('backup_id')
    target_environment = data.get('target_environment', 'staging')
    
    try:
        # åœ¨æµ‹è¯•ç¯å¢ƒä¸­æ‰§è¡Œæ¢å¤
        recovery_result = perform_recovery_test(
            backup_id=backup_id,
            target_environment=target_environment
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": recovery_result,
            "message": "Recovery test completed"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500
```

### 5.2 æ€§èƒ½ç›‘æ§API

```python
# api/v2/production/performance.py
from flask import Blueprint, request, jsonify
from datetime import datetime, timedelta

perf_bp = Blueprint('performance_v2', __name__, url_prefix='/api/v2/performance')

@perf_bp.route('/dashboard', methods=['GET'])
@api_key_required
@scope_required("production:monitor")
def get_performance_dashboard():
    """è·å–æ€§èƒ½ä»ªè¡¨æ¿æ•°æ®"""
    time_range = request.args.get('range', '1h')
    
    try:
        # æ”¶é›†å„ç§æ€§èƒ½æŒ‡æ ‡
        metrics = {
            "system": get_system_performance_metrics(time_range),
            "api": get_api_performance_metrics(time_range),
            "database": get_database_performance_metrics(time_range),
            "network": get_network_performance_metrics(time_range),
            "ddns": get_ddns_performance_metrics(time_range)
        }
        
        # è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ
        bottlenecks = identify_performance_bottlenecks(metrics)
        
        # ç”Ÿæˆå»ºè®®
        recommendations = generate_performance_recommendations(bottlenecks)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "time_range": time_range,
                "metrics": metrics,
                "summary": {
                    "overall_performance": calculate_overall_performance_score(metrics),
                    "bottlenecks": bottlenecks,
                    "recommendations": recommendations
                }
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@perf_bp.route('/endpoints', methods=['GET'])
@api_key_required
@scope_required("production:monitor")
def get_endpoint_performance():
    """è·å–APIç«¯ç‚¹æ€§èƒ½æ•°æ®"""
    endpoint = request.args.get('endpoint')
    time_range = request.args.get('range', '24h')
    
    try:
        if endpoint:
            # è·å–ç‰¹å®šç«¯ç‚¹çš„æ€§èƒ½æ•°æ®
            endpoint_data = get_endpoint_performance_data(endpoint, time_range)
        else:
            # è·å–æ‰€æœ‰ç«¯ç‚¹çš„æ€§èƒ½æ•°æ®
            endpoint_data = get_all_endpoints_performance(time_range)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": endpoint_data
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@perf_bp.route('/slow-queries', methods=['GET'])
@api_key_required
@scope_required("production:admin")
def get_slow_queries():
    """è·å–æ…¢æŸ¥è¯¢æ•°æ®"""
    limit = request.args.get('limit', 50, type=int)
    time_range = request.args.get('range', '24h')
    
    try:
        slow_queries = get_slow_query_data(limit, time_range)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "slow_queries": slow_queries,
                "analysis": analyze_slow_queries(slow_queries)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@perf_bp.route('/optimize', methods=['POST'])
@api_key_required
@scope_required("production:admin")
def run_optimization():
    """è¿è¡Œæ€§èƒ½ä¼˜åŒ–"""
    optimization_type = request.args.get('type', 'all')
    
    try:
        # æ‰§è¡Œä¼˜åŒ–
        optimization_result = perform_performance_optimization(optimization_type)
        
        # è®°å½•ä¼˜åŒ–æ“ä½œ
        log_optimization_event(
            user_id=request.key_info["user_id"],
            type=optimization_type,
            result=optimization_result
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": optimization_result,
            "message": f"Performance optimization '{optimization_type}' completed"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@perf_bp.route('/capacity', methods=['GET'])
@api_key_required
@scope_required("production:admin")
def get_capacity_planning():
    """è·å–å®¹é‡è§„åˆ’æ•°æ®"""
    try:
        capacity_data = get_capacity_planning_data()
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": capacity_data
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500
```

## 6. **ç›‘æ§ä¸å‘Šè­¦API**

### 6.1 å®æ—¶ç›‘æ§API

```python
# api/v2/monitoring/real_time.py
from flask import Blueprint, request, jsonify
import psutil
import socket

monitor_bp = Blueprint('monitoring_v2', __name__, url_prefix='/api/v2/monitoring')

@monitor_bp.route('/system', methods=['GET'])
@api_key_required
@scope_required("monitoring:read")
def get_system_monitoring():
    """è·å–ç³»ç»Ÿå®æ—¶ç›‘æ§æ•°æ®"""
    metrics = request.args.get('metrics', 'all')
    
    try:
        monitoring_data = {}
        
        if metrics in ['all', 'cpu']:
            monitoring_data['cpu'] = {
                "percent": psutil.cpu_percent(interval=1),
                "percent_per_core": psutil.cpu_percent(interval=1, percpu=True),
                "load_average": psutil.getloadavg() if hasattr(psutil, 'getloadavg') else None,
                "frequency": psutil.cpu_freq().current if hasattr(psutil.cpu_freq(), 'current') else None
            }
        
        if metrics in ['all', 'memory']:
            memory = psutil.virtual_memory()
            monitoring_data['memory'] = {
                "total": memory.total,
                "available": memory.available,
                "percent": memory.percent,
                "used": memory.used,
                "free": memory.free,
                "buffers": getattr(memory, 'buffers', 0),
                "cached": getattr(memory, 'cached', 0)
            }
        
        if metrics in ['all', 'disk']:
            disk = psutil.disk_usage('/')
            monitoring_data['disk'] = {
                "total": disk.total,
                "used": disk.used,
                "free": disk.free,
                "percent": disk.percent
            }
            
            # IOç»Ÿè®¡
            disk_io = psutil.disk_io_counters()
            if disk_io:
                monitoring_data['disk_io'] = {
                    "read_count": disk_io.read_count,
                    "write_count": disk_io.write_count,
                    "read_bytes": disk_io.read_bytes,
                    "write_bytes": disk_io.write_bytes
                }
        
        if metrics in ['all', 'network']:
            net_io = psutil.net_io_counters()
            if net_io:
                monitoring_data['network'] = {
                    "bytes_sent": net_io.bytes_sent,
                    "bytes_recv": net_io.bytes_recv,
                    "packets_sent": net_io.packets_sent,
                    "packets_recv": net_io.packets_recv,
                    "interfaces": get_network_interfaces_stats()
                }
        
        if metrics in ['all', 'processes']:
            processes = []
            for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
                try:
                    processes.append(proc.info)
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    pass
            
            monitoring_data['processes'] = {
                "total": len(processes),
                "top_cpu": sorted(processes, key=lambda x: x.get('cpu_percent', 0), reverse=True)[:10],
                "top_memory": sorted(processes, key=lambda x: x.get('memory_percent', 0), reverse=True)[:10]
            }
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": monitoring_data,
            "metadata": {
                "hostname": socket.gethostname(),
                "uptime": get_system_uptime()
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@monitor_bp.route('/services', methods=['GET'])
@api_key_required
@scope_required("monitoring:read")
def get_services_status():
    """è·å–æœåŠ¡çŠ¶æ€"""
    service_name = request.args.get('service')
    
    try:
        if service_name:
            # è·å–ç‰¹å®šæœåŠ¡çŠ¶æ€
            service_status = get_service_status(service_name)
            services_data = {service_name: service_status}
        else:
            # è·å–æ‰€æœ‰æœåŠ¡çŠ¶æ€
            services_data = get_all_services_status()
        
        # è®¡ç®—æ€»ä½“å¥åº·çŠ¶æ€
        healthy_services = sum(1 for s in services_data.values() if s.get('status') == 'running')
        total_services = len(services_data)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "services": services_data,
                "summary": {
                    "total": total_services,
                    "healthy": healthy_services,
                    "unhealthy": total_services - healthy_services,
                    "health_percentage": (healthy_services / total_services * 100) if total_services > 0 else 0
                }
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@monitor_bp.route('/dns/health', methods=['GET'])
@api_key_required
@scope_required("monitoring:read")
def get_dns_health():
    """è·å–DNSå¥åº·çŠ¶æ€"""
    domain = request.args.get('domain', 'ddns.0379.email')
    
    try:
        dns_health_data = check_dns_health(domain)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": dns_health_data
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@monitor_bp.route('/web/health', methods=['GET'])
@api_key_required
@scope_required("monitoring:read")
def get_web_health():
    """è·å–WebæœåŠ¡å¥åº·çŠ¶æ€"""
    url = request.args.get('url', 'https://ddns.0379.email')
    
    try:
        web_health_data = check_web_health(url)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": web_health_data
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500
```

### 6.2 å‘Šè­¦ç®¡ç†API

```python
# api/v2/alerts/management.py
from flask import Blueprint, request, jsonify

alerts_bp = Blueprint('alerts_v2', __name__, url_prefix='/api/v2/alerts')

@alerts_bp.route('', methods=['GET'])
@api_key_required
@scope_required("alerts:read")
def get_alerts():
    """è·å–å‘Šè­¦åˆ—è¡¨"""
    status = request.args.get('status', 'active')  # active, resolved, all
    severity = request.args.get('severity')  # critical, warning, info
    limit = request.args.get('limit', 100, type=int)
    offset = request.args.get('offset', 0, type=int)
    
    try:
        alerts = get_alert_list(
            status=status,
            severity=severity,
            limit=limit,
            offset=offset
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "alerts": alerts,
                "count": len(alerts),
                "summary": {
                    "total": get_total_alert_count(),
                    "active": get_active_alert_count(),
                    "critical": get_critical_alert_count()
                }
            },
            "pagination": {
                "limit": limit,
                "offset": offset,
                "total": get_total_alert_count()
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@alerts_bp.route('/<string:alert_id>', methods=['GET'])
@api_key_required
@scope_required("alerts:read")
def get_alert_details(alert_id):
    """è·å–å‘Šè­¦è¯¦æƒ…"""
    try:
        alert_details = get_alert_by_id(alert_id)
        
        if not alert_details:
            return jsonify({
                "success": False,
                "error": f"Alert {alert_id} not found"
            }), 404
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": alert_details
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@alerts_bp.route('/<string:alert_id>/resolve', methods=['POST'])
@api_key_required
@scope_required("alerts:write")
def resolve_alert(alert_id):
    """è§£å†³å‘Šè­¦"""
    data = request.get_json()
    resolution_notes = data.get('resolution_notes', '')
    
    try:
        result = resolve_alert_by_id(alert_id, resolution_notes)
        
        if not result:
            return jsonify({
                "success": False,
                "error": f"Alert {alert_id} not found or already resolved"
            }), 404
        
        # è®°å½•è§£å†³æ“ä½œ
        log_alert_resolution(
            alert_id=alert_id,
            user_id=request.key_info["user_id"],
            resolution_notes=resolution_notes
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": result,
            "message": f"Alert {alert_id} resolved"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@alerts_bp.route('/rules', methods=['GET'])
@api_key_required
@scope_required("alerts:read")
def get_alert_rules():
    """è·å–å‘Šè­¦è§„åˆ™"""
    try:
        rules = get_alert_rules_list()
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "rules": rules,
                "count": len(rules)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@alerts_bp.route('/rules', methods=['POST'])
@api_key_required
@scope_required("alerts:admin")
def create_alert_rule():
    """åˆ›å»ºå‘Šè­¦è§„åˆ™"""
    data = request.get_json()
    
    # éªŒè¯è§„åˆ™æ•°æ®
    required_fields = ["name", "condition", "severity", "notification_channels"]
    missing = [field for field in required_fields if field not in data]
    if missing:
        return jsonify({
            "success": False,
            "error": f"Missing required fields: {', '.join(missing)}"
        }), 400
    
    try:
        rule = create_alert_rule(data)
        
        # è®°å½•è§„åˆ™åˆ›å»º
        log_alert_rule_creation(
            rule_id=rule["id"],
            user_id=request.key_info["user_id"],
            rule_data=data
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": rule,
            "message": "Alert rule created"
        }), 201
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@alerts_bp.route('/notifications', methods=['GET'])
@api_key_required
@scope_required("alerts:read")
def get_notifications():
    """è·å–é€šçŸ¥å†å²"""
    limit = request.args.get('limit', 50, type=int)
    channel = request.args.get('channel')
    status = request.args.get('status')  # sent, failed
    
    try:
        notifications = get_notification_history(
            limit=limit,
            channel=channel,
            status=status
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "notifications": notifications,
                "summary": {
                    "total": get_total_notification_count(),
                    "sent": get_sent_notification_count(),
                    "failed": get_failed_notification_count()
                }
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@alerts_bp.route('/silence', methods=['POST'])
@api_key_required
@scope_required("alerts:admin")
def create_silence():
    """åˆ›å»ºé™é»˜è§„åˆ™"""
    data = request.get_json()
    
    required_fields = ["matchers", "starts_at", "ends_at"]
    missing = [field for field in required_fields if field not in data]
    if missing:
        return jsonify({
            "success": False,
            "error": f"Missing required fields: {', '.join(missing)}"
        }), 400
    
    try:
        silence = create_alert_silence(data)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": silence,
            "message": "Alert silence created"
        }), 201
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500
```

## 7. **é…ç½®ç®¡ç†API**

### 7.1 é…ç½®ä¸­å¿ƒAPI

```python
# api/v2/config/center.py
from flask import Blueprint, request, jsonify
import yaml
import json

config_bp = Blueprint('config_v2', __name__, url_prefix='/api/v2/config')

@config_bp.route('', methods=['GET'])
@token_required
@role_required("config:read")
def get_configurations():
    """è·å–é…ç½®åˆ—è¡¨"""
    environment = request.args.get('environment')
    service = request.args.get('service')
    version = request.args.get('version')
    
    try:
        configs = list_configurations(
            environment=environment,
            service=service,
            version=version
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "configurations": configs,
                "count": len(configs)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@config_bp.route('/<string:config_id>', methods=['GET'])
@token_required
@role_required("config:read")
def get_configuration(config_id):
    """è·å–é…ç½®è¯¦æƒ…"""
    include_secrets = request.args.get('include_secrets', 'false').lower() == 'true'
    version = request.args.get('version', 'latest')
    
    try:
        config = get_configuration_by_id(config_id, version, include_secrets)
        
        if not config:
            return jsonify({
                "success": False,
                "error": f"Configuration {config_id} not found"
            }), 404
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": config
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@config_bp.route('', methods=['POST'])
@token_required
@role_required("config:write")
def create_configuration():
    """åˆ›å»ºé…ç½®"""
    data = request.get_json()
    
    required_fields = ["name", "environment", "service", "config"]
    missing = [field for field in required_fields if field not in data]
    if missing:
        return jsonify({
            "success": False,
            "error": f"Missing required fields: {', '.join(missing)}"
        }), 400
    
    try:
        # éªŒè¯é…ç½®æ ¼å¼
        if not validate_config_format(data["config"]):
            return jsonify({
                "success": False,
                "error": "Invalid configuration format"
            }), 400
        
        # åˆ›å»ºé…ç½®
        config = create_configuration_entry(data)
        
        # è®°å½•é…ç½®åˆ›å»º
        log_configuration_change(
            action="create",
            config_id=config["id"],
            user_id=request.user_id,
            environment=data["environment"],
            service=data["service"]
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": config,
            "message": "Configuration created"
        }), 201
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@config_bp.route('/<string:config_id>', methods=['PUT'])
@token_required
@role_required("config:write")
def update_configuration(config_id):
    """æ›´æ–°é…ç½®"""
    data = request.get_json()
    
    if "config" not in data:
        return jsonify({
            "success": False,
            "error": "Config data is required"
        }), 400
    
    try:
        # éªŒè¯é…ç½®æ ¼å¼
        if not validate_config_format(data["config"]):
            return jsonify({
                "success": False,
                "error": "Invalid configuration format"
            }), 400
        
        # æ›´æ–°é…ç½®
        config = update_configuration_entry(config_id, data)
        
        if not config:
            return jsonify({
                "success": False,
                "error": f"Configuration {config_id} not found"
            }), 404
        
        # è®°å½•é…ç½®æ›´æ–°
        log_configuration_change(
            action="update",
            config_id=config_id,
            user_id=request.user_id,
            environment=config.get("environment"),
            service=config.get("service")
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": config,
            "message": "Configuration updated"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@config_bp.route('/<string:config_id>/rollback', methods=['POST'])
@token_required
@role_required("config:admin")
def rollback_configuration(config_id):
    """å›æ»šé…ç½®"""
    data = request.get_json()
    
    version = data.get('version')
    if not version:
        return jsonify({
            "success": False,
            "error": "Version is required"
        }), 400
    
    try:
        config = rollback_configuration_to_version(config_id, version)
        
        if not config:
            return jsonify({
                "success": False,
                "error": f"Configuration {config_id} version {version} not found"
            }), 404
        
        # è®°å½•é…ç½®å›æ»š
        log_configuration_change(
            action="rollback",
            config_id=config_id,
            user_id=request.user_id,
            environment=config.get("environment"),
            service=config.get("service"),
            version=version
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": config,
            "message": f"Configuration rolled back to version {version}"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@config_bp.route('/<string:config_id>/diff', methods=['GET'])
@token_required
@role_required("config:read")
def diff_configuration(config_id):
    """å¯¹æ¯”é…ç½®ç‰ˆæœ¬"""
    version1 = request.args.get('v1', 'latest')
    version2 = request.args.get('v2')
    
    try:
        diff_result = diff_configuration_versions(config_id, version1, version2)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": diff_result
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@config_bp.route('/<string:config_id>/history', methods=['GET'])
@token_required
@role_required("config:read")
def get_configuration_history(config_id):
    """è·å–é…ç½®å†å²"""
    limit = request.args.get('limit', 50, type=int)
    
    try:
        history = get_configuration_history_list(config_id, limit)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "config_id": config_id,
                "history": history,
                "total_versions": len(history)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@config_bp.route('/templates', methods=['GET'])
@token_required
@role_required("config:read")
def get_config_templates():
    """è·å–é…ç½®æ¨¡æ¿"""
    template_type = request.args.get('type')
    
    try:
        templates = get_configuration_templates(template_type)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "templates": templates,
                "count": len(templates)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@config_bp.route('/validate', methods=['POST'])
@token_required
@role_required("config:read")
def validate_configuration():
    """éªŒè¯é…ç½®"""
    data = request.get_json()
    
    config_content = data.get('config')
    config_type = data.get('type', 'yaml')
    template_id = data.get('template_id')
    
    if not config_content:
        return jsonify({
            "success": False,
            "error": "Config content is required"
        }), 400
    
    try:
        validation_result = validate_configuration_content(
            content=config_content,
            config_type=config_type,
            template_id=template_id
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": validation_result
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500
```

### 7.2 å¯†é’¥ç®¡ç†API

```python
# api/v2/secrets/manager.py
from flask import Blueprint, request, jsonify
from cryptography.fernet import Fernet
import base64
import os

secrets_bp = Blueprint('secrets_v2', __name__, url_prefix='/api/v2/secrets')

class SecretsManager:
    def __init__(self):
        self.key_file = "/opt/yyc3/secrets/master.key"
        self.load_or_generate_key()
    
    def load_or_generate_key(self):
        """åŠ è½½æˆ–ç”Ÿæˆä¸»å¯†é’¥"""
        if os.path.exists(self.key_file):
            with open(self.key_file, 'rb') as f:
                self.master_key = f.read()
        else:
            self.master_key = Fernet.generate_key()
            os.makedirs(os.path.dirname(self.key_file), exist_ok=True)
            with open(self.key_file, 'wb') as f:
                f.write(self.master_key)
        
        self.cipher = Fernet(self.master_key)
    
    def encrypt_secret(self, plaintext):
        """åŠ å¯†ç§˜å¯†"""
        return self.cipher.encrypt(plaintext.encode()).decode()
    
    def decrypt_secret(self, ciphertext):
        """è§£å¯†ç§˜å¯†"""
        return self.cipher.decrypt(ciphertext.encode()).decode()
    
    def rotate_key(self):
        """è½®æ¢ä¸»å¯†é’¥"""
        # å¤‡ä»½æ—§å¯†é’¥
        old_key = self.master_key
        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
        backup_file = f"{self.key_file}.backup.{timestamp}"
        
        with open(backup_file, 'wb') as f:
            f.write(old_key)
        
        # ç”Ÿæˆæ–°å¯†é’¥
        new_key = Fernet.generate_key()
        self.master_key = new_key
        self.cipher = Fernet(new_key)
        
        with open(self.key_file, 'wb') as f:
            f.write(new_key)
        
        return {
            "old_key_backup": backup_file,
            "key_rotated": True,
            "timestamp": timestamp
        }

secrets_manager = SecretsManager()

@secrets_bp.route('', methods=['GET'])
@token_required
@role_required("secrets:read")
def list_secrets():
    """åˆ—å‡ºæ‰€æœ‰ç§˜å¯†"""
    namespace = request.args.get('namespace')
    tag = request.args.get('tag')
    
    try:
        secrets = list_secrets_data(namespace=namespace, tag=tag)
        
        # è§£å¯†ç§˜å¯†å€¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
        include_values = request.args.get('include_values', 'false').lower() == 'true'
        if include_values:
            for secret in secrets:
                if "value" in secret:
                    try:
                        secret["value"] = secrets_manager.decrypt_secret(secret["value"])
                    except:
                        secret["value"] = "[DECRYPTION_FAILED]"
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "secrets": secrets,
                "count": len(secrets),
                "namespaces": get_secret_namespaces()
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@secrets_bp.route('', methods=['POST'])
@token_required
@role_required("secrets:write")
def create_secret():
    """åˆ›å»ºç§˜å¯†"""
    data = request.get_json()
    
    required_fields = ["key", "value", "namespace"]
    missing = [field for field in required_fields if field not in data]
    if missing:
        return jsonify({
            "success": False,
            "error": f"Missing required fields: {', '.join(missing)}"
        }), 400
    
    try:
        # åŠ å¯†ç§˜å¯†å€¼
        encrypted_value = secrets_manager.encrypt_secret(data["value"])
        
        secret_data = {
            "key": data["key"],
            "value": encrypted_value,
            "namespace": data["namespace"],
            "description": data.get("description"),
            "tags": data.get("tags", []),
            "created_by": request.user_id
        }
        
        secret = create_secret_entry(secret_data)
        
        # è®°å½•ç§˜å¯†åˆ›å»º
        log_secret_operation(
            action="create",
            secret_key=data["key"],
            namespace=data["namespace"],
            user_id=request.user_id
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "key": secret["key"],
                "namespace": secret["namespace"],
                "created_at": secret["created_at"],
                "message": "Secret created successfully"
            }
        }), 201
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@secrets_bp.route('/<string:namespace>/<string:key>', methods=['GET'])
@token_required
@role_required("secrets:read")
def get_secret(namespace, key):
    """è·å–ç§˜å¯†"""
    try:
        secret = get_secret_entry(namespace, key)
        
        if not secret:
            return jsonify({
                "success": False,
                "error": f"Secret {namespace}/{key} not found"
            }), 404
        
        # è§£å¯†å€¼
        decrypted_value = secrets_manager.decrypt_secret(secret["value"])
        
        # è®°å½•è®¿é—®
        log_secret_access(
            secret_key=key,
            namespace=namespace,
            user_id=request.user_id
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "key": secret["key"],
                "namespace": secret["namespace"],
                "value": decrypted_value,
                "description": secret.get("description"),
                "tags": secret.get("tags", []),
                "created_at": secret["created_at"],
                "updated_at": secret.get("updated_at"),
                "created_by": secret.get("created_by"),
                "access_count": secret.get("access_count", 0) + 1
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@secrets_bp.route('/key/rotate', methods=['POST'])
@token_required
@role_required("secrets:admin")
def rotate_master_key():
    """è½®æ¢ä¸»å¯†é’¥"""
    try:
        result = secrets_manager.rotate_key()
        
        # è®°å½•å¯†é’¥è½®æ¢
        log_secret_operation(
            action="key_rotate",
            user_id=request.user_id,
            details=result
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": result,
            "message": "Master key rotated successfully"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@secrets_bp.route('/access/logs', methods=['GET'])
@token_required
@role_required("secrets:admin")
def get_secret_access_logs():
    """è·å–ç§˜å¯†è®¿é—®æ—¥å¿—"""
    limit = request.args.get('limit', 100, type=int)
    namespace = request.args.get('namespace')
    key = request.args.get('key')
    user_id = request.args.get('user_id')
    
    try:
        logs = get_secret_access_logs_data(
            limit=limit,
            namespace=namespace,
            key=key,
            user_id=user_id
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "logs": logs,
                "count": len(logs),
                "summary": get_secret_access_summary()
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@secrets_bp.route('/sync', methods=['POST'])
@token_required
@role_required("secrets:admin")
def sync_secrets():
    """åŒæ­¥ç§˜å¯†åˆ°å…¶ä»–ç¯å¢ƒ"""
    data = request.get_json()
    
    source_env = data.get('source_environment')
    target_env = data.get('target_environment')
    namespace = data.get('namespace')
    
    if not source_env or not target_env:
        return jsonify({
            "success": False,
            "error": "Source and target environments are required"
        }), 400
    
    try:
        sync_result = sync_secrets_between_environments(
            source_env=source_env,
            target_env=target_env,
            namespace=namespace
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": sync_result,
            "message": f"Secrets synced from {source_env} to {target_env}"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500
```

## 8. **æ•°æ®åˆ†æAPI**

### 8.1 ç»Ÿè®¡ä¸åˆ†æAPI

```python
# api/v2/analytics/stats.py
from flask import Blueprint, request, jsonify
from datetime import datetime, timedelta

analytics_bp = Blueprint('analytics_v2', __name__, url_prefix='/api/v2/analytics')

@analytics_bp.route('/usage', methods=['GET'])
@token_required
@role_required("analytics:read")
def get_usage_statistics():
    """è·å–ä½¿ç”¨ç»Ÿè®¡"""
    period = request.args.get('period', '7d')  # 1d, 7d, 30d, 90d
    metric = request.args.get('metric', 'requests')  # requests, errors, latency, bandwidth
    
    try:
        stats = get_usage_statistics_data(period, metric)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "period": period,
                "metric": metric,
                "statistics": stats,
                "summary": calculate_usage_summary(stats)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@analytics_bp.route('/performance', methods=['GET'])
@token_required
@role_required("analytics:read")
def get_performance_analytics():
    """è·å–æ€§èƒ½åˆ†æ"""
    time_range = request.args.get('range', '24h')
    endpoint = request.args.get('endpoint')
    
    try:
        analytics = get_performance_analytics_data(time_range, endpoint)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "time_range": time_range,
                "endpoint": endpoint,
                "analytics": analytics,
                "insights": extract_performance_insights(analytics)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@analytics_bp.route('/ddns/history', methods=['GET'])
@token_required
@role_required("analytics:read")
def get_ddns_analytics():
    """è·å–DDNSåˆ†ææ•°æ®"""
    days = request.args.get('days', 30, type=int)
    
    try:
        analytics = get_ddns_analytics_data(days)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "period_days": days,
                "analytics": analytics,
                "trends": analyze_ddns_trends(analytics)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@analytics_bp.route('/users', methods=['GET'])
@token_required
@role_required("analytics:admin")
def get_user_analytics():
    """è·å–ç”¨æˆ·åˆ†æ"""
    period = request.args.get('period', '30d')
    
    try:
        analytics = get_user_analytics_data(period)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "period": period,
                "analytics": analytics,
                "insights": extract_user_insights(analytics)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@analytics_bp.route('/predictive', methods=['GET'])
@token_required
@role_required("analytics:admin")
def get_predictive_analytics():
    """è·å–é¢„æµ‹åˆ†æ"""
    metric = request.args.get('metric', 'requests')
    horizon = request.args.get('horizon', '7d')  # é¢„æµ‹èŒƒå›´
    
    try:
        predictions = get_predictive_analytics_data(metric, horizon)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "metric": metric,
                "horizon": horizon,
                "predictions": predictions,
                "confidence": predictions.get("confidence", 0.95)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@analytics_bp.route('/reports/generate', methods=['POST'])
@token_required
@role_required("analytics:write")
def generate_analytics_report():
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    data = request.get_json()
    
    report_type = data.get('type', 'weekly')
    format_type = data.get('format', 'html')  # html, pdf, json
    
    try:
        report = generate_analytics_report_data(report_type, format_type)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "report_id": report["id"],
                "type": report_type,
                "format": format_type,
                "url": report.get("url"),
                "message": f"{report_type} report generated"
            }
        }), 202
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@analytics_bp.route('/export', methods=['POST'])
@token_required
@role_required("analytics:admin")
def export_analytics_data():
    """å¯¼å‡ºåˆ†ææ•°æ®"""
    data = request.get_json()
    
    metrics = data.get('metrics', ['requests', 'errors', 'latency'])
    start_date = data.get('start_date')
    end_date = data.get('end_date', datetime.utcnow().isoformat())
    format_type = data.get('format', 'csv')  # csv, json, excel
    
    try:
        export_result = export_analytics_data_to_file(
            metrics=metrics,
            start_date=start_date,
            end_date=end_date,
            format_type=format_type
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": export_result
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500
```

### 8.2 è¶‹åŠ¿ä¸é¢„æµ‹API

```python
# api/v2/analytics/trends.py
from flask import Blueprint, request, jsonify
import pandas as pd
from prophet import Prophet
import numpy as np

trends_bp = Blueprint('trends_v2', __name__, url_prefix='/api/v2/trends')

@trends_bp.route('/ddns/changes', methods=['GET'])
@token_required
@role_required("analytics:read")
def get_ddns_change_trends():
    """è·å–DDNSå˜æ›´è¶‹åŠ¿"""
    days = request.args.get('days', 90, type=int)
    
    try:
        # è·å–DDNSå˜æ›´å†å²æ•°æ®
        changes = get_ddns_change_history(days)
        
        # è½¬æ¢ä¸ºDataFrameè¿›è¡Œè¶‹åŠ¿åˆ†æ
        df = pd.DataFrame(changes)
        if not df.empty:
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df.set_index('timestamp', inplace=True)
            
            # æŒ‰å¤©èšåˆ
            daily_changes = df.resample('D').size()
            
            # è®¡ç®—è¶‹åŠ¿
            trend_data = {
                "daily_average": daily_changes.mean(),
                "weekly_pattern": detect_weekly_pattern(daily_changes),
                "trend_direction": calculate_trend_direction(daily_changes),
                "anomalies": detect_anomalies(daily_changes)
            }
        else:
            trend_data = {}
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "period_days": days,
                "total_changes": len(changes),
                "trend_analysis": trend_data,
                "raw_data": changes[:100]  # è¿”å›å‰100æ¡æ•°æ®
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@trends_bp.route('/ip/stability', methods=['GET'])
@token_required
@role_required("analytics:read")
def get_ip_stability_analysis():
    """è·å–IPç¨³å®šæ€§åˆ†æ"""
    days = request.args.get('days', 30, type=int)
    
    try:
        # è·å–IPå˜æ›´å†å²
        ip_history = get_ip_change_history(days)
        
        if not ip_history:
            return jsonify({
                "success": True,
                "timestamp": datetime.utcnow().isoformat(),
                "data": {
                    "period_days": days,
                    "message": "No IP change history available"
                }
            })
        
        # åˆ†æIPç¨³å®šæ€§
        stability_analysis = analyze_ip_stability(ip_history)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "period_days": days,
                "ip_history": ip_history,
                "stability_analysis": stability_analysis,
                "recommendations": generate_ip_stability_recommendations(stability_analysis)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@trends_bp.route('/forecast', methods=['POST'])
@token_required
@role_required("analytics:admin")
def generate_forecast():
    """ç”Ÿæˆé¢„æµ‹"""
    data = request.get_json()
    
    metric = data.get('metric', 'ddns_changes')
    periods = data.get('periods', 30)  # é¢„æµ‹æœªæ¥30ä¸ªå‘¨æœŸ
    confidence = data.get('confidence', 0.95)
    
    try:
        # è·å–å†å²æ•°æ®
        historical_data = get_historical_data_for_metric(metric)
        
        if len(historical_data) < 30:  # éœ€è¦è¶³å¤Ÿçš„æ•°æ®
            return jsonify({
                "success": False,
                "error": "Insufficient historical data for forecasting"
            }), 400
        
        # ä½¿ç”¨Prophetè¿›è¡Œé¢„æµ‹
        forecast = generate_prophet_forecast(
            historical_data=historical_data,
            periods=periods,
            confidence=confidence
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "metric": metric,
                "forecast_periods": periods,
                "confidence_interval": confidence,
                "forecast": forecast,
                "accuracy_metrics": calculate_forecast_accuracy(forecast)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@trends_bp.route('/seasonality', methods=['GET'])
@token_required
@role_required("analytics:read")
def analyze_seasonality():
    """åˆ†æå­£èŠ‚æ€§æ¨¡å¼"""
    metric = request.args.get('metric', 'api_requests')
    years = request.args.get('years', 2, type=int)
    
    try:
        seasonality_data = analyze_seasonal_patterns(metric, years)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "metric": metric,
                "analysis_period_years": years,
                "seasonality_analysis": seasonality_data,
                "detected_patterns": extract_seasonal_patterns(seasonality_data)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@trends_bp.route('/correlation', methods=['GET'])
@token_required
@role_required("analytics:admin")
def analyze_correlations():
    """åˆ†æç›¸å…³æ€§"""
    metrics = request.args.getlist('metrics')  # å¯ä»¥ä¼ å…¥å¤šä¸ªæŒ‡æ ‡
    
    if not metrics or len(metrics) < 2:
        return jsonify({
            "success": False,
            "error": "At least two metrics are required for correlation analysis"
        }), 400
    
    try:
        correlation_matrix = calculate_correlation_matrix(metrics)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "metrics": metrics,
                "correlation_matrix": correlation_matrix,
                "strong_correlations": identify_strong_correlations(correlation_matrix)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500
```

## 9. **WebSocketå®æ—¶API**

### 9.1 å®æ—¶é€šçŸ¥ä¸äº‹ä»¶

```python
# api/websocket/events.py
from flask import Flask
from flask_socketio import SocketIO, emit, join_room, leave_room
import json
import asyncio

socketio = SocketIO(cors_allowed_origins="*")

# å®¢æˆ·ç«¯è¿æ¥ç®¡ç†
connected_clients = {}
client_rooms = {}

@socketio.on('connect')
def handle_connect():
    """å¤„ç†å®¢æˆ·ç«¯è¿æ¥"""
    client_id = request.sid
    connected_clients[client_id] = {
        'connected_at': datetime.utcnow().isoformat(),
        'user_id': None,
        'roles': []
    }
    print(f"Client connected: {client_id}")
    
    emit('connected', {
        'status': 'connected',
        'client_id': client_id,
        'timestamp': datetime.utcnow().isoformat()
    })

@socketio.on('authenticate')
def handle_authentication(data):
    """å¤„ç†å®¢æˆ·ç«¯è®¤è¯"""
    client_id = request.sid
    token = data.get('token')
    
    try:
        # éªŒè¯JWTä»¤ç‰Œ
        payload = jwt_auth.verify_token(token)
        if payload:
            connected_clients[client_id]['user_id'] = payload['sub']
            connected_clients[client_id]['roles'] = payload.get('roles', [])
            
            # æ ¹æ®ç”¨æˆ·è§’è‰²åŠ å…¥ç›¸åº”æˆ¿é—´
            for role in payload.get('roles', []):
                join_room(f"role:{role}")
            
            # åŠ å…¥ç”¨æˆ·ä¸“å±æˆ¿é—´
            join_room(f"user:{payload['sub']}")
            
            emit('authenticated', {
                'success': True,
                'user_id': payload['sub'],
                'roles': payload.get('roles', []),
                'timestamp': datetime.utcnow().isoformat()
            })
        else:
            emit('authentication_error', {
                'success': False,
                'error': 'Invalid token'
            })
    except Exception as e:
        emit('authentication_error', {
            'success': False,
            'error': str(e)
        })

@socketio.on('subscribe')
def handle_subscription(data):
    """å¤„ç†è®¢é˜…è¯·æ±‚"""
    client_id = request.sid
    topics = data.get('topics', [])
    
    for topic in topics:
        # éªŒè¯è®¢é˜…æƒé™
        if can_subscribe_to_topic(client_id, topic):
            join_room(topic)
            if topic not in client_rooms:
                client_rooms[topic] = []
            client_rooms[topic].append(client_id)
            
            emit('subscribed', {
                'topic': topic,
                'success': True,
                'timestamp': datetime.utcnow().isoformat()
            })
        else:
            emit('subscription_error', {
                'topic': topic,
                'error': 'Insufficient permissions',
                'timestamp': datetime.utcnow().isoformat()
            })

@socketio.on('unsubscribe')
def handle_unsubscription(data):
    """å¤„ç†å–æ¶ˆè®¢é˜…"""
    client_id = request.sid
    topics = data.get('topics', [])
    
    for topic in topics:
        leave_room(topic)
        if topic in client_rooms and client_id in client_rooms[topic]:
            client_rooms[topic].remove(client_id)
        
        emit('unsubscribed', {
            'topic': topic,
            'success': True,
            'timestamp': datetime.utcnow().isoformat()
        })

@socketio.on('disconnect')
def handle_disconnect():
    """å¤„ç†å®¢æˆ·ç«¯æ–­å¼€è¿æ¥"""
    client_id = request.sid
    if client_id in connected_clients:
        del connected_clients[client_id]
    
    # ä»æ‰€æœ‰æˆ¿é—´ä¸­ç§»é™¤
    for topic, clients in client_rooms.items():
        if client_id in clients:
            clients.remove(client_id)
    
    print(f"Client disconnected: {client_id}")

# å®æ—¶äº‹ä»¶å¹¿æ’­å‡½æ•°
def broadcast_event(event_type, data, room=None):
    """å¹¿æ’­äº‹ä»¶åˆ°æŒ‡å®šæˆ¿é—´æˆ–æ‰€æœ‰å®¢æˆ·ç«¯"""
    event_data = {
        'type': event_type,
        'data': data,
        'timestamp': datetime.utcnow().isoformat()
    }
    
    if room:
        socketio.emit('event', event_data, room=room)
    else:
        socketio.emit('event', event_data)

def broadcast_ddns_update(update_data):
    """å¹¿æ’­DDNSæ›´æ–°äº‹ä»¶"""
    event_data = {
        'type': 'ddns_update',
        'data': update_data,
        'timestamp': datetime.utcnow().isoformat()
    }
    
    # å¹¿æ’­ç»™æ‰€æœ‰è®¢é˜…äº†ddns_updatesçš„å®¢æˆ·ç«¯
    socketio.emit('event', event_data, room='ddns_updates')
    
    # ä¹Ÿå¹¿æ’­ç»™ç®¡ç†å‘˜
    socketio.emit('event', event_data, room='role:admin')

def broadcast_system_alert(alert_data):
    """å¹¿æ’­ç³»ç»Ÿå‘Šè­¦"""
    event_data = {
        'type': 'system_alert',
        'data': alert_data,
        'timestamp': datetime.utcnow().isoformat()
    }
    
    # å¹¿æ’­ç»™æ‰€æœ‰è®¢é˜…äº†alertsçš„å®¢æˆ·ç«¯
    socketio.emit('event', event_data, room='alerts')
    
    # æ ¹æ®å‘Šè­¦çº§åˆ«å¹¿æ’­ç»™ä¸åŒè§’è‰²
    if alert_data.get('severity') == 'critical':
        socketio.emit('event', event_data, room='role:admin')
    elif alert_data.get('severity') == 'warning':
        socketio.emit('event', event_data, room='role:operator')

def broadcast_monitoring_data(metrics_data):
    """å¹¿æ’­ç›‘æ§æ•°æ®"""
    event_data = {
        'type': 'monitoring_update',
        'data': metrics_data,
        'timestamp': datetime.utcnow().isoformat()
    }
    
    # å¹¿æ’­ç»™æ‰€æœ‰è®¢é˜…äº†monitoringçš„å®¢æˆ·ç«¯
    socketio.emit('event', event_data, room='monitoring')

# åå°ä»»åŠ¡ï¼šå®šæœŸå‘é€å¿ƒè·³
def send_heartbeat():
    """å‘é€å¿ƒè·³åŒ…"""
    while True:
        socketio.emit('heartbeat', {
            'timestamp': datetime.utcnow().isoformat(),
            'server_time': datetime.utcnow().isoformat()
        })
        socketio.sleep(30)  # æ¯30ç§’å‘é€ä¸€æ¬¡

# å¯åŠ¨å¿ƒè·³ä»»åŠ¡
socketio.start_background_task(send_heartbeat)

# WebSocketç«¯ç‚¹å®šä¹‰
@socketio.on('ping')
def handle_ping():
    """å¤„ç†pingè¯·æ±‚"""
    emit('pong', {
        'timestamp': datetime.utcnow().isoformat()
    })

@socketio.on('get_online_users')
def handle_get_online_users():
    """è·å–åœ¨çº¿ç”¨æˆ·åˆ—è¡¨"""
    online_users = []
    for client_id, client_info in connected_clients.items():
        if client_info['user_id']:
            online_users.append({
                'user_id': client_info['user_id'],
                'connected_at': client_info['connected_at'],
                'roles': client_info['roles']
            })
    
    emit('online_users', {
        'users': online_users,
        'count': len(online_users),
        'timestamp': datetime.utcnow().isoformat()
    })

@socketio.on('private_message')
def handle_private_message(data):
    """å¤„ç†ç§ä¿¡"""
    recipient_id = data.get('to')
    message = data.get('message')
    
    if not recipient_id or not message:
        emit('error', {
            'error': 'Recipient and message are required'
        })
        return
    
    # å‘é€ç»™ç‰¹å®šç”¨æˆ·
    emit('private_message', {
        'from': connected_clients.get(request.sid, {}).get('user_id'),
        'message': message,
        'timestamp': datetime.utcnow().isoformat()
    }, room=f"user:{recipient_id}")
    
    # ç»™è‡ªå·±ä¹Ÿå‘é€ç¡®è®¤
    emit('message_sent', {
        'to': recipient_id,
        'message': message,
        'timestamp': datetime.utcnow().isoformat()
    })
```

### 9.2 å®æ—¶æ•°æ®æµAPI

```python
# api/websocket/streams.py
from flask_socketio import emit
import asyncio
import json

@socketio.on('start_stream')
def handle_start_stream(data):
    """å¼€å§‹å®æ—¶æ•°æ®æµ"""
    stream_type = data.get('type')
    client_id = request.sid
    
    if not stream_type:
        emit('stream_error', {
            'error': 'Stream type is required'
        })
        return
    
    # éªŒè¯æµæƒé™
    if not can_access_stream(client_id, stream_type):
        emit('stream_error', {
            'error': 'Insufficient permissions for this stream'
        })
        return
    
    # å¼€å§‹ç›¸åº”çš„æ•°æ®æµ
    if stream_type == 'system_metrics':
        start_system_metrics_stream(client_id)
    elif stream_type == 'ddns_updates':
        start_ddns_updates_stream(client_id)
    elif stream_type == 'api_requests':
        start_api_requests_stream(client_id)
    elif stream_type == 'error_logs':
        start_error_logs_stream(client_id)
    
    emit('stream_started', {
        'type': stream_type,
        'timestamp': datetime.utcnow().isoformat()
    })

@socketio.on('stop_stream')
def handle_stop_stream(data):
    """åœæ­¢å®æ—¶æ•°æ®æµ"""
    stream_type = data.get('type')
    client_id = request.sid
    
    # åœæ­¢ç›¸åº”çš„æ•°æ®æµ
    if stream_type == 'system_metrics':
        stop_system_metrics_stream(client_id)
    elif stream_type == 'ddns_updates':
        stop_ddns_updates_stream(client_id)
    elif stream_type == 'api_requests':
        stop_api_requests_stream(client_id)
    elif stream_type == 'error_logs':
        stop_error_logs_stream(client_id)
    
    emit('stream_stopped', {
        'type': stream_type,
        'timestamp': datetime.utcnow().isoformat()
    })

# ç³»ç»ŸæŒ‡æ ‡æµ
def start_system_metrics_stream(client_id):
    """å¯åŠ¨ç³»ç»ŸæŒ‡æ ‡æµ"""
    async def stream_metrics():
        while client_id in connected_clients:
            try:
                metrics = collect_system_metrics()
                
                emit('metrics_update', {
                    'type': 'system',
                    'metrics': metrics,
                    'timestamp': datetime.utcnow().isoformat()
                }, room=client_id)
                
                await asyncio.sleep(5)  # æ¯5ç§’å‘é€ä¸€æ¬¡
            except Exception as e:
                print(f"Error streaming metrics: {e}")
                break
    
    # å¯åŠ¨åå°ä»»åŠ¡
    socketio.start_background_task(stream_metrics)

def stop_system_metrics_stream(client_id):
    """åœæ­¢ç³»ç»ŸæŒ‡æ ‡æµ"""
    # åœ¨å®é™…å®ç°ä¸­ï¼Œéœ€è¦è·Ÿè¸ªå¹¶åœæ­¢ç›¸åº”çš„åå°ä»»åŠ¡
    pass

# DDNSæ›´æ–°æµ
def start_ddns_updates_stream(client_id):
    """å¯åŠ¨DDNSæ›´æ–°æµ"""
    # è®¢é˜…DDNSæ›´æ–°äº‹ä»¶
    join_room('ddns_updates_stream', sid=client_id)

def stop_ddns_updates_stream(client_id):
    """åœæ­¢DDNSæ›´æ–°æµ"""
    leave_room('ddns_updates_stream', sid=client_id)

# APIè¯·æ±‚æµ
def start_api_requests_stream(client_id):
    """å¯åŠ¨APIè¯·æ±‚æµ"""
    async def stream_api_requests():
        # è¿™é‡Œå¯ä»¥è¿æ¥åˆ°å®é™…çš„APIæ—¥å¿—æµ
        # ç¤ºä¾‹ï¼šæ¨¡æ‹Ÿå®æ—¶APIè¯·æ±‚
        while client_id in connected_clients:
            try:
                # æ¨¡æ‹Ÿè·å–æœ€è¿‘APIè¯·æ±‚
                recent_requests = get_recent_api_requests(limit=10)
                
                emit('api_requests', {
                    'type': 'api_requests',
                    'requests': recent_requests,
                    'timestamp': datetime.utcnow().isoformat()
                }, room=client_id)
                
                await asyncio.sleep(10)  # æ¯10ç§’å‘é€ä¸€æ¬¡
            except Exception as e:
                print(f"Error streaming API requests: {e}")
                break
    
    socketio.start_background_task(stream_api_requests)

# é”™è¯¯æ—¥å¿—æµ
def start_error_logs_stream(client_id):
    """å¯åŠ¨é”™è¯¯æ—¥å¿—æµ"""
    async def stream_error_logs():
        # ç›‘æ§é”™è¯¯æ—¥å¿—æ–‡ä»¶
        log_file = "/opt/yyc3/logs/error.log"
        last_position = 0
        
        while client_id in connected_clients:
            try:
                with open(log_file, 'r') as f:
                    f.seek(last_position)
                    new_lines = f.readlines()
                    last_position = f.tell()
                    
                    if new_lines:
                        errors = []
                        for line in new_lines:
                            if 'ERROR' in line or 'CRITICAL' in line:
                                errors.append(line.strip())
                        
                        if errors:
                            emit('error_logs', {
                                'type': 'error_logs',
                                'logs': errors[-10:],  # æœ€å¤šå‘é€10æ¡
                                'timestamp': datetime.utcnow().isoformat()
                            }, room=client_id)
                
                await asyncio.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
            except Exception as e:
                print(f"Error streaming error logs: {e}")
                break
    
    socketio.start_background_task(stream_error_logs)

# å®æ—¶ä»ªè¡¨æ¿æ•°æ®
@socketio.on('dashboard_data')
def handle_dashboard_data(data):
    """å¤„ç†ä»ªè¡¨æ¿æ•°æ®è¯·æ±‚"""
    dashboard_type = data.get('dashboard')
    client_id = request.sid
    
    if not dashboard_type:
        emit('dashboard_error', {
            'error': 'Dashboard type is required'
        })
        return
    
    try:
        if dashboard_type == 'overview':
            # å‘é€æ¦‚è§ˆä»ªè¡¨æ¿æ•°æ®
            overview_data = get_dashboard_overview_data()
            emit('dashboard_update', {
                'type': 'overview',
                'data': overview_data,
                'timestamp': datetime.utcnow().isoformat()
            }, room=client_id)
        
        elif dashboard_type == 'performance':
            # å‘é€æ€§èƒ½ä»ªè¡¨æ¿æ•°æ®
            performance_data = get_dashboard_performance_data()
            emit('dashboard_update', {
                'type': 'performance',
                'data': performance_data,
                'timestamp': datetime.utcnow().isoformat()
            }, room=client_id)
        
        elif dashboard_type == 'ddns':
            # å‘é€DDNSä»ªè¡¨æ¿æ•°æ®
            ddns_data = get_dashboard_ddns_data()
            emit('dashboard_update', {
                'type': 'ddns',
                'data': ddns_data,
                'timestamp': datetime.utcnow().isoformat()
            }, room=client_id)
    
    except Exception as e:
        emit('dashboard_error', {
            'error': str(e)
        })

# å®æ—¶å‘½ä»¤æ‰§è¡Œ
@socketio.on('execute_command')
def handle_execute_command(data):
    """å¤„ç†å®æ—¶å‘½ä»¤æ‰§è¡Œ"""
    command = data.get('command')
    client_id = request.sid
    
    if not command:
        emit('command_error', {
            'error': 'Command is required'
        })
        return
    
    # éªŒè¯å‘½ä»¤æ‰§è¡Œæƒé™
    if not can_execute_command(client_id, command):
        emit('command_error', {
            'error': 'Insufficient permissions to execute this command'
        })
        return
    
    try:
        # æ‰§è¡Œå‘½ä»¤
        result = execute_system_command(command)
        
        emit('command_result', {
            'command': command,
            'result': result,
            'timestamp': datetime.utcnow().isoformat()
        }, room=client_id)
    
    except Exception as e:
        emit('command_error', {
            'error': str(e),
            'command': command
        })
```

## 10. **ç¬¬ä¸‰æ–¹é›†æˆAPI**

### 10.1 Webhooké›†æˆ

```python
# api/v2/integrations/webhooks.py
from flask import Blueprint, request, jsonify
import hmac
import hashlib
import json

webhooks_bp = Blueprint('webhooks_v2', __name__, url_prefix='/api/v2/webhooks')

@webhooks_bp.route('', methods=['GET'])
@token_required
@role_required("integrations:read")
def list_webhooks():
    """åˆ—å‡ºæ‰€æœ‰Webhooké…ç½®"""
    try:
        webhooks = get_webhook_configurations()
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "webhooks": webhooks,
                "count": len(webhooks)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@webhooks_bp.route('', methods=['POST'])
@token_required
@role_required("integrations:write")
def create_webhook():
    """åˆ›å»ºWebhooké…ç½®"""
    data = request.get_json()
    
    required_fields = ["name", "url", "events", "secret"]
    missing = [field for field in required_fields if field not in data]
    if missing:
        return jsonify({
            "success": False,
            "error": f"Missing required fields: {', '.join(missing)}"
        }), 400
    
    try:
        webhook = create_webhook_configuration(data)
        
        # æµ‹è¯•Webhook
        test_result = test_webhook_configuration(webhook["id"])
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "webhook": webhook,
                "test_result": test_result
            },
            "message": "Webhook created and tested"
        }), 201
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@webhooks_bp.route('/<string:webhook_id>/test', methods=['POST'])
@token_required
@role_required("integrations:write")
def test_webhook(webhook_id):
    """æµ‹è¯•Webhook"""
    try:
        test_result = test_webhook_configuration(webhook_id)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": test_result,
            "message": "Webhook test completed"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@webhooks_bp.route('/<string:webhook_id>/deliveries', methods=['GET'])
@token_required
@role_required("integrations:read")
def get_webhook_deliveries(webhook_id):
    """è·å–WebhookæŠ•é€’è®°å½•"""
    limit = request.args.get('limit', 50, type=int)
    status = request.args.get('status')  # success, failed
    
    try:
        deliveries = get_webhook_delivery_history(
            webhook_id=webhook_id,
            limit=limit,
            status=status
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "webhook_id": webhook_id,
                "deliveries": deliveries,
                "summary": {
                    "total": get_total_deliveries_count(webhook_id),
                    "successful": get_successful_deliveries_count(webhook_id),
                    "failed": get_failed_deliveries_count(webhook_id)
                }
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

# Webhookæ¥æ”¶ç«¯ç‚¹
@webhooks_bp.route('/receive/<string:provider>', methods=['POST'])
def receive_webhook(provider):
    """æ¥æ”¶ç¬¬ä¸‰æ–¹Webhook"""
    # éªŒè¯è¯·æ±‚ç­¾å
    signature = request.headers.get('X-Hub-Signature-256')
    if not signature:
        return jsonify({"error": "Missing signature"}), 401
    
    # æ ¹æ®provideréªŒè¯ç­¾å
    secret = get_webhook_secret_for_provider(provider)
    if not secret:
        return jsonify({"error": "Unknown provider"}), 404
    
    # è®¡ç®—ç­¾å
    body = request.get_data()
    expected_signature = 'sha256=' + hmac.new(
        secret.encode(),
        body,
        hashlib.sha256
    ).hexdigest()
    
    if not hmac.compare_digest(signature, expected_signature):
        return jsonify({"error": "Invalid signature"}), 401
    
    try:
        data = request.get_json()
        
        # å¤„ç†Webhookäº‹ä»¶
        process_webhook_event(provider, data)
        
        # è®°å½•æ¥æ”¶
        log_webhook_reception(provider, data)
        
        return jsonify({
            "success": True,
            "message": "Webhook received"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

# Webhookäº‹ä»¶å¤„ç†å‡½æ•°
def process_webhook_event(provider, data):
    """å¤„ç†Webhookäº‹ä»¶"""
    if provider == 'github':
        process_github_webhook(data)
    elif provider == 'gitlab':
        process_gitlab_webhook(data)
    elif provider == 'slack':
        process_slack_webhook(data)
    elif provider == 'discord':
        process_discord_webhook(data)
    elif provider == 'telegram':
        process_telegram_webhook(data)
    else:
        # é€šç”¨å¤„ç†
        process_generic_webhook(provider, data)

def process_github_webhook(data):
    """å¤„ç†GitHub Webhook"""
    event_type = request.headers.get('X-GitHub-Event')
    
    if event_type == 'push':
        # å¤„ç†ä»£ç æ¨é€
        repository = data['repository']['full_name']
        branch = data['ref'].split('/')[-1]
        
        # è§¦å‘è‡ªåŠ¨åŒ–éƒ¨ç½²
        trigger_deployment(repository, branch)
        
    elif event_type == 'pull_request':
        # å¤„ç†Pull Request
        action = data['action']
        pr_number = data['pull_request']['number']
        
        if action in ['opened', 'reopened']:
            # è§¦å‘CI/CD
            trigger_ci_for_pr(pr_number)
    
    # å¹¿æ’­äº‹ä»¶
    broadcast_event('github_webhook', {
        'event_type': event_type,
        'data': data
    })

def process_slack_webhook(data):
    """å¤„ç†Slack Webhook"""
    # å¤„ç†Slackå‘½ä»¤æˆ–äº¤äº’
    if data.get('type') == 'url_verification':
        # Slack URLéªŒè¯
        return {'challenge': data.get('challenge')}
    
    # å¤„ç†Slackäº¤äº’
    process_slack_interaction(data)
    
    # å¹¿æ’­äº‹ä»¶
    broadcast_event('slack_webhook', {
        'data': data
    })
```

### 10.2 ç¬¬ä¸‰æ–¹æœåŠ¡é›†æˆ

```python
# api/v2/integrations/services.py
from flask import Blueprint, request, jsonify
import requests

integrations_bp = Blueprint('integrations_v2', __name__, url_prefix='/api/v2/integrations')

@integrations_bp.route('/slack/notify', methods=['POST'])
@token_required
@role_required("integrations:write")
def send_slack_notification():
    """å‘é€Slacké€šçŸ¥"""
    data = request.get_json()
    
    channel = data.get('channel', '#alerts')
    message = data.get('message')
    attachments = data.get('attachments', [])
    
    if not message:
        return jsonify({
            "success": False,
            "error": "Message is required"
        }), 400
    
    try:
        result = send_slack_message(
            channel=channel,
            message=message,
            attachments=attachments
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": result,
            "message": "Slack notification sent"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@integrations_bp.route('/telegram/send', methods=['POST'])
@token_required
@role_required("integrations:write")
def send_telegram_message():
    """å‘é€Telegramæ¶ˆæ¯"""
    data = request.get_json()
    
    chat_id = data.get('chat_id')
    message = data.get('message')
    parse_mode = data.get('parse_mode', 'Markdown')
    
    if not chat_id or not message:
        return jsonify({
            "success": False,
            "error": "Chat ID and message are required"
        }), 400
    
    try:
        result = send_telegram_notification(
            chat_id=chat_id,
            message=message,
            parse_mode=parse_mode
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": result,
            "message": "Telegram message sent"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@integrations_bp.route('/email/send', methods=['POST'])
@token_required
@role_required("integrations:write")
def send_email():
    """å‘é€ç”µå­é‚®ä»¶"""
    data = request.get_json()
    
    required_fields = ["to", "subject", "body"]
    missing = [field for field in required_fields if field not in data]
    if missing:
        return jsonify({
            "success": False,
            "error": f"Missing required fields: {', '.join(missing)}"
        }), 400
    
    try:
        result = send_email_notification(
            to=data["to"],
            subject=data["subject"],
            body=data["body"],
            html=data.get("html"),
            attachments=data.get("attachments", [])
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": result,
            "message": "Email sent"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@integrations_bp.route('/github/repos', methods=['GET'])
@token_required
@role_required("integrations:read")
def list_github_repositories():
    """åˆ—å‡ºGitHubä»“åº“"""
    org = request.args.get('org')
    
    try:
        repos = get_github_repositories(org=org)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": {
                "repositories": repos,
                "count": len(repos)
            }
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@integrations_bp.route('/github/deploy', methods=['POST'])
@token_required
@role_required("integrations:admin")
def trigger_github_deployment():
    """è§¦å‘GitHubéƒ¨ç½²"""
    data = request.get_json()
    
    required_fields = ["repository", "ref"]
    missing = [field for field in required_fields if field not in data]
    if missing:
        return jsonify({
            "success": False,
            "error": f"Missing required fields: {', '.join(missing)}"
        }), 400
    
    try:
        deployment = trigger_github_deployment_action(
            repository=data["repository"],
            ref=data["ref"],
            environment=data.get("environment", "production"),
            payload=data.get("payload", {})
        )
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": deployment,
            "message": "GitHub deployment triggered"
        }), 202
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@integrations_bp.route('/docker/webhook', methods=['POST'])
@token_required
@role_required("integrations:write")
def handle_docker_webhook():
    """å¤„ç†Docker Webhook"""
    data = request.get_json()
    
    try:
        # å¤„ç†Dockeré•œåƒæ¨é€äº‹ä»¶
        if data.get('push_data'):
            image_name = data['repository']['repo_name']
            tag = data['push_data']['tag']
            
            # è§¦å‘å®¹å™¨æ›´æ–°
            trigger_container_update(image_name, tag)
            
            return jsonify({
                "success": True,
                "timestamp": datetime.utcnow().isoformat(),
                "message": f"Docker image {image_name}:{tag} update triggered"
            })
        
        return jsonify({
            "success": False,
            "error": "Invalid Docker webhook payload"
        }), 400
    
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@integrations_bp.route('/aws/status', methods=['GET'])
@token_required
@role_required("integrations:read")
def get_aws_status():
    """è·å–AWSæœåŠ¡çŠ¶æ€"""
    region = request.args.get('region', 'us-east-1')
    
    try:
        status = get_aws_service_status(region)
        
        return jsonify({
            "success": True,
            "timestamp": datetime.utcnow().isoformat(),
            "data": status
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500
```

## 11. **APIæ–‡æ¡£ä¸æµ‹è¯•**

### 11.1 OpenAPIè§„èŒƒ

```yaml
# openapi.yaml
openapi: 3.0.3
info:
  title: NAS DDNS API
  description: Comprehensive API for NAS DDNS Management System
  version: 2.0.0
  contact:
    name: API Support
    email: api@ddns.0379.email
  license:
    name: MIT
    url: https://opensource.org/licenses/MIT

servers:
  - url: https://api.ddns.0379.edu/api/v2
    description: Production server
  - url: https://api-staging.ddns.0379.edu/api/v2
    description: Staging server
  - url: http://localhost:8080/api/v2
    description: Local development server

security:
  - bearerAuth: []
  - apiKeyAuth: []

components:
  securitySchemes:
    bearerAuth:
      type: http
      scheme: bearer
      bearerFormat: JWT
    apiKeyAuth:
      type: apiKey
      in: header
      name: X-API-Key

  schemas:
    Error:
      type: object
      properties:
        success:
          type: boolean
          example: false
        error:
          type: string
          example: "Resource not found"
        timestamp:
          type: string
          format: date-time

    Success:
      type: object
      properties:
        success:
          type: boolean
          example: true
        data:
          type: object
        timestamp:
          type: string
          format: date-time

    DDNSStatus:
      type: object
      properties:
        ddns_enabled:
          type: boolean
        ddns_running:
          type: boolean
        current_ip:
          type: string
        domain:
          type: string
        last_check:
          type: string
          format: date-time

  parameters:
    PaginationLimit:
      name: limit
      in: query
      description: Number of items per page
      required: false
      schema:
        type: integer
        minimum: 1
        maximum: 100
        default: 50
    
    PaginationOffset:
      name: offset
      in: query
      description: Offset for pagination
      required: false
      schema:
        type: integer
        minimum: 0
        default: 0
    
    TimeRange:
      name: range
      in: query
      description: Time range for data
      required: false
      schema:
        type: string
        enum: [1h, 24h, 7d, 30d]
        default: 24h

paths:
  /health:
    get:
      summary: Health check
      description: Check API health status
      responses:
        '200':
          description: API is healthy
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Success'
        '503':
          description: API is unhealthy
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'

  /ddns/status:
    get:
      summary: Get DDNS status
      description: Get current DDNS service status
      security:
        - bearerAuth: []
      responses:
        '200':
          description: DDNS status retrieved
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Success'
        '401':
          description: Unauthorized
        '500':
          description: Internal server error

  /ddns/records:
    get:
      summary: List DNS records
      description: List all DNS records for managed domains
      security:
        - bearerAuth: []
      parameters:
        - $ref: '#/components/parameters/PaginationLimit'
        - $ref: '#/components/parameters/PaginationOffset'
        - name: domain
          in: query
          schema:
            type: string
          required: false
          description: Filter by domain
      responses:
        '200':
          description: DNS records retrieved
        '401':
          description: Unauthorized

  /alerts:
    get:
      summary: List alerts
      description: Get list of system alerts
      security:
        - bearerAuth: []
        - apiKeyAuth: []
      parameters:
        - $ref: '#/components/parameters/PaginationLimit'
        - name: status
          in: query
          schema:
            type: string
            enum: [active, resolved, all]
          required: false
          default: active
        - name: severity
          in: query
          schema:
            type: string
            enum: [critical, warning, info]
          required: false
      responses:
        '200':
          description: Alerts retrieved
        '401':
          description: Unauthorized
        '403':
          description: Forbidden

  /monitoring/system:
    get:
      summary: System monitoring
      description: Get real-time system monitoring data
      security:
        - apiKeyAuth: []
      parameters:
        - name: metrics
          in: query
          schema:
            type: string
            enum: [all, cpu, memory, disk, network, processes]
          required: false
          default: all
      responses:
        '200':
          description: Monitoring data retrieved
        '401':
          description: Unauthorized
```

### 11.2 APIæµ‹è¯•å¥—ä»¶

```python
# tests/api/test_ddns_api.py
import pytest
import requests
import json
from datetime import datetime

BASE_URL = "http://localhost:8080/api/v2"

class TestDDNSAPI:
    """DDNS APIæµ‹è¯•ç±»"""
    
    @pytest.fixture
    def auth_headers(self):
        """è·å–è®¤è¯å¤´éƒ¨"""
        # è·å–è®¿é—®ä»¤ç‰Œ
        auth_response = requests.post(f"{BASE_URL}/auth/login", json={
            "username": "admin",
            "password": "admin123"
        })
        token = auth_response.json()["data"]["access_token"]
        
        return {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"
        }
    
    def test_health_check(self):
        """æµ‹è¯•å¥åº·æ£€æŸ¥"""
        response = requests.get(f"{BASE_URL}/health")
        assert response.status_code == 200
        data = response.json()
        assert data["success"] == True
        assert data["status"] == "healthy"
    
    def test_get_ddns_status(self, auth_headers):
        """æµ‹è¯•è·å–DDNSçŠ¶æ€"""
        response = requests.get(f"{BASE_URL}/ddns/status", headers=auth_headers)
        assert response.status_code == 200
        data = response.json()
        assert data["success"] == True
        assert "ddns_enabled" in data["data"]
        assert "current_ip" in data["data"]
    
    def test_list_dns_records(self, auth_headers):
        """æµ‹è¯•åˆ—å‡ºDNSè®°å½•"""
        response = requests.get(f"{BASE_URL}/ddns/records", headers=auth_headers)
        assert response.status_code == 200
        data = response.json()
        assert data["success"] == True
        assert "records" in data["data"]
        assert isinstance(data["data"]["records"], list)
    
    def test_manual_ddns_update(self, auth_headers):
        """æµ‹è¯•æ‰‹åŠ¨DDNSæ›´æ–°"""
        response = requests.post(
            f"{BASE_URL}/ddns/manual-update",
            headers=auth_headers,
            json={"force": True}
        )
        assert response.status_code == 200 or response.status_code == 429  # 429æ˜¯é€Ÿç‡é™åˆ¶
        if response.status_code == 200:
            data = response.json()
            assert data["success"] == True
    
    def test_get_update_history(self, auth_headers):
        """æµ‹è¯•è·å–æ›´æ–°å†å²"""
        response = requests.get(
            f"{BASE_URL}/ddns/history",
            headers=auth_headers,
            params={"limit": 10}
        )
        assert response.status_code == 200
        data = response.json()
        assert data["success"] == True
        assert "history" in data["data"]

class TestMonitoringAPI:
    """ç›‘æ§APIæµ‹è¯•ç±»"""
    
    @pytest.fixture
    def api_key_headers(self):
        """è·å–APIå¯†é’¥å¤´éƒ¨"""
        return {
            "X-API-Key": "test-api-key-123",
            "Content-Type": "application/json"
        }
    
    def test_get_system_monitoring(self, api_key_headers):
        """æµ‹è¯•è·å–ç³»ç»Ÿç›‘æ§æ•°æ®"""
        response = requests.get(
            f"{BASE_URL}/monitoring/system",
            headers=api_key_headers,
            params={"metrics": "cpu,memory"}
        )
        assert response.status_code == 200
        data = response.json()
        assert data["success"] == True
        assert "cpu" in data["data"]
        assert "memory" in data["data"]
    
    def test_get_services_status(self, api_key_headers):
        """æµ‹è¯•è·å–æœåŠ¡çŠ¶æ€"""
        response = requests.get(
            f"{BASE_URL}/monitoring/services",
            headers=api_key_headers
        )
        assert response.status_code == 200
        data = response.json()
        assert data["success"] == True
        assert "services" in data["data"]

class TestAnalyticsAPI:
    """åˆ†æAPIæµ‹è¯•ç±»"""
    
    def test_get_usage_statistics(self, auth_headers):
        """æµ‹è¯•è·å–ä½¿ç”¨ç»Ÿè®¡"""
        response = requests.get(
            f"{BASE_URL}/analytics/usage",
            headers=auth_headers,
            params={"period": "7d", "metric": "requests"}
        )
        assert response.status_code == 200
        data = response.json()
        assert data["success"] == True
        assert "statistics" in data["data"]
    
    def test_get_ddns_analytics(self, auth_headers):
        """æµ‹è¯•è·å–DDNSåˆ†æ"""
        response = requests.get(
            f"{BASE_URL}/analytics/ddns/history",
            headers=auth_headers,
            params={"days": 30}
        )
        assert response.status_code == 200
        data = response.json()
        assert data["success"] == True
        assert "analytics" in data["data"]

class TestConfigAPI:
    """é…ç½®APIæµ‹è¯•ç±»"""
    
    def test_list_configurations(self, auth_headers):
        """æµ‹è¯•åˆ—å‡ºé…ç½®"""
        response = requests.get(
            f"{BASE_URL}/config",
            headers=auth_headers,
            params={"environment": "production"}
        )
        assert response.status_code == 200
        data = response.json()
        assert data["success"] == True
        assert "configurations" in data["data"]
    
    def test_create_configuration(self, auth_headers):
        """æµ‹è¯•åˆ›å»ºé…ç½®"""
        config_data = {
            "name": "test-config",
            "environment": "test",
            "service": "ddns",
            "config": {
                "domain": "test.0379.email",
                "check_interval": 300
            }
        }
        
        response = requests.post(
            f"{BASE_URL}/config",
            headers=auth_headers,
            json=config_data
        )
        
        # 201åˆ›å»ºæˆåŠŸæˆ–400é…ç½®å·²å­˜åœ¨
        assert response.status_code in [201, 400]
        
        if response.status_code == 201:
            data = response.json()
            assert data["success"] == True
            assert data["data"]["name"] == "test-config"

# æ€§èƒ½æµ‹è¯•
class TestAPIPerformance:
    """APIæ€§èƒ½æµ‹è¯•ç±»"""
    
    def test_response_time(self, auth_headers):
        """æµ‹è¯•å“åº”æ—¶é—´"""
        import time
        
        endpoints = [
            "/health",
            "/ddns/status",
            "/monitoring/system"
        ]
        
        max_response_time = 2.0  # ç§’
        
        for endpoint in endpoints:
            start_time = time.time()
            if "monitoring" in endpoint:
                headers = {"X-API-Key": "test-key"}
            else:
                headers = auth_headers
            
            response = requests.get(f"{BASE_URL}{endpoint}", headers=headers)
            end_time = time.time()
            
            response_time = end_time - start_time
            print(f"{endpoint}: {response_time:.3f}s")
            
            assert response_time < max_response_time, f"{endpoint}å“åº”æ—¶é—´è¿‡é•¿: {response_time:.3f}s"
            assert response.status_code == 200
    
    def test_concurrent_requests(self):
        """æµ‹è¯•å¹¶å‘è¯·æ±‚"""
        import concurrent.futures
        
        def make_request(endpoint):
            response = requests.get(f"{BASE_URL}{endpoint}")
            return response.status_code
        
        endpoints = ["/health"] * 50  # 50ä¸ªå¹¶å‘è¯·æ±‚
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            results = list(executor.map(make_request, endpoints))
        
        success_count = sum(1 for code in results if code == 200)
        success_rate = success_count / len(results)
        
        print(f"å¹¶å‘è¯·æ±‚æˆåŠŸç‡: {success_rate:.2%}")
        assert success_rate >= 0.95, f"å¹¶å‘è¯·æ±‚æˆåŠŸç‡è¿‡ä½: {success_rate:.2%}"

# å®‰å…¨æµ‹è¯•
class TestAPISecurity:
    """APIå®‰å…¨æµ‹è¯•ç±»"""
    
    def test_authentication_required(self):
        """æµ‹è¯•è®¤è¯è¦æ±‚"""
        protected_endpoints = [
            "/ddns/status",
            "/ddns/records",
            "/config"
        ]
        
        for endpoint in protected_endpoints:
            response = requests.get(f"{BASE_URL}{endpoint}")
            assert response.status_code in [401, 403], f"{endpoint}åº”è¯¥è¦æ±‚è®¤è¯"
    
    def test_rate_limiting(self, auth_headers):
        """æµ‹è¯•é€Ÿç‡é™åˆ¶"""
        # å¿«é€Ÿå‘é€å¤šä¸ªè¯·æ±‚
        for i in range(15):
            response = requests.get(f"{BASE_URL}/ddns/status", headers=auth_headers)
        
        # åº”è¯¥è¢«é™åˆ¶
        assert response.status_code == 429, "é€Ÿç‡é™åˆ¶åº”è¯¥ç”Ÿæ•ˆ"
    
    def test_input_validation(self, auth_headers):
        """æµ‹è¯•è¾“å…¥éªŒè¯"""
        # æµ‹è¯•æ— æ•ˆçš„é…ç½®æ•°æ®
        invalid_config = {
            "name": "",
            "environment": "production",
            "config": "not a json object"
        }
        
        response = requests.post(
            f"{BASE_URL}/config",
            headers=auth_headers,
            json=invalid_config
        )
        
        assert response.status_code == 400, "åº”è¯¥æ‹’ç»æ— æ•ˆè¾“å…¥"
        data = response.json()
        assert "error" in data
    
    def test_sql_injection_prevention(self, auth_headers):
        """æµ‹è¯•SQLæ³¨å…¥é˜²æŠ¤"""
        # å°è¯•SQLæ³¨å…¥
        malicious_params = {
            "domain": "0379.email' OR '1'='1",
            "type": "A' UNION SELECT * FROM users--"
        }
        
        response = requests.get(
            f"{BASE_URL}/ddns/records",
            headers=auth_headers,
            params=malicious_params
        )
        
        # åº”è¯¥æ­£ç¡®å¤„ç†æˆ–è¿”å›é”™è¯¯ï¼Œè€Œä¸æ˜¯æ‰§è¡ŒSQL
        assert response.status_code != 500, "ä¸åº”è¯¥è¿”å›æœåŠ¡å™¨é”™è¯¯"
        
        if response.status_code == 200:
            data = response.json()
            # åº”è¯¥è¿”å›ç©ºç»“æœæˆ–é”™è¯¯ï¼Œè€Œä¸æ˜¯ç”¨æˆ·æ•°æ®
            assert "users" not in str(data).lower()

# é›†æˆæµ‹è¯•
class TestIntegration:
    """é›†æˆæµ‹è¯•"""
    
    def test_end_to_end_workflow(self, auth_headers):
        """æµ‹è¯•ç«¯åˆ°ç«¯å·¥ä½œæµ"""
        # 1. æ£€æŸ¥å½“å‰çŠ¶æ€
        status_response = requests.get(f"{BASE_URL}/ddns/status", headers=auth_headers)
        assert status_response.status_code == 200
        current_ip = status_response.json()["data"]["current_ip"]
        
        # 2. æ‰‹åŠ¨è§¦å‘æ›´æ–°
        update_response = requests.post(
            f"{BASE_URL}/ddns/manual-update",
            headers=auth_headers,
            json={"force": False}
        )
        
        if update_response.status_code == 200:
            # 3. æ£€æŸ¥æ›´æ–°å†å²
            history_response = requests.get(
                f"{BASE_URL}/ddns/history",
                headers=auth_headers,
                params={"limit": 1}
            )
            assert history_response.status_code == 200
            
            history = history_response.json()["data"]["history"]
            if history:
                latest_update = history[0]
                # éªŒè¯æ›´æ–°è®°å½•
                assert "timestamp" in latest_update
                assert "ip" in latest_update
        
        # 4. æ£€æŸ¥ç›‘æ§æ•°æ®
        monitor_response = requests.get(
            f"{BASE_URL}/monitoring/system",
            headers={"X-API-Key": "test-key"}
        )
        assert monitor_response.status_code == 200
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        report_response = requests.post(
            f"{BASE_URL}/analytics/reports/generate",
            headers=auth_headers,
            json={"type": "test", "format": "json"}
        )
        assert report_response.status_code in [200, 202]
        
        print("ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•å®Œæˆ")

# è¿è¡Œæµ‹è¯•
if __name__ == "__main__":
    # å¯ä»¥ä½¿ç”¨pytestè¿è¡Œæµ‹è¯•
    # pytest tests/api/test_ddns_api.py -v
    
    # æˆ–è€…ç›´æ¥è¿è¡Œ
    import sys
    sys.path.append('.')
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹å¹¶è¿è¡Œ
    test_suite = TestDDNSAPI()
    
    # éœ€è¦å…ˆè®¾ç½®æµ‹è¯•ç¯å¢ƒ
    print("Running API tests...")
    
    # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…åº”è¯¥ä½¿ç”¨pytest
    try:
        test_suite.test_health_check()
        print("âœ“ Health check test passed")
    except Exception as e:
        print(f"âœ— Health check test failed: {e}")
```

## 12. **éƒ¨ç½²ä¸è¿ç»´**

### 12.1 Dockeréƒ¨ç½²é…ç½®

```dockerfile
# Dockerfile
# å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–

# ç¬¬ä¸€é˜¶æ®µï¼šæ„å»ºé˜¶æ®µ
FROM python:3.9-slim AS builder

WORKDIR /app

# å®‰è£…æ„å»ºä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    make \
    curl \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
COPY requirements-dev.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --user --no-cache-dir -r requirements.txt

# ç¬¬äºŒé˜¶æ®µï¼šè¿è¡Œé˜¶æ®µ
FROM python:3.9-slim

LABEL maintainer="admin@ddns.0379.email"
LABEL version="2.0.0"
LABEL description="NAS DDNS API Service"

WORKDIR /app

# åˆ›å»ºérootç”¨æˆ·
RUN groupadd -r nas && useradd -r -g nas nas

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN apt-get update && apt-get install -y \
    curl \
    dnsutils \
    nginx \
    supervisor \
    && rm -rf /var/lib/apt/lists/*

# ä»æ„å»ºé˜¶æ®µå¤åˆ¶Pythonä¾èµ–
COPY --from=builder /root/.local /root/.local
ENV PATH=/root/.local/bin:$PATH

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# å¤åˆ¶é…ç½®æ–‡ä»¶
COPY docker/nginx.conf /etc/nginx/nginx.conf
COPY docker/supervisord.conf /etc/supervisor/conf.d/supervisord.conf

# è®¾ç½®æƒé™
RUN chown -R nas:nas /app
RUN chmod +x /app/docker/entrypoint.sh

# åˆ›å»ºå¿…è¦çš„ç›®å½•
RUN mkdir -p /app/logs /app/data /app/cache
RUN chown -R nas:nas /app/logs /app/data /app/cache

# åˆ‡æ¢åˆ°érootç”¨æˆ·
USER nas

# æš´éœ²ç«¯å£
EXPOSE 8080 8443

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8080/api/v2/health || exit 1

# å¯åŠ¨è„šæœ¬
ENTRYPOINT ["/app/docker/entrypoint.sh"]
CMD ["supervisord", "-c", "/etc/supervisor/conf.d/supervisord.conf"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  # APIæœåŠ¡
  api:
    build: .
    container_name: nas-ddns-api
    restart: unless-stopped
    ports:
      - "8080:8080"
      - "8443:8443"
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=postgresql://user:password@db:5432/nas_ddns
      - REDIS_URL=redis://redis:6379/0
      - SECRET_KEY=${SECRET_KEY}
      - ALIYUN_ACCESS_KEY_ID=${ALIYUN_ACCESS_KEY_ID}
      - ALIYUN_ACCESS_KEY_SECRET=${ALIYUN_ACCESS_KEY_SECRET}
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./cache:/app/cache
      - ./config:/app/config
    depends_on:
      - db
      - redis
    networks:
      - nas-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/v2/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # PostgreSQLæ•°æ®åº“
  db:
    image: postgres:14-alpine
    container_name: nas-ddns-db
    restart: unless-stopped
    environment:
      - POSTGRES_DB=nas_ddns
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      volumes:
        - postgres_data:/var/lib/postgresql/data
        - ./docker/init.sql:/docker-entrypoint-initdb.d/init.sql
      networks:
        - nas-network
      healthcheck:
        test: ["CMD-SHELL", "pg_isready -U ${DB_USER}"]
        interval: 10s
        timeout: 5s
        retries: 5

    # RedisæœåŠ¡
    redis:
      image: redis:7-alpine
      container_name: nas-ddns-redis
      restart: unless-stopped
      command: >
        redis-server
        --requirepass ${REDIS_PASSWORD}
        --appendonly yes
        --maxmemory 256mb
        --maxmemory-policy allkeys-lru
      volumes:
        - redis_data:/data
      networks:
        - nas-network
      healthcheck:
        test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
        interval: 10s
        timeout: 3s
        retries: 5

    # Nginxåå‘ä»£ç†
    nginx:
      image: nginx:alpine
      container_name: nas-ddns-nginx
      restart: unless-stopped
      ports:
        - "80:80"
        - "443:443"
      volumes:
        - ./docker/nginx.conf:/etc/nginx/nginx.conf:ro
        - ./docker/ssl:/etc/nginx/ssl:ro
        - ./logs/nginx:/var/log/nginx
      depends_on:
        - api
      networks:
        - nas-network

    # Prometheusç›‘æ§
    prometheus:
      image: prom/prometheus:latest
      container_name: nas-ddns-prometheus
      restart: unless-stopped
      ports:
        - "9090:9090"
      volumes:
        - ./docker/prometheus.yml:/etc/prometheus/prometheus.yml
        - prometheus_data:/prometheus
      command:
        - '--config.file=/etc/prometheus/prometheus.yml'
        - '--storage.tsdb.path=/prometheus'
        - '--web.console.libraries=/etc/prometheus/console_libraries'
        - '--web.console.templates=/etc/prometheus/consoles'
      networks:
        - nas-network

    # Grafanaå¯è§†åŒ–
    grafana:
      image: grafana/grafana:latest
      container_name: nas-ddns-grafana
      restart: unless-stopped
      ports:
        - "3001:3000"
      environment:
        - GF_SECURITY_ADMIN_USER=${GRAFANA_USER}
        - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      volumes:
        - grafana_data:/var/lib/grafana
        - ./docker/grafana/dashboards:/etc/grafana/provisioning/dashboards
        - ./docker/grafana/datasources:/etc/grafana/provisioning/datasources
      depends_on:
        - prometheus
      networks:
        - nas-network

    # æ—¥å¿—é‡‡é›† (Loki)
    loki:
      image: grafana/loki:latest
      container_name: nas-ddns-loki
      restart: unless-stopped
      ports:
        - "3100:3100"
      volumes:
        - ./docker/loki-config.yml:/etc/loki/local-config.yaml
        - loki_data:/loki
      command: -config.file=/etc/loki/local-config.yaml
      networks:
        - nas-network

    # å¤‡ä»½æœåŠ¡
    backup:
      image: prodrigestivill/postgres-backup-local
      container_name: nas-ddns-backup
      restart: unless-stopped
      volumes:
        - ./backups:/backups
      environment:
        - POSTGRES_HOST=db
        - POSTGRES_DB=nas_ddns
        - POSTGRES_USER=${DB_USER}
        - POSTGRES_PASSWORD=${DB_PASSWORD}
        - SCHEDULE=@daily
        - BACKUP_KEEP_DAYS=7
        - BACKUP_KEEP_WEEKS=4
        - BACKUP_KEEP_MONTHS=6
      depends_on:
        - db
      networks:
        - nas-network

  networks:
    nas-network:
      driver: bridge

  volumes:
    postgres_data:
    redis_data:
    prometheus_data:
    grafana_data:
    loki_data:

### 12.2 Kuberneteséƒ¨ç½²é…ç½®

  # k8s/namespace.yaml
  apiVersion: v1
  kind: Namespace
  metadata:
    name: yyc3-production
    labels:
      name: production
      environment: production

  ---
  # k8s/deployment.yaml
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: yyc3-api
    namespace: yyc3-production
    labels:
      app: yyc3-api
      tier: backend
  spec:
    replicas: 3  # é«˜å¯ç”¨ï¼šå¤šå‰¯æœ¬
    strategy:
      type: RollingUpdate
      rollingUpdate:
        maxSurge: 1
        maxUnavailable: 0
    selector:
      matchLabels:
        app: yyc3-api
    template:
      metadata:
        labels:
          app: yyc3-api
          version: v2.0.0
        annotations:
          prometheus.io/scrape: "true"
          prometheus.io/port: "8080"
          prometheus.io/path: "/metrics"
      spec:
        serviceAccountName: yyc3-api
        securityContext:
          runAsNonRoot: true
          runAsUser: 1000
          fsGroup: 1000
        containers:
        - name: api
          image: registry.0379.email/yyc3/api:v2.0.0
          imagePullPolicy: Always
          ports:
          - name: http
            containerPort: 8080
            protocol: TCP
          - name: https
            containerPort: 8443
            protocol: TCP
          env:
          - name: ENVIRONMENT
            value: "production"
          - name: DATABASE_URL
            valueFrom:
              secretKeyRef:
                name: yyc3-secrets
                key: database-url
          - name: REDIS_URL
            valueFrom:
              secretKeyRef:
                name: yyc3-secrets
                key: redis-url
          resources:
            requests:
              memory: "256Mi"
              cpu: "250m"
            limits:
              memory: "512Mi"
              cpu: "500m"
          livenessProbe:
            httpGet:
              path: /api/v2/health
              port: http
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /api/v2/ready
              port: http
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 1
            successThreshold: 1
            failureThreshold: 3
          volumeMounts:
          - name: config
            mountPath: /app/config
            readOnly: true
          - name: logs
            mountPath: /app/logs
        volumes:
        - name: config
          configMap:
            name: yyc3-config
        - name: logs
          emptyDir: {}
  ---
  # k8s/service.yaml
  apiVersion: v1
  kind: Service
  metadata:
    name: yyc3-api
    namespace: yyc3-production
    labels:
      app: yyc3-api
  spec:
    type: ClusterIP
    ports:
    - name: http
      port: 80
      targetPort: 8080
      protocol: TCP
    - name: https
      port: 443
      targetPort: 8443
      protocol: TCP
    selector:
      app: yyc3-api
  ---
  # k8s/ingress.yaml
  apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    name: yyc3-api-ingress
    namespace: yyc3-production
    annotations:
      kubernetes.io/ingress.class: "nginx"
      cert-manager.io/cluster-issuer: "letsencrypt-prod"
      nginx.ingress.kubernetes.io/rate-limit: "100"
      nginx.ingress.kubernetes.io/ssl-redirect: "true"
  spec:
    tls:
    - hosts:
      - api.0379.email
      secretName: yyc3-api-tls
    rules:
    - host: api.0379.email
      http:
        paths:
        - path: /
          pathType: Prefix
          backend:
            service:
              name: yyc3-api
              port:
                number: 80
  ---
  # k8s/hpa.yaml (Horizontal Pod Autoscaler)
  apiVersion: autoscaling/v2
  kind: HorizontalPodAutoscaler
  metadata:
    name: yyc3-api-hpa
    namespace: yyc3-production
  spec:
    scaleTargetRef:
      apiVersion: apps/v1
      kind: Deployment
      name: yyc3-api
    minReplicas: 3
    maxReplicas: 10
    metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
    behavior:
      scaleDown:
        stabilizationWindowSeconds: 300
        policies:
        - type: Percent
          value: 50
          periodSeconds: 60
      scaleUp:
        stabilizationWindowSeconds: 0
        policies:
        - type: Percent
          value: 100
          periodSeconds: 15

--------

## 13. CI/CDæµæ°´çº¿æ„å»º

### 13.1 GitHub Actionså·¥ä½œæµ

  # .github/workflows/ci-cd.yml
  name: YYCÂ³ API CI/CD Pipeline

  on:
    push:
      branches: [ main, develop ]
    pull_request:
      branches: [ main ]
    release:
      types: [ created ]

  env:
    REGISTRY: registry.0379.email
    IMAGE_NAME: yyc3/api

  jobs:
    # Lintä¸æµ‹è¯•
    test:
      name: Code Quality & Tests
      runs-on: ubuntu-latest

      steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Lint with flake8
        run: |
          # åœæ­¢æ„å»ºå¦‚æœæœ‰Pythonè¯­æ³•é”™è¯¯æˆ–æœªå®šä¹‰çš„åç§°
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
          # é€€å‡ºé›¶å°†æ‰€æœ‰é”™è¯¯è§†ä¸ºè­¦å‘Š
          flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

      - name: Type check with mypy
        run: mypy --ignore-missing-imports .

      - name: Security check with bandit
        run: bandit -r . -f json -o bandit-report.json || true

      - name: Run Unit Tests
        run: pytest --cov=. --cov-report=xml --cov-report=html

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella

      - name: Upload Security Report
        uses: actions/upload-artifact@v3
        with:
          name: security-report
          path: bandit-report.json

    # æ„å»ºé•œåƒ
    build:
      name: Build Docker Image
      needs: test
      runs-on: ubuntu-latest
      outputs:
        image-tag: ${{ steps.meta.outputs.tags }}
        image-digest: ${{ steps.build.outputs.digest }}

      steps:
      - uses: actions/checkout@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Log in to Container Registry
        uses: docker/login-action@v2
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ secrets.REGISTRY_USER }}
          password: ${{ secrets.REGISTRY_PASSWORD }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v4
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,prefix=

      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache
          cache-to: type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache,mode=max
          build-args: |
            BUILD_DATE=${{ github.event.head_commit.timestamp }}
            VCS_REF=${{ github.sha }}
            VERSION=${{ steps.meta.outputs.version }}

    # éƒ¨ç½²åˆ°Stagingç¯å¢ƒ
    deploy-staging:
      name: Deploy to Staging
      needs: build
      runs-on: ubuntu-latest
      if: github.ref == 'refs/heads/develop'
      environment:
        name: staging
        url: https://staging-api.0379.email

      steps:
      - uses: actions/checkout@v3

      - name: Configure kubectl
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBE_CONFIG_STAGING }}" | base64 -d > $HOME/.kube/config

      - name: Deploy to Kubernetes
        run: |
          kubectl set image deployment/yyc3-api \
            api=${{ needs.build.outputs.image-tag }} \
            -n yyc3-staging
          kubectl rollout status deployment/yyc3-api -n yyc3-staging

      - name: Run smoke tests
        run: |
          kubectl run smoke-test --image=curlimages/curl --rm -i --restart=Never -- \
            curl -f https://staging-api.0379.email/api/v2/health || exit 1

    # éƒ¨ç½²åˆ°Productionç¯å¢ƒ
    deploy-production:
      name: Deploy to Production
      needs: build
      runs-on: ubuntu-latest
      if: github.event_name == 'release'
      environment:
        name: production
        url: https://api.0379.email

      steps:
      - uses: actions/checkout@v3

      - name: Configure kubectl
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBE_CONFIG_PROD }}" | base64 -d > $HOME/.kube/config

      - name: Canary Deployment (10%)
        run: |
          # é‡‘ä¸é›€å‘å¸ƒç­–ç•¥ï¼šå…ˆæ›´æ–°10%çš„æµé‡
          kubectl patch deployment yyc3-api -n yyc3-production -p '{"spec":{"replicas": 10}}' # å‡è®¾æ€»å‰¯æœ¬æ•°ä¸º10
          # æ›´æ–°é•œåƒ
          kubectl set image deployment/yyc3-api \
            api=${{ needs.build.outputs.image-tag }} \
            -n yyc3-production
          kubectl rollout status deployment/yyc3-api -n yyc3-production

      - name: Wait for approval
        uses: trstringer/manual-approval@v1
        with:
          secret: ${{ secrets.GITHUB_TOKEN }}
          approvers: admin,devops-lead
          minimum-approvals: 1
          timeout-minutes: 30

      - name: Full Rollout (100%)
        run: |
          kubectl patch deployment yyc3-api -n yyc3-production -p '{"spec":{"replicas": 10}}'
          kubectl rollout status deployment/yyc3-api -n yyc3-production

      - name: Post-deployment tests
        run: |
          python tests/api/integration_tests.py --env production

--------

## 14. æ„å»º"äº”é«˜äº”æ ‡äº”åŒ–"ä¼ä¸šçº§ä½“ç³»

æœ¬ç« èŠ‚å°†æ·±å…¥é˜è¿°å¦‚ä½•é€šè¿‡ä¸Šè¿°APIæ¶æ„ï¼Œè½åœ°å®æ–½"äº”é«˜äº”æ ‡äº”åŒ–"çš„ä¼ä¸šçº§æŠ€æœ¯æ ‡å‡†ã€‚

### 14.1 äº”é«˜ (High - High Availability, Performance, Concurrency, Security, Scalability)

#### ğŸ”´ é«˜å¯ç”¨æ€§

â€¢ å¤šå®ä¾‹éƒ¨ç½²: Docker/K8s éƒ¨ç½²ä¸å°‘äº3ä¸ªå‰¯æœ¬ï¼Œç¡®ä¿å•ç‚¹æ•…éšœä¸å½±å“æœåŠ¡ã€‚
â€¢ å¥åº·æ£€æŸ¥: å®ç°äº†  /health ,  /ready  å’Œ  /live  ä¸‰çº§æ¢é’ˆï¼Œé…åˆK8så­˜æ´»æ€§å’Œå°±ç»ªæ€§æ¢é’ˆã€‚
â€¢ æ•…éšœè½¬ç§»: APIæä¾›äº†  /api/v2/ha/failover  ç«¯ç‚¹ï¼Œç»“åˆK8s HPAï¼ˆè‡ªåŠ¨æ‰©ç¼©å®¹ï¼‰å’ŒPDBï¼ˆPodä¸­æ–­é¢„ç®—ï¼‰å®ç°æ— ç¼åˆ‡æ¢ã€‚
â€¢ æ•°æ®å¤‡ä»½: é›†æˆæ•°æ®åº“å¤‡ä»½æœåŠ¡å’ŒRedisæŒä¹…åŒ–ç­–ç•¥ã€‚

#### ğŸ”´ é«˜æ€§èƒ½

â€¢ ç¼“å­˜ç­–ç•¥: å…¨é¢é›†æˆRedisç¼“å­˜ï¼Œæ”¯æŒTTLè®¾ç½®å’ŒLRUæ·˜æ±°ç­–ç•¥ã€‚
â€¢ è¿æ¥æ± : æ•°æ®åº“å’ŒRediså‡ä½¿ç”¨è¿æ¥æ± å¤ç”¨ã€‚
â€¢ å¼‚æ­¥å¤„ç†: ä½¿ç”¨Celeryæˆ–åå°çº¿ç¨‹å¤„ç†è€—æ—¶ä»»åŠ¡ï¼ˆå¦‚DDNSæ›´æ–°ã€æ—¥å¿—åˆ†æï¼‰ã€‚
â€¢ å“åº”å‹ç¼©: Nginxé…ç½®Gzipå‹ç¼©ï¼Œå‡å°‘ä¼ è¾“è´Ÿè½½ã€‚

#### ğŸ”´ é«˜å¹¶å‘

â€¢ I/Oæ¨¡å‹: Flaské…åˆGunicornä½¿ç”¨Gevent/Eventletå¼‚æ­¥Workerã€‚
â€¢ WebSocketæ”¯æŒ: æä¾›é•¿è¿æ¥èƒ½åŠ›ï¼Œæ”¯æŒæ•°åƒå¹¶å‘è¿æ¥å®æ—¶æ¨é€ã€‚
â€¢ è´Ÿè½½å‡è¡¡: Nginxåå‘è½®è¯¢/æœ€å°‘è¿æ¥è´Ÿè½½å‡è¡¡ï¼ŒK8s Serviceé›†ç¾¤IPè´Ÿè½½åˆ†å‘ã€‚
â€¢ æ— çŠ¶æ€è®¾è®¡: APIè®¾è®¡ä¸ºæ— çŠ¶æ€ï¼Œä¾¿äºæ°´å¹³æ‰©å±•ã€‚

#### ğŸ”´ é«˜å®‰å…¨æ€§

â€¢ å¤šé‡è®¤è¯: æ”¯æŒJWT (OAuth2) å’Œ API Key åŒé‡è®¤è¯æœºåˆ¶ã€‚
â€¢ åŠ å¯†ä¼ è¾“: å¼ºåˆ¶HTTPS (TLS 1.3)ï¼Œé…ç½®ä¸¥æ ¼çš„HSTSå’ŒCSPå¤´ã€‚
â€¢ å¯†é’¥ç®¡ç†: Secrets Manager ç®¡ç†æ•æ„Ÿä¿¡æ¯ï¼Œæ”¯æŒå¯†é’¥è½®æ¢ ( /api/v2/secrets/key/rotate )ã€‚
â€¢ è®¿é—®æ§åˆ¶: ç»†ç²’åº¦çš„RBAC ( @role_required ) å’ŒScopeæ§åˆ¶ ( @scope_required )ã€‚

#### ğŸ”´ é«˜æ‰©å±•æ€§

â€¢ å¾®æœåŠ¡æ¶æ„: å°†DDNSã€ç›‘æ§ã€é…ç½®ã€åˆ†ææ‹†åˆ†ä¸ºç‹¬ç«‹æœåŠ¡ï¼Œç‹¬ç«‹æ‰©ç¼©å®¹ã€‚
â€¢ æ’ä»¶åŒ–è®¾è®¡: APIè“å›¾æœºåˆ¶å…è®¸åŠ¨æ€åŠ è½½æ–°æ¨¡å—ã€‚
â€¢ æ¶ˆæ¯é˜Ÿåˆ—é›†æˆ: é¢„ç•™RabbitMQ/Kafkaæ¥å£ç”¨äºæœåŠ¡è§£è€¦ã€‚
â€¢ å¼¹æ€§ä¼¸ç¼©: K8s HPAåŸºäºCPU/å†…å­˜/è‡ªå®šä¹‰æŒ‡æ ‡è‡ªåŠ¨è°ƒæ•´å‰¯æœ¬æ•°ã€‚

### 14.2 äº”æ ‡ (Standard - Interface, Doc, Error, Auth, Monitor)

#### ğŸ”µ æ ‡å‡†æ¥å£

â€¢ RESTfulè§„èŒƒ: ä¸¥æ ¼éµå¾ªRESTè®¾è®¡åŸåˆ™ï¼Œä½¿ç”¨æ ‡å‡†HTTPåŠ¨è¯ (GET/POST/PUT/DELETE)ã€‚
â€¢ ç‰ˆæœ¬æ§åˆ¶: URLè·¯å¾„ç‰ˆæœ¬åŒ– ( /api/v2/... )ï¼Œç¡®ä¿å‘åå…¼å®¹ã€‚
â€¢ æ•°æ®æ ¼å¼: ç»Ÿä¸€ä½¿ç”¨JSONè¯·æ±‚/å“åº”ä½“ï¼Œæ ‡å‡†åŒ–æ—¶é—´æ ¼å¼ (ISO 8601)ã€‚
â€¢ OpenAPI 3.0: å®Œæ•´çš„Swaggerè§„èŒƒå®šä¹‰ï¼Œæ”¯æŒæ¥å£å¥‘çº¦æµ‹è¯•ã€‚

#### ğŸ”µ æ ‡å‡†æ–‡æ¡£

â€¢ è‡ªåŠ¨åŒ–æ–‡æ¡£: é›†æˆSwagger UI ( /api/docs ) å’Œ ReDocã€‚
â€¢ ä»£ç æ³¨é‡Š: Python docstring è¯¦å°½æè¿°å‚æ•°ã€è¿”å›å€¼å’Œå¼‚å¸¸ã€‚
â€¢ å˜æ›´æ—¥å¿—: ç»´æŠ¤è¯¦ç»†çš„  CHANGELOG.md ï¼Œè®°å½•æ¯ä¸ªç‰ˆæœ¬çš„APIå˜æ›´ã€‚
â€¢ æœ€ä½³å®è·µ: æ¯ä¸ªæ¥å£æä¾›ä½¿ç”¨ç¤ºä¾‹ ( examples )ã€‚

#### ğŸ”µ æ ‡å‡†é”™è¯¯ç 

â€¢ ç»Ÿä¸€æ ¼å¼: æ‰€æœ‰é”™è¯¯å“åº”éµå¾ª  {success, error{code, message}, timestamp}  ç»“æ„ã€‚
â€¢ é”™è¯¯åˆ†ç±»: å®šä¹‰æ¸…æ™°çš„é”™è¯¯ä»£ç å‰ç¼€ (å¦‚  AUTH_ ,  RATE_LIMIT_ ,  VALIDATION_ )ã€‚
â€¢ å›½é™…åŒ–æ”¯æŒ: é”™è¯¯ä¿¡æ¯æ”¯æŒi18nå¤šè¯­è¨€ã€‚
â€¢ HTTPçŠ¶æ€ç æ˜ å°„: æ­£ç¡®æ˜ å°„ä¸šåŠ¡é”™è¯¯åˆ°HTTPçŠ¶æ€ç  (400, 401, 403, 404, 429, 500)ã€‚

#### ğŸ”µ æ ‡å‡†è®¤è¯

â€¢ OAuth2.0æ ‡å‡†: å®ç° RFC 6749 æ ‡å‡†ï¼Œæ”¯æŒæˆæƒç æ¨¡å¼ã€å®¢æˆ·ç«¯å‡­è¯æ¨¡å¼ã€‚
â€¢ JWTæ ‡å‡†: éµå¾ª RFC 7519ï¼ŒåŒ…å«æ ‡å‡†Claims (iss, sub, aud, exp, iat)ã€‚
â€¢ API Keyæ ‡å‡†: Headerä¼ é€’ ( X-API-Key )ï¼Œæ”¯æŒKey IDå’ŒSecretåˆ†ç¦»ã€‚
â€¢ SSOé›†æˆ: é¢„ç•™OIDCæ¥å£ï¼Œæ”¯æŒä¼ä¸šå•ç‚¹ç™»å½•ã€‚

#### ğŸ”µ æ ‡å‡†ç›‘æ§

â€¢ Metricsæ ‡å‡†: é›†æˆPrometheus  /metrics  ç«¯ç‚¹ï¼Œéµå¾ªå››å¤§æŒ‡æ ‡ç±»å‹ (Counter, Gauge, Histogram, Summary)ã€‚
â€¢ æ—¥å¿—æ ‡å‡†: ç»“æ„åŒ–JSONæ—¥å¿— (JSON Logging)ï¼ŒåŒ…å« trace_id, user_id, timestamp ç­‰æ ‡å‡†å­—æ®µã€‚
â€¢ é“¾è·¯è¿½è¸ª: é›†æˆOpenTelemetryï¼Œæ”¯æŒåˆ†å¸ƒå¼è¿½è¸ª (Distributed Tracing)ã€‚
â€¢ å‘Šè­¦æ ‡å‡†: Alertmanageræ ¼å¼å‘Šè­¦ï¼Œæ”¯æŒPromQLè§„åˆ™å®šä¹‰ã€‚

### 14.3 äº”åŒ– (Modernization - Container, Cloud, Auto, AI, Mesh)

#### ğŸŸ¢ å®¹å™¨åŒ–

â€¢ Dockeré•œåƒ: æ ‡å‡†åŒ–å¤šé˜¶æ®µæ„å»º (Multi-stage Build)ï¼Œæœ€å°åŒ–é•œåƒä½“ç§¯ã€‚
â€¢ Docker Compose: å¼€å‘ç¯å¢ƒä¸€é”®å¯åŠ¨ï¼Œå®šä¹‰å®Œæ•´çš„ç½‘ç»œå’Œå­˜å‚¨å·ã€‚
â€¢ é•œåƒä»“åº“: ä½¿ç”¨Harboræˆ–ç§æœ‰Registryç®¡ç†é•œåƒç”Ÿå‘½å‘¨æœŸã€‚
â€¢ ä¸å¯å˜åŸºç¡€è®¾æ–½: åŸºäºé•œåƒç‰ˆæœ¬éƒ¨ç½²ï¼Œé¿å…SSHç™»å½•ä¿®æ”¹é…ç½®ã€‚

#### ğŸŸ¢ äº‘åŸç”ŸåŒ–

â€¢ Kubernetesç¼–æ’: ç”Ÿäº§ç¯å¢ƒå®Œå…¨æ‰˜ç®¡äºK8sã€‚
â€¢ å£°æ˜å¼API: ä½¿ç”¨YAML/Jsonæè¿°æœŸæœ›çŠ¶æ€ï¼Œç”±K8sæ§åˆ¶å™¨ç»´æŠ¤ã€‚
â€¢ æœåŠ¡ç½‘æ ¼: è™½æœªå¼ºåˆ¶éƒ¨ç½²ï¼Œä½†æ¶æ„è®¾è®¡å…¼å®¹Istio/Linkerdï¼Œå¯æ— ç¼æ¥å…¥æµé‡ç®¡ç†ã€ç†”æ–­é™çº§ã€‚
â€¢ Serverlessé¢„ç•™: æ¶æ„æ”¯æŒå‘Serverless (å¦‚AWS Lambda/FaaS) è¿ç§»ã€‚

#### ğŸŸ¢ è‡ªåŠ¨åŒ–

â€¢ CI/CDæµæ°´çº¿: GitHub Actionså®ç°ä»ä»£ç æäº¤åˆ°ç”Ÿäº§éƒ¨ç½²çš„å…¨è‡ªåŠ¨æµæ°´çº¿ã€‚
â€¢ åŸºç¡€è®¾æ–½å³ä»£ç : Terraform/Ansibleç®¡ç†K8sé›†ç¾¤å’Œäº‘èµ„æºé…ç½®ã€‚
â€¢ è‡ªåŠ¨æµ‹è¯•: å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€E2Eæµ‹è¯•è‡ªåŠ¨æ‰§è¡Œã€‚
â€¢ è‡ªåŠ¨è¿ç»´: è‡ªåŠ¨åŒ–å¤‡ä»½ã€æ—¥å¿—è½®è½¬ã€è¯ä¹¦ç»­ç­¾ (ACME/Let's Encrypt)ã€‚

#### ğŸŸ¢ æ™ºèƒ½åŒ–

â€¢ LLMé›†æˆ: å†…ç½®AI Agentæ¥å£ ( /api/v2/llm )ï¼Œæ”¯æŒæ™ºèƒ½é—®ç­”å’Œè‡ªåŠ¨åŒ–è¿ç»´åŠ©æ‰‹ã€‚
â€¢ å¼‚å¸¸æ£€æµ‹: åŸºäºå†å²æ•°æ®çš„é¢„æµ‹åˆ†æ ( /api/v2/analytics/predictive )ï¼Œè‡ªåŠ¨å‘ç°å¼‚å¸¸æµé‡ã€‚
â€¢ æ™ºèƒ½æ—¥å¿—åˆ†æ: è‡ªåŠ¨è§£ææ—¥å¿—ï¼Œè¯†åˆ«é”™è¯¯æ¨¡å¼å¹¶ç”ŸæˆæŠ¥å‘Šã€‚
â€¢ è‡ªæ„ˆæœºåˆ¶: ç»“åˆK8s Operatorï¼Œé’ˆå¯¹ç‰¹å®šé”™è¯¯å®ç°è‡ªåŠ¨é‡å¯æˆ–é‡è¯•ã€‚

#### ğŸŸ¢ ç½‘æ ¼åŒ–

â€¢ æµé‡æ§åˆ¶: é€šè¿‡Ingresså’ŒService Meshç®¡ç†ç°åº¦å‘å¸ƒã€é‡‘ä¸é›€å‘å¸ƒã€‚
â€¢ æœåŠ¡å‘ç°: åŸºäºK8s DNSæœåŠ¡å‘ç°ï¼ŒåŠ¨æ€æ„ŸçŸ¥æœåŠ¡å®ä¾‹ã€‚
â€¢ ç»Ÿä¸€å…¥å£: API Gatewayä½œä¸ºç»Ÿä¸€æµé‡å…¥å£ï¼Œå¤„ç†é‰´æƒã€é™æµã€è·¯ç”±ã€‚
â€¢ Sidecaræ¨¡å¼: å®¹å™¨è®¾è®¡ä¸­é¢„ç•™Sidecarå®¹å™¨ä½ç½®ï¼Œç”¨äºè¿è¡Œä»£ç†ã€æ—¥å¿—é‡‡é›†ç­‰è¾…åŠ©è¿›ç¨‹ã€‚

--------

## 15. æ€»ç»“ä¸å±•æœ›

æœ¬APIè®¾è®¡æ–‡æ¡£æ„å»ºäº†ä¸€å¥—ç¬¦åˆ**"äº”é«˜äº”æ ‡äº”åŒ–"**ä¼ä¸šçº§æ ‡å‡†çš„NAS
DDNSç®¡ç†ç³»ç»Ÿã€‚é€šè¿‡æ¨¡å—åŒ–çš„å¾®æœåŠ¡æ¶æ„ã€ä¸¥å¯†çš„å®‰å…¨è®¤è¯ä½“ç³»ã€å®Œå–„çš„ç›‘æ§å‘Šè­¦æœºåˆ¶ä»¥åŠç°ä»£åŒ–çš„CI/CDæµæ°´çº¿ï¼Œä¸ä»…è§£å†³äº†åŸºç¡€DDN
Sè§£æéœ€æ±‚ï¼Œæ›´æä¾›äº†å¯æ‰©å±•ã€å¯ç»´æŠ¤ã€é«˜å¯ç”¨çš„ä¼ä¸šçº§å¹³å°ã€‚

æœªæ¥æ¼”è¿›æ–¹å‘ï¼š

1. Service Meshè½åœ°: å¼•å…¥Istioå®ç°æ›´ç»†ç²’åº¦çš„æµé‡æ²»ç†å’ŒmTLSåŠ å¯†ã€‚
2. ServerlessåŒ–: å°†éƒ¨åˆ†è§¦å‘å¼API (å¦‚DDNSæ›´æ–°) è¿ç§»è‡³Serverlesså‡½æ•°è®¡ç®—ï¼Œé™ä½æˆæœ¬ã€‚
3. è¾¹ç¼˜è®¡ç®—é›†æˆ: ç»“åˆFRPå’Œè¾¹ç¼˜èŠ‚ç‚¹ï¼Œå®ç°æ›´å¿«é€Ÿçš„DNSè§£æå“åº”ã€‚
4. AIè¿ç»´å¤§è„‘: è¿›ä¸€æ­¥åˆ©ç”¨LLMèƒ½åŠ›ï¼Œå®ç°å…¨é“¾è·¯æ™ºèƒ½æ•…éšœè‡ªæ„ˆã€‚

--------

  # æ–‡æ¡£ä¿®è®¢å†å²

  | ç‰ˆæœ¬ | æ—¥æœŸ | ä½œè€… | æè¿° |
  |------|------|------|------|
  | 2.0.0 | 2026-01-03 | YYCÂ³ | å®Œæ•´æ„å»ºäº”é«˜äº”æ ‡äº”åŒ–ä¼ä¸šçº§APIä½“ç³» |
  | 1.5.0 | 2025-11-02 | YYCÂ³ | å¢åŠ Dockerä¸K8séƒ¨ç½²é…ç½® |
  | 1.0.0 | 2025-01-30 | YYCÂ³ | åˆå§‹ç‰ˆæœ¬ï¼ŒåŸºç¡€APIè®¾è®¡ |

  ---
  **Â© 2026 YYCÂ³ (YanYuCloudCube) Enterprise API Design**
