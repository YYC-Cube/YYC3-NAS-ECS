# YYCÂ³ï¼ˆYanYuCloudCubeï¼‰NAS DDNS API å¿«é€Ÿå¼€å§‹æŒ‡å—

![Git Banner](../public/git_1800_450-6.png)

<div align="center">

[![YYCÂ³](https://img.shields.io/badge/YYCÂ³-äº”é«˜äº”æ ‡äº”åŒ–-blue)](https://github.com/YYC3)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/)
[![Flask](https://img.shields.io/badge/flask-3.0+-red.svg)](https://flask.palletsprojects.com/)
[![Docker](https://img.shields.io/badge/docker-20.10+-blue.svg)](https://www.docker.com/)
[![Docker Compose](https://img.shields.io/badge/docker--compose-2.0+-blue.svg)](https://docs.docker.com/compose/)
[![PostgreSQL](https://img.shields.io/badge/postgresql-15+-blue.svg)](https://www.postgresql.org/)
[![Redis](https://img.shields.io/badge/redis-7+-red.svg)](https://redis.io/)
[![API](https://img.shields.io/badge/api-v2.0-orange.svg)](https://ddns.0379.email/api/v2/docs)
[![Status](https://img.shields.io/badge/status-production-success.svg)](https://ddns.0379.email)
[![Quick Start](https://img.shields.io/badge/start-5%20min-brightgreen.svg)](#å¿«é€Ÿå¯åŠ¨)
[![Documentation](https://img.shields.io/badge/docs-complete-brightgreen.svg)](README.md)
[![Support](https://img.shields.io/badge/support-active-brightgreen.svg)](https://github.com/YYC3/issues)

**è¨€å¯è±¡é™ | è¯­æ¢æœªæ¥**
**ä¸‡è±¡å½’å…ƒäºäº‘æ¢ | æ·±æ ˆæ™ºå¯æ–°çºªå…ƒ**

</div>

---

## ğŸ“‹ ç›®å½•

- [å‰ç½®è¦æ±‚](#-å‰ç½®è¦æ±‚)
- [å¿«é€Ÿå¯åŠ¨](#-å¿«é€Ÿå¯åŠ¨)
- [è®¿é—®åœ°å€](#-è®¿é—®åœ°å€)
- [å¸¸ç”¨å‘½ä»¤](#-å¸¸ç”¨å‘½ä»¤)
- [é…ç½®è¯´æ˜](#-é…ç½®è¯´æ˜)
- [æ•…éšœæ’æŸ¥](#-æ•…éšœæ’æŸ¥)
- [API ä½¿ç”¨ç¤ºä¾‹](#-api-ä½¿ç”¨ç¤ºä¾‹)
- [ç”Ÿäº§éƒ¨ç½²å»ºè®®](#-ç”Ÿäº§éƒ¨ç½²å»ºè®®)
- [æ€§èƒ½ä¼˜åŒ–](#-æ€§èƒ½ä¼˜åŒ–)
- [å®‰å…¨é…ç½®](#-å®‰å…¨é…ç½®)
- [ä¸‹ä¸€æ­¥](#-ä¸‹ä¸€æ­¥)
- [è·å–å¸®åŠ©](#-è·å–å¸®åŠ©)

---

## ğŸš€ å‰ç½®è¦æ±‚

### ç³»ç»Ÿè¦æ±‚

| ç»„ä»¶ | æœ€ä½ç‰ˆæœ¬ | æ¨èç‰ˆæœ¬ | ç”¨é€” |
|------|----------|----------|------|
| **Docker** | 20.10+ | 24.0+ | å®¹å™¨è¿è¡Œæ—¶ |
| **Docker Compose** | 2.0+ | 2.23+ | å®¹å™¨ç¼–æ’ |
| **æ“ä½œç³»ç»Ÿ** | Linux/macOS/Windows | Ubuntu 22.04 LTS | è¿è¡Œç¯å¢ƒ |
| **CPU** | 2 æ ¸ | 4 æ ¸+ | å¤„ç†èƒ½åŠ› |
| **å†…å­˜** | 4GB | 8GB+ | è¿è¡Œå†…å­˜ |
| **ç£ç›˜ç©ºé—´** | 10GB | 20GB+ | å­˜å‚¨ç©ºé—´ |

### è½¯ä»¶ä¾èµ–

```bash
# æ£€æŸ¥ Docker ç‰ˆæœ¬
docker --version

# æ£€æŸ¥ Docker Compose ç‰ˆæœ¬
docker-compose --version

# æ£€æŸ¥ç³»ç»Ÿèµ„æº
free -h
df -h
```

### ç½‘ç»œè¦æ±‚

- ç¨³å®šçš„äº’è”ç½‘è¿æ¥ï¼ˆç”¨äºä¸‹è½½é•œåƒå’Œä¾èµ–ï¼‰
- å¼€æ”¾å¿…è¦çš„ç«¯å£ï¼ˆ8080, 5432, 6379, 9090, 3000ï¼‰
- å¦‚éœ€å¤–ç½‘è®¿é—®ï¼Œéœ€è¦é…ç½®åŸŸåå’Œ DNS è§£æ

### æƒé™è¦æ±‚

- Docker è¿è¡Œæƒé™ï¼ˆé root ç”¨æˆ·éœ€è¦æ·»åŠ åˆ° docker ç»„ï¼‰
- æ–‡ä»¶ç³»ç»Ÿè¯»å†™æƒé™
- ç½‘ç»œé…ç½®æƒé™ï¼ˆå¦‚éœ€ä¿®æ”¹é˜²ç«å¢™è§„åˆ™ï¼‰

---

## âš¡ å¿«é€Ÿå¯åŠ¨

### 1. å…‹éš†é¡¹ç›®

```bash
# å…‹éš†é¡¹ç›®ä»“åº“
git clone <repository-url>
cd nas-ddns-api

# æˆ–è€…ä¸‹è½½å‹ç¼©åŒ…
wget <download-url>
unzip <zip-file>
cd nas-ddns-api
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘ç¯å¢ƒå˜é‡æ–‡ä»¶
nano .env
# æˆ–ä½¿ç”¨å…¶ä»–ç¼–è¾‘å™¨
vim .env
# æˆ–
code .env
```

#### å¿…éœ€é…ç½®é¡¹

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œè®¾ç½®ä»¥ä¸‹å¿…è¦é…ç½®ï¼š

```bash
# ========================================
# é˜¿é‡Œäº‘é…ç½®ï¼ˆå¿…éœ€ï¼‰
# ========================================
ALIYUN_ACCESS_KEY_ID=your_access_key_id
ALIYUN_ACCESS_KEY_SECRET=your_access_key_secret
ALIYUN_DOMAIN=your_domain.com
ALIYUN_SUB_DOMAIN=ddns

# ========================================
# æœåŠ¡å™¨é…ç½®ï¼ˆå¿…éœ€ï¼‰
# ========================================
NAS_SERVER_IP=your_server_ip
NAS_DOMAIN=ddns.your_domain.com

# ========================================
# è¿è¡Œç¯å¢ƒé…ç½®
# ========================================
ENVIRONMENT=production    # development, production, testing
API_PORT=8080
DEBUG=false
LOG_LEVEL=info

# ========================================
# æ•°æ®åº“é…ç½®
# ========================================
POSTGRES_DB=nas_ddns
POSTGRES_USER=nas_admin
POSTGRES_PASSWORD=your_secure_password

# ========================================
# Redis é…ç½®
# ========================================
REDIS_PASSWORD=your_redis_password

# ========================================
# ç›‘æ§é…ç½®
# ========================================
GRAFANA_ADMIN_PASSWORD=your_grafana_password
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000

# ========================================
# å®‰å…¨é…ç½®
# ========================================
JWT_SECRET_KEY=your_jwt_secret_key_min_32_chars
API_RATE_LIMIT=100
```

#### é…ç½®è¯´æ˜

| é…ç½®é¡¹ | è¯´æ˜ | å¿…éœ€ | é»˜è®¤å€¼ |
|--------|------|------|--------|
| `ALIYUN_ACCESS_KEY_ID` | é˜¿é‡Œäº‘è®¿é—®å¯†é’¥ ID | âœ… | - |
| `ALIYUN_ACCESS_KEY_SECRET` | é˜¿é‡Œäº‘è®¿é—®å¯†é’¥ Secret | âœ… | - |
| `ALIYUN_DOMAIN` | ä¸»åŸŸå | âœ… | - |
| `ALIYUN_SUB_DOMAIN` | å­åŸŸå | âœ… | ddns |
| `NAS_SERVER_IP` | æœåŠ¡å™¨ IP åœ°å€ | âœ… | - |
| `NAS_DOMAIN` | DDNS åŸŸå | âœ… | - |
| `ENVIRONMENT` | è¿è¡Œç¯å¢ƒ | âŒ | production |
| `API_PORT` | API ç«¯å£ | âŒ | 8080 |
| `DEBUG` | è°ƒè¯•æ¨¡å¼ | âŒ | false |
| `LOG_LEVEL` | æ—¥å¿—çº§åˆ« | âŒ | info |

### 3. å¯åŠ¨æœåŠ¡

#### æ–¹å¼ä¸€ï¼šä½¿ç”¨å¿«é€Ÿå¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# èµ‹äºˆæ‰§è¡Œæƒé™
chmod +x start.sh

# å¯åŠ¨æ‰€æœ‰æœåŠ¡
./start.sh

# æŸ¥çœ‹å¯åŠ¨æ—¥å¿—
docker-compose logs -f
```

#### æ–¹å¼äºŒï¼šä½¿ç”¨å®Œæ•´éƒ¨ç½²è„šæœ¬

```bash
# èµ‹äºˆæ‰§è¡Œæƒé™
chmod +x deploy.sh

# æ‰§è¡Œå®Œæ•´éƒ¨ç½²ï¼ˆåŒ…æ‹¬æ•°æ®åº“åˆå§‹åŒ–ï¼‰
./deploy.sh

# éƒ¨ç½²è„šæœ¬ä¼šè‡ªåŠ¨æ‰§è¡Œï¼š
# 1. æ‹‰å– Docker é•œåƒ
# 2. åˆ›å»ºå¿…è¦çš„ç›®å½•
# 3. åˆå§‹åŒ–æ•°æ®åº“
# 4. å¯åŠ¨æ‰€æœ‰æœåŠ¡
# 5. è¿è¡Œå¥åº·æ£€æŸ¥
```

#### æ–¹å¼ä¸‰ï¼šæ‰‹åŠ¨å¯åŠ¨

```bash
# æ‹‰å–æœ€æ–°é•œåƒ
docker-compose pull

# æ„å»ºè‡ªå®šä¹‰é•œåƒï¼ˆå¦‚æœéœ€è¦ï¼‰
docker-compose build

# å¯åŠ¨æ‰€æœ‰æœåŠ¡ï¼ˆåå°è¿è¡Œï¼‰
docker-compose up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹å¯åŠ¨æ—¥å¿—
docker-compose logs -f api
```

#### å¯åŠ¨æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        å¯åŠ¨æµç¨‹                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®                                         â”‚
â”‚  2. æ‹‰å– Docker é•œåƒ                                        â”‚
â”‚  3. åˆ›å»ºç½‘ç»œå’Œå·                                            â”‚
â”‚  4. å¯åŠ¨ PostgreSQL æ•°æ®åº“                                  â”‚
â”‚  5. å¯åŠ¨ Redis ç¼“å­˜æœåŠ¡                                     â”‚
â”‚  6. åˆå§‹åŒ–æ•°æ®åº“ç»“æ„                                        â”‚
â”‚  7. å¯åŠ¨ Flask API æœåŠ¡                                     â”‚
â”‚  8. å¯åŠ¨ Prometheus ç›‘æ§                                    â”‚
â”‚  9. å¯åŠ¨ Grafana å¯è§†åŒ–                                     â”‚
â”‚ 10. è¿è¡Œå¥åº·æ£€æŸ¥                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. éªŒè¯æœåŠ¡

#### è‡ªåŠ¨éªŒè¯

```bash
# è¿è¡Œ API æµ‹è¯•è„šæœ¬
chmod +x scripts/test_api.sh
./scripts/test_api.sh
```

#### æ‰‹åŠ¨éªŒè¯

```bash
# æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€
curl http://localhost:8080/api/v2/health

# æ£€æŸ¥ DDNS çŠ¶æ€
curl http://localhost:8080/api/v2/ddns/status

# æ£€æŸ¥ API ç‰ˆæœ¬
curl http://localhost:8080/api/v2/version

# æ£€æŸ¥ç³»ç»Ÿç›‘æ§
curl http://localhost:8080/api/v2/monitoring/system
```

#### é¢„æœŸå“åº”

å¥åº·æ£€æŸ¥æˆåŠŸå“åº”ç¤ºä¾‹ï¼š

```json
{
  "status": "healthy",
  "version": "2.0.0",
  "timestamp": "2025-01-30T12:00:00Z",
  "services": {
    "database": "connected",
    "redis": "connected",
    "aliyun": "connected"
  }
}
```

---

## ğŸŒ è®¿é—®åœ°å€

å¯åŠ¨æˆåŠŸåï¼Œå¯ä»¥è®¿é—®ä»¥ä¸‹åœ°å€ï¼š

| æœåŠ¡ | åœ°å€ | è¯´æ˜ | è®¤è¯ |
|------|------|------|------|
| **ä¸» API** | http://localhost:8080/ | RESTful API | JWT |
| **API æ–‡æ¡£** | http://localhost:8080/api/v2/docs | Swagger æ–‡æ¡£ | æ— éœ€è®¤è¯ |
| **å¥åº·æ£€æŸ¥** | http://localhost:8080/api/v2/health | æœåŠ¡å¥åº·çŠ¶æ€ | æ— éœ€è®¤è¯ |
| **Prometheus** | http://localhost:9090 | ç›‘æ§æŒ‡æ ‡ | æ— éœ€è®¤è¯ |
| **Grafana** | http://localhost:3000 | ç›‘æ§é¢æ¿ | admin/admin |

### æœåŠ¡è®¿é—®è¯´æ˜

#### API æ–‡æ¡£

è®¿é—® Swagger æ–‡æ¡£é¡µé¢ï¼Œå¯ä»¥ï¼š

- æŸ¥çœ‹æ‰€æœ‰ API ç«¯ç‚¹
- æµ‹è¯• API è¯·æ±‚
- æŸ¥çœ‹è¯·æ±‚/å“åº”ç¤ºä¾‹
- åœ¨çº¿è°ƒè¯• API

#### Prometheus

Prometheus æä¾›ä»¥ä¸‹åŠŸèƒ½ï¼š

- æŸ¥è¯¢ç›‘æ§æŒ‡æ ‡
- æŸ¥çœ‹ç›®æ ‡çŠ¶æ€
- æ‰§è¡Œ PromQL æŸ¥è¯¢
- å¯¼å‡ºç›‘æ§æ•°æ®

#### Grafana

Grafana é»˜è®¤ç™»å½•ä¿¡æ¯ï¼š

- ç”¨æˆ·åï¼š`admin`
- å¯†ç ï¼š`admin`ï¼ˆé¦–æ¬¡ç™»å½•åéœ€ä¿®æ”¹ï¼‰

åŠŸèƒ½åŒ…æ‹¬ï¼š

- åˆ›å»ºè‡ªå®šä¹‰ä»ªè¡¨æ¿
- å¯è§†åŒ–ç›‘æ§æ•°æ®
- è®¾ç½®å‘Šè­¦è§„åˆ™
- å¯¼å…¥é¢„ç½®ä»ªè¡¨æ¿

---

## ğŸ› ï¸ å¸¸ç”¨å‘½ä»¤

### æœåŠ¡ç®¡ç†

```bash
# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ‰€æœ‰æœåŠ¡æ—¥å¿—
docker-compose logs -f

# æŸ¥çœ‹ API æœåŠ¡æ—¥å¿—
docker-compose logs -f api

# é‡å¯æ‰€æœ‰æœåŠ¡
docker-compose restart

# é‡å¯ç‰¹å®šæœåŠ¡
docker-compose restart api

# åœæ­¢æœåŠ¡
docker-compose stop

# åœæ­¢å¹¶åˆ é™¤å®¹å™¨
docker-compose down

# å®Œå…¨æ¸…ç†ï¼ˆåŒ…æ‹¬æ•°æ®å·ï¼‰
docker-compose down -v

# é‡æ–°æ„å»ºå¹¶å¯åŠ¨
docker-compose up -d --build

# æŸ¥çœ‹èµ„æºä½¿ç”¨æƒ…å†µ
docker stats
```

### æ•°æ®åº“ç®¡ç†

```bash
# åˆå§‹åŒ–æ•°æ®åº“
docker-compose exec api flask db upgrade

# åˆ›å»ºç®¡ç†å‘˜ç”¨æˆ·
docker-compose exec api flask create-admin

# å¡«å……æµ‹è¯•æ•°æ®
docker-compose exec api flask seed

# è¿›å…¥æ•°æ®åº“å‘½ä»¤è¡Œ
docker-compose exec postgres psql -U nas_admin -d nas_ddns

# æ‰§è¡Œ SQL è„šæœ¬
docker-compose exec -T postgres psql -U nas_admin -d nas_ddns < script.sql

# å¤‡ä»½æ•°æ®åº“
docker-compose exec postgres pg_dump -U nas_admin nas_ddns > backup.sql

# æŸ¥çœ‹æ•°æ®åº“å¤§å°
docker-compose exec postgres psql -U nas_admin -d nas_ddns -c "SELECT pg_size_pretty(pg_database_size('nas_ddns'));"
```

### Redis ç®¡ç†

```bash
# è¿›å…¥ Redis å‘½ä»¤è¡Œ
docker-compose exec redis redis-cli

# æµ‹è¯• Redis è¿æ¥
docker-compose exec redis redis-cli ping

# æŸ¥çœ‹æ‰€æœ‰é”®
docker-compose exec redis redis-cli KEYS '*'

# æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
docker-compose exec redis redis-cli FLUSHALL

# æŸ¥çœ‹å†…å­˜ä½¿ç”¨
docker-compose exec redis redis-cli INFO memory

# ç›‘æ§ Redis å‘½ä»¤
docker-compose exec redis redis-cli MONITOR
```

### å¤‡ä»½ä¸æ¢å¤

```bash
# æ‰§è¡Œå®Œæ•´å¤‡ä»½
docker-compose exec api python scripts/backup.sh

# ä»…å¤‡ä»½æ•°æ®åº“
docker-compose exec postgres pg_dump -U nas_admin nas_ddns > db_backup.sql

# ä»…å¤‡ä»½é…ç½®
tar -czf config_backup.tar.gz .env docker-compose.yml

# æ¢å¤æ•°æ®åº“
docker-compose exec -T postgres psql -U nas_admin -d nas_ddns < db_backup.sql

# æ¢å¤æ•°æ®åº“ï¼ˆä½¿ç”¨ pg_restoreï¼‰
docker-compose exec -T postgres pg_restore -d nas_ddns -U nas_admin /backup/database.dump

# æ¢å¤é…ç½®
tar -xzf config_backup.tar.gz
```

### ç›‘æ§ä¸è°ƒè¯•

```bash
# æŸ¥çœ‹ API æ—¥å¿—ï¼ˆå®æ—¶ï¼‰
docker-compose logs -f api

# æŸ¥çœ‹æ‰€æœ‰æœåŠ¡æ—¥å¿—ï¼ˆå®æ—¶ï¼‰
docker-compose logs -f

# æŸ¥çœ‹æœ€è¿‘ 100 è¡Œæ—¥å¿—
docker-compose logs --tail=100 api

# è¿›å…¥ API å®¹å™¨
docker-compose exec api bash

# è¿›å…¥æ•°æ®åº“å®¹å™¨
docker-compose exec postgres bash

# æŸ¥çœ‹å®¹å™¨èµ„æºä½¿ç”¨
docker-compose top

# æŸ¥çœ‹å®¹å™¨ç½‘ç»œ
docker network ls
docker network inspect nas-ddns-api_default

# æ£€æŸ¥å®¹å™¨å¥åº·çŠ¶æ€
docker-compose ps
```

### æ—¥å¿—ç®¡ç†

```bash
# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
docker-compose logs api | grep ERROR

# æŸ¥çœ‹è­¦å‘Šæ—¥å¿—
docker-compose logs api | grep WARNING

# å¯¼å‡ºæ—¥å¿—åˆ°æ–‡ä»¶
docker-compose logs api > api.log

# æ¸…ç†æ—¥å¿—
docker-compose logs --tail=0 api

# æŸ¥çœ‹ç‰¹å®šæ—¶é—´æ®µçš„æ—¥å¿—
docker-compose logs --since="2025-01-30T00:00:00" --until="2025-01-30T23:59:59" api
```

---

## âš™ï¸ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡

ä¸»è¦é…ç½®é¡¹ä½äº `.env` æ–‡ä»¶ï¼š

```bash
# ========================================
# è¿è¡Œç¯å¢ƒ
# ========================================
ENVIRONMENT=production    # development, production, testing

# ========================================
# API é…ç½®
# ========================================
API_PORT=8080
DEBUG=false
LOG_LEVEL=info           # debug, info, warning, error, critical

# ========================================
# æ•°æ®åº“é…ç½®
# ========================================
POSTGRES_DB=nas_ddns
POSTGRES_USER=nas_admin
POSTGRES_PASSWORD=your_secure_password
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# ========================================
# Redis é…ç½®
# ========================================
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=your_redis_password
REDIS_DB=0

# ========================================
# é˜¿é‡Œäº‘é…ç½®
# ========================================
ALIYUN_ACCESS_KEY_ID=your_key
ALIYUN_ACCESS_KEY_SECRET=your_secret
ALIYUN_DOMAIN=your_domain.com
ALIYUN_SUB_DOMAIN=ddns
ALIYUN_RECORD_TYPE=A
ALIYUN_TTL=600

# ========================================
# ç›‘æ§é…ç½®
# ========================================
GRAFANA_ADMIN_PASSWORD=admin
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000

# ========================================
# å®‰å…¨é…ç½®
# ========================================
JWT_SECRET_KEY=your_jwt_secret_key_min_32_chars
JWT_ACCESS_TOKEN_EXPIRES=3600
JWT_REFRESH_TOKEN_EXPIRES=2592000
API_RATE_LIMIT=100
CORS_ORIGINS=*

# ========================================
# DDNS é…ç½®
# ========================================
DDNS_UPDATE_INTERVAL=300
DDNS_CHECK_INTERVAL=60
DDNS_IP_CHECK_URL=https://api.ipify.org

# ========================================
# å‘Šè­¦é…ç½®
# ========================================
ALERT_EMAIL_ENABLED=true
ALERT_EMAIL_SMTP_HOST=smtp.gmail.com
ALERT_EMAIL_SMTP_PORT=587
ALERT_EMAIL_USERNAME=your_email@gmail.com
ALERT_EMAIL_PASSWORD=your_email_password
ALERT_EMAIL_FROM=noreply@your_domain.com
ALERT_EMAIL_TO=admin@your_domain.com
```

### é…ç½®æ–‡ä»¶è¯´æ˜

| æ–‡ä»¶ | è¯´æ˜ | ä¼˜å…ˆçº§ |
|------|------|--------|
| `.env` | ç¯å¢ƒå˜é‡é…ç½® | æœ€é«˜ |
| `.env.example` | ç¯å¢ƒå˜é‡æ¨¡æ¿ | - |
| `docker-compose.yml` | Docker Compose é…ç½® | ä¸­ |
| `config/config.py` | åº”ç”¨é…ç½® | ä½ |
| `config/production.py` | ç”Ÿäº§ç¯å¢ƒé…ç½® | ä½ |
| `config/development.py` | å¼€å‘ç¯å¢ƒé…ç½® | ä½ |

### è°ƒæ•´èµ„æºé…ç½®

ç¼–è¾‘ `docker-compose.yml` ä¸­çš„èµ„æºé…ç½®ï¼š

```yaml
services:
  api:
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    environment:
      - WORKERS=4
      - THREADS=2

  postgres:
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    command:
      - "postgres"
      - "-c"
      - "max_connections=200"
      - "-c"
      - "shared_buffers=512MB"
      - "-c"
      - "effective_cache_size=2GB"

  redis:
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    command:
      - "redis-server"
      - "--maxmemory"
      - "512mb"
      - "--maxmemory-policy"
      - "allkeys-lru"
```

### Nginx é…ç½®ç¤ºä¾‹

å¦‚æœä½¿ç”¨ Nginx ä½œä¸ºåå‘ä»£ç†ï¼Œé…ç½®ç¤ºä¾‹ï¼š

```nginx
server {
    listen 80;
    server_name ddns.your_domain.com;

    # é‡å®šå‘åˆ° HTTPS
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name ddns.your_domain.com;

    # SSL è¯ä¹¦é…ç½®
    ssl_certificate /etc/ssl/certs/your_domain.crt;
    ssl_certificate_key /etc/ssl/private/your_domain.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;

    # API ä»£ç†
    location / {
        proxy_pass http://localhost:8080;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # è¶…æ—¶é…ç½®
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }

    # WebSocket æ”¯æŒ
    location /ws {
        proxy_pass http://localhost:8080;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }

    # é™æ€æ–‡ä»¶ç¼“å­˜
    location /static {
        alias /path/to/static/files;
        expires 30d;
        add_header Cache-Control "public, immutable";
    }
}
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### æœåŠ¡æ— æ³•å¯åŠ¨

**ç—‡çŠ¶**ï¼šæœåŠ¡å¯åŠ¨å¤±è´¥æˆ–ç«‹å³é€€å‡º

**è¯Šæ–­æ­¥éª¤**ï¼š

```bash
# æ£€æŸ¥ç«¯å£å ç”¨
lsof -i :8080
lsof -i :5432
lsof -i :6379
lsof -i :9090
lsof -i :3000

# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
docker-compose logs --tail=100 api
docker-compose logs --tail=100 postgres
docker-compose logs --tail=100 redis

# æ£€æŸ¥ç£ç›˜ç©ºé—´
df -h

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
free -h

# æ£€æŸ¥ Docker çŠ¶æ€
docker ps -a
docker system df
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# 1. åœæ­¢å ç”¨ç«¯å£çš„è¿›ç¨‹
kill -9 <PID>

# 2. æ¸…ç† Docker èµ„æº
docker system prune -a

# 3. é‡æ–°å¯åŠ¨æœåŠ¡
docker-compose down -v
docker-compose up -d

# 4. æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®
cat .env | grep -v '^#' | grep -v '^$'

# 5. éªŒè¯ Docker ç½‘ç»œè¿æ¥
docker network inspect nas-ddns-api_default
```

### æ•°æ®åº“è¿æ¥å¤±è´¥

**ç—‡çŠ¶**ï¼šAPI æ— æ³•è¿æ¥åˆ° PostgreSQL æ•°æ®åº“

**è¯Šæ–­æ­¥éª¤**ï¼š

```bash
# æ£€æŸ¥ PostgreSQL çŠ¶æ€
docker-compose ps postgres

# æµ‹è¯•æ•°æ®åº“è¿æ¥
docker-compose exec postgres pg_isready

# æŸ¥çœ‹ PostgreSQL æ—¥å¿—
docker-compose logs postgres

# æ£€æŸ¥æ•°æ®åº“è¿æ¥é…ç½®
docker-compose exec api env | grep POSTGRES

# æµ‹è¯•ä» API å®¹å™¨è¿æ¥æ•°æ®åº“
docker-compose exec api ping -c 3 postgres
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# 1. é‡å¯ PostgreSQL æœåŠ¡
docker-compose restart postgres

# 2. æ£€æŸ¥æ•°æ®åº“å‡­è¯
docker-compose exec postgres psql -U nas_admin -d nas_ddns -c "SELECT version();"

# 3. é‡æ–°åˆå§‹åŒ–æ•°æ®åº“
docker-compose exec api flask db upgrade

# 4. æ£€æŸ¥ç½‘ç»œè¿æ¥
docker-compose exec api nc -zv postgres 5432

# 5. éªŒè¯æ•°æ®åº“æƒé™
docker-compose exec postgres psql -U nas_admin -d nas_ddns -c "\l"
```

### Redis è¿æ¥é—®é¢˜

**ç—‡çŠ¶**ï¼šAPI æ— æ³•è¿æ¥åˆ° Redis ç¼“å­˜

**è¯Šæ–­æ­¥éª¤**ï¼š

```bash
# æ£€æŸ¥ Redis çŠ¶æ€
docker-compose ps redis

# æµ‹è¯• Redis è¿æ¥
docker-compose exec redis redis-cli ping

# æŸ¥çœ‹ Redis æ—¥å¿—
docker-compose logs redis

# æ£€æŸ¥ Redis é…ç½®
docker-compose exec redis redis-cli CONFIG GET '*'

# æµ‹è¯•ä» API å®¹å™¨è¿æ¥ Redis
docker-compose exec api nc -zv redis 6379
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# 1. é‡å¯ Redis æœåŠ¡
docker-compose restart redis

# 2. æµ‹è¯• Redis å‘½ä»¤
docker-compose exec redis redis-cli SET test "hello"
docker-compose exec redis redis-cli GET test

# 3. æ¸…ç©º Redis ç¼“å­˜
docker-compose exec redis redis-cli FLUSHALL

# 4. æ£€æŸ¥ Redis å¯†ç é…ç½®
docker-compose exec redis redis-cli -a your_password PING

# 5. éªŒè¯ Redis å†…å­˜ä½¿ç”¨
docker-compose exec redis redis-cli INFO memory
```

### DDNS æ›´æ–°å¤±è´¥

**ç—‡çŠ¶**ï¼šDDNS è®°å½•æ— æ³•æ›´æ–°æˆ–æ›´æ–°å¤±è´¥

**è¯Šæ–­æ­¥éª¤**ï¼š

```bash
# æ£€æŸ¥é˜¿é‡Œäº‘å‡­æ®
docker-compose exec api python -c "from app.utils.aliyun import test_credentials; test_credentials()"

# æŸ¥çœ‹ DDNS æ—¥å¿—
docker-compose logs api | grep ddns

# æ£€æŸ¥å½“å‰ IP åœ°å€
curl https://api.ipify.org

# æŸ¥çœ‹åŸŸå DNS è®°å½•
nslookup ddns.your_domain.com

# æ£€æŸ¥ API é…ç½®
docker-compose exec api env | grep ALIYUN
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# 1. éªŒè¯é˜¿é‡Œäº‘è®¿é—®å¯†é’¥
docker-compose exec api python -c "
import os
from app.utils.aliyun import AliyunDDNS
print('Access Key ID:', os.getenv('ALIYUN_ACCESS_KEY_ID'))
print('Domain:', os.getenv('ALIYUN_DOMAIN'))
print('Sub Domain:', os.getenv('ALIYUN_SUB_DOMAIN'))
"

# 2. æ‰‹åŠ¨è§¦å‘ DDNS æ›´æ–°
docker-compose exec api python -c "
from app.utils.aliyun import AliyunDDNS
ddns = AliyunDDNS()
result = ddns.update_ddns()
print('Update result:', result)
"

# 3. æ£€æŸ¥åŸŸåè§£æ
nslookup ddns.your_domain.com
dig ddns.your_domain.com

# 4. éªŒè¯ IP åœ°å€
curl https://api.ipify.org
curl https://api64.ipify.org

# 5. æŸ¥çœ‹é˜¿é‡Œäº‘ DNS è®°å½•
docker-compose exec api python -c "
from app.utils.aliyun import AliyunDDNS
ddns = AliyunDDNS()
records = ddns.get_domain_records()
print('Current records:', records)
"
```

### API å“åº”ç¼“æ…¢

**ç—‡çŠ¶**ï¼šAPI è¯·æ±‚å“åº”æ—¶é—´è¿‡é•¿

**è¯Šæ–­æ­¥éª¤**ï¼š

```bash
# æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½
uptime
top

# æ£€æŸ¥æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½
docker-compose exec postgres psql -U nas_admin -d nas_ddns -c "
SELECT query, mean_exec_time, calls 
FROM pg_stat_statements 
ORDER BY mean_exec_time DESC 
LIMIT 10;
"

# æ£€æŸ¥ Redis ç¼“å­˜å‘½ä¸­ç‡
docker-compose exec redis redis-cli INFO stats | grep keyspace

# æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ
ping -c 10 api.ipify.org

# æŸ¥çœ‹ API æ—¥å¿—ä¸­çš„æ…¢æŸ¥è¯¢
docker-compose logs api | grep "slow query"
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# 1. ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢
docker-compose exec postgres psql -U nas_admin -d nas_ddns -c "
CREATE INDEX IF NOT EXISTS idx_ddns_records_created_at 
ON ddns_records(created_at);
CREATE INDEX IF NOT EXISTS idx_ddns_records_domain 
ON ddns_records(domain);
"

# 2. æ¸…ç† Redis ç¼“å­˜
docker-compose exec redis redis-cli FLUSHALL

# 3. å¢åŠ ç¼“å­˜æ—¶é—´
# ç¼–è¾‘ .env æ–‡ä»¶
REDIS_CACHE_TTL=3600

# 4. å¯ç”¨æŸ¥è¯¢ç¼“å­˜
# ç¼–è¾‘ config/config.py
SQLALCHEMY_CACHE_ENABLED=True

# 5. ä¼˜åŒ–æ•°æ®åº“è¿æ¥æ± 
# ç¼–è¾‘ docker-compose.yml
environment:
  - SQLALCHEMY_POOL_SIZE=20
  - SQLALCHEMY_MAX_OVERFLOW=10
  - SQLALCHEMY_POOL_TIMEOUT=30
```

### å†…å­˜ä¸è¶³

**ç—‡çŠ¶**ï¼šå®¹å™¨å› å†…å­˜ä¸è¶³è¢«ç»ˆæ­¢

**è¯Šæ–­æ­¥éª¤**ï¼š

```bash
# æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ
free -h
docker stats --no-stream

# æŸ¥çœ‹å®¹å™¨å†…å­˜é™åˆ¶
docker inspect api | grep -i memory

# æ£€æŸ¥å†…å­˜æ³„æ¼
docker-compose exec api python -c "
import tracemalloc
tracemalloc.start()
# è¿è¡Œåº”ç”¨ç¨‹åº
snapshot = tracemalloc.take_snapshot()
top_stats = snapshot.statistics('lineno')
for stat in top_stats[:10]:
    print(stat)
"

# æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—
dmesg | grep -i "out of memory"
journalctl -xe | grep -i "killed process"
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# 1. å¢åŠ å†…å­˜é™åˆ¶
# ç¼–è¾‘ docker-compose.yml
services:
  api:
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

  postgres:
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  redis:
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

# 2. ä¼˜åŒ– Redis å†…å­˜ä½¿ç”¨
docker-compose exec redis redis-cli CONFIG SET maxmemory 512mb
docker-compose exec redis redis-cli CONFIG SET maxmemory-policy allkeys-lru

# 3. æ¸…ç† Docker èµ„æº
docker system prune -a --volumes

# 4. ä¼˜åŒ–æ•°æ®åº“ç¼“å­˜
docker-compose exec postgres psql -U nas_admin -d nas_ddns -c "
ALTER SYSTEM SET shared_buffers = '512MB';
ALTER SYSTEM SET effective_cache_size = '2GB';
ALTER SYSTEM SET work_mem = '16MB';
SELECT pg_reload_conf();
"

# 5. é‡å¯æœåŠ¡
docker-compose restart
```

### æƒé™é”™è¯¯

**ç—‡çŠ¶**ï¼šæ–‡ä»¶è®¿é—®æˆ–æ“ä½œæƒé™è¢«æ‹’ç»

**è¯Šæ–­æ­¥éª¤**ï¼š

```bash
# æ£€æŸ¥æ–‡ä»¶æƒé™
ls -la
ls -la data/

# æ£€æŸ¥ç”¨æˆ·ç»„
groups
id

# æŸ¥çœ‹å®¹å™¨ç”¨æˆ·
docker-compose exec api whoami
docker-compose exec postgres whoami

# æ£€æŸ¥ SELinux çŠ¶æ€ï¼ˆå¦‚æœä½¿ç”¨ï¼‰
getenforce
sestatus
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# 1. ä¿®å¤æ–‡ä»¶æƒé™
sudo chown -R $USER:$USER data/
sudo chmod -R 755 data/

# 2. æ·»åŠ ç”¨æˆ·åˆ° docker ç»„
sudo usermod -aG docker $USER
newgrp docker

# 3. ä¿®å¤ Docker å·æƒé™
docker-compose down
sudo chown -R $USER:$USER /var/lib/docker/volumes/
docker-compose up -d

# 4. ç¦ç”¨ SELinuxï¼ˆä¸´æ—¶ï¼‰
sudo setenforce 0

# 5. é…ç½® SELinux ä¸Šä¸‹æ–‡ï¼ˆæ°¸ä¹…ï¼‰
sudo semanage fcontext -a -t container_file_t "/path/to/data(/.*)?"
sudo restorecon -Rv /path/to/data
```

### æ—¥å¿—æ–‡ä»¶è¿‡å¤§

**ç—‡çŠ¶**ï¼šç£ç›˜ç©ºé—´è¢«æ—¥å¿—æ–‡ä»¶å ç”¨

**è¯Šæ–­æ­¥éª¤**ï¼š

```bash
# æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶å¤§å°
du -sh /var/lib/docker/containers/*/*-json.log
docker-compose logs --tail=0 api

# æŸ¥çœ‹ç£ç›˜ä½¿ç”¨æƒ…å†µ
df -h
du -sh ./*

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—é…ç½®
docker inspect api | grep -i log
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# 1. é…ç½®æ—¥å¿—è½®è½¬
# ç¼–è¾‘ /etc/docker/daemon.json
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3"
  }
}

# 2. é‡å¯ Docker æœåŠ¡
sudo systemctl restart docker

# 3. æ¸…ç†æ—§æ—¥å¿—
docker-compose logs --tail=0 api
docker system prune -a

# 4. æ‰‹åŠ¨æ¸…ç†æ—¥å¿—æ–‡ä»¶
sudo truncate -s 0 /var/lib/docker/containers/*/*-json.log

# 5. é…ç½®åº”ç”¨æ—¥å¿—çº§åˆ«
# ç¼–è¾‘ .env æ–‡ä»¶
LOG_LEVEL=warning
```

---

## ğŸ“š API ä½¿ç”¨ç¤ºä¾‹

### è®¤è¯æµç¨‹

#### 1. è·å–è®¿é—®ä»¤ç‰Œ

```bash
# ä½¿ç”¨ç®¡ç†å‘˜è´¦å·ç™»å½•
curl -X POST http://localhost:8080/api/v2/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "username": "admin",
    "password": "your_password"
  }'
```

**å“åº”ç¤ºä¾‹**ï¼š

```json
{
  "success": true,
  "data": {
    "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
    "refresh_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
    "token_type": "Bearer",
    "expires_in": 3600
  }
}
```

#### 2. ä½¿ç”¨ä»¤ç‰Œè®¿é—® API

```bash
# åœ¨è¯·æ±‚å¤´ä¸­åŒ…å«ä»¤ç‰Œ
curl -X GET http://localhost:8080/api/v2/ddns/status \
  -H "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."
```

#### 3. åˆ·æ–°ä»¤ç‰Œ

```bash
# ä½¿ç”¨åˆ·æ–°ä»¤ç‰Œè·å–æ–°çš„è®¿é—®ä»¤ç‰Œ
curl -X POST http://localhost:8080/api/v2/auth/refresh \
  -H "Content-Type: application/json" \
  -d '{
    "refresh_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."
  }'
```

### DDNS ç®¡ç†

#### 1. è·å– DDNS çŠ¶æ€

```bash
curl -X GET http://localhost:8080/api/v2/ddns/status \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN"
```

**å“åº”ç¤ºä¾‹**ï¼š

```json
{
  "success": true,
  "data": {
    "current_ip": "123.45.67.89",
    "domain": "ddns.example.com",
    "last_update": "2025-01-30T12:00:00Z",
    "status": "active",
    "ttl": 600
  }
}
```

#### 2. æ‰‹åŠ¨æ›´æ–° DDNS

```bash
curl -X POST http://localhost:8080/api/v2/ddns/update \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "force": true
  }'
```

**å“åº”ç¤ºä¾‹**ï¼š

```json
{
  "success": true,
  "data": {
    "old_ip": "123.45.67.89",
    "new_ip": "123.45.67.90",
    "updated_at": "2025-01-30T12:05:00Z",
    "message": "DDNS record updated successfully"
  }
}
```

#### 3. è·å–æ›´æ–°å†å²

```bash
curl -X GET "http://localhost:8080/api/v2/ddns/history?page=1&per_page=10" \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN"
```

**å“åº”ç¤ºä¾‹**ï¼š

```json
{
  "success": true,
  "data": {
    "total": 100,
    "page": 1,
    "per_page": 10,
    "records": [
      {
        "id": 1,
        "ip": "123.45.67.90",
        "updated_at": "2025-01-30T12:05:00Z",
        "status": "success"
      }
    ]
  }
}
```

### åŸŸåç®¡ç†

#### 1. è·å–æ‰€æœ‰åŸŸå

```bash
curl -X GET http://localhost:8080/api/v2/domains \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN"
```

#### 2. æ·»åŠ æ–°åŸŸå

```bash
curl -X POST http://localhost:8080/api/v2/domains \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "domain": "example.com",
    "sub_domain": "ddns",
    "record_type": "A",
    "ttl": 600
  }'
```

#### 3. æ›´æ–°åŸŸåé…ç½®

```bash
curl -X PUT http://localhost:8080/api/v2/domains/1 \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "ttl": 300
  }'
```

#### 4. åˆ é™¤åŸŸå

```bash
curl -X DELETE http://localhost:8080/api/v2/domains/1 \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN"
```

### ç›‘æ§ä¸ç»Ÿè®¡

#### 1. è·å–ç³»ç»Ÿç›‘æ§æ•°æ®

```bash
curl -X GET http://localhost:8080/api/v2/monitoring/system \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN"
```

**å“åº”ç¤ºä¾‹**ï¼š

```json
{
  "success": true,
  "data": {
    "cpu_usage": 25.5,
    "memory_usage": 45.2,
    "disk_usage": 60.8,
    "network_in": 1024.5,
    "network_out": 512.3,
    "uptime": 86400
  }
}
```

#### 2. è·å– API ç»Ÿè®¡

```bash
curl -X GET http://localhost:8080/api/v2/monitoring/api \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN"
```

**å“åº”ç¤ºä¾‹**ï¼š

```json
{
  "success": true,
  "data": {
    "total_requests": 10000,
    "successful_requests": 9800,
    "failed_requests": 200,
    "avg_response_time": 150.5,
    "requests_per_minute": 50
  }
}
```

#### 3. è·å– DDNS ç»Ÿè®¡

```bash
curl -X GET http://localhost:8080/api/v2/monitoring/ddns \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN"
```

**å“åº”ç¤ºä¾‹**ï¼š

```json
{
  "success": true,
  "data": {
    "total_updates": 500,
    "successful_updates": 495,
    "failed_updates": 5,
    "last_update": "2025-01-30T12:05:00Z",
    "avg_update_time": 2.5
  }
}
```

### ç”¨æˆ·ç®¡ç†

#### 1. è·å–ç”¨æˆ·åˆ—è¡¨

```bash
curl -X GET http://localhost:8080/api/v2/users \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN"
```

#### 2. åˆ›å»ºç”¨æˆ·

```bash
curl -X POST http://localhost:8080/api/v2/users \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "username": "newuser",
    "email": "newuser@example.com",
    "password": "secure_password",
    "role": "user"
  }'
```

#### 3. æ›´æ–°ç”¨æˆ·

```bash
curl -X PUT http://localhost:8080/api/v2/users/2 \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "email": "updated@example.com"
  }'
```

#### 4. åˆ é™¤ç”¨æˆ·

```bash
curl -X DELETE http://localhost:8080/api/v2/users/2 \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN"
```

### é”™è¯¯å¤„ç†

æ‰€æœ‰ API é”™è¯¯å“åº”éƒ½éµå¾ªç»Ÿä¸€æ ¼å¼ï¼š

```json
{
  "success": false,
  "error": {
    "code": "ERROR_CODE",
    "message": "é”™è¯¯æè¿°ä¿¡æ¯",
    "details": {}
  }
}
```

**å¸¸è§é”™è¯¯ç **ï¼š

| é”™è¯¯ç  | è¯´æ˜ | HTTP çŠ¶æ€ç  |
|--------|------|-------------|
| `INVALID_TOKEN` | æ— æ•ˆçš„è®¿é—®ä»¤ç‰Œ | 401 |
| `EXPIRED_TOKEN` | ä»¤ç‰Œå·²è¿‡æœŸ | 401 |
| `INSUFFICIENT_PERMISSIONS` | æƒé™ä¸è¶³ | 403 |
| `RESOURCE_NOT_FOUND` | èµ„æºä¸å­˜åœ¨ | 404 |
| `VALIDATION_ERROR` | è¯·æ±‚å‚æ•°éªŒè¯å¤±è´¥ | 400 |
| `INTERNAL_SERVER_ERROR` | æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ | 500 |

### å¤šè¯­è¨€ç¤ºä¾‹

#### Python

```python
import requests

BASE_URL = "http://localhost:8080/api/v2"

# ç™»å½•è·å–ä»¤ç‰Œ
response = requests.post(f"{BASE_URL}/auth/login", json={
    "username": "admin",
    "password": "your_password"
})
token = response.json()["data"]["access_token"]

# ä½¿ç”¨ä»¤ç‰Œè®¿é—® API
headers = {"Authorization": f"Bearer {token}"}

# è·å– DDNS çŠ¶æ€
response = requests.get(f"{BASE_URL}/ddns/status", headers=headers)
print(response.json())

# æ‰‹åŠ¨æ›´æ–° DDNS
response = requests.post(f"{BASE_URL}/ddns/update", 
                        headers=headers, 
                        json={"force": True})
print(response.json())
```

#### JavaScript

```javascript
const BASE_URL = "http://localhost:8080/api/v2";

// ç™»å½•è·å–ä»¤ç‰Œ
async function login() {
  const response = await fetch(`${BASE_URL}/auth/login`, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      username: "admin",
      password: "your_password"
    })
  });
  const data = await response.json();
  return data.data.access_token;
}

// ä½¿ç”¨ä»¤ç‰Œè®¿é—® API
async function getDDNSStatus(token) {
  const response = await fetch(`${BASE_URL}/ddns/status`, {
    headers: { "Authorization": `Bearer ${token}` }
  });
  return await response.json();
}

// æ‰‹åŠ¨æ›´æ–° DDNS
async function updateDDNS(token) {
  const response = await fetch(`${BASE_URL}/ddns/update`, {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${token}`,
      "Content-Type": "application/json"
    },
    body: JSON.stringify({ force: true })
  });
  return await response.json();
}

// ä½¿ç”¨ç¤ºä¾‹
(async () => {
  const token = await login();
  const status = await getDDNSStatus(token);
  console.log(status);
  
  const update = await updateDDNS(token);
  console.log(update);
})();
```

#### Go

```go
package main

import (
    "bytes"
    "encoding/json"
    "fmt"
    "net/http"
)

const BASE_URL = "http://localhost:8080/api/v2"

type LoginRequest struct {
    Username string `json:"username"`
    Password string `json:"password"`
}

type LoginResponse struct {
    Success bool `json:"success"`
    Data    struct {
        AccessToken string `json:"access_token"`
    } `json:"data"`
}

func login() (string, error) {
    reqBody, _ := json.Marshal(LoginRequest{
        Username: "admin",
        Password: "your_password",
    })
    
    resp, err := http.Post(
        BASE_URL+"/auth/login",
        "application/json",
        bytes.NewBuffer(reqBody),
    )
    if err != nil {
        return "", err
    }
    defer resp.Body.Close()
    
    var result LoginResponse
    json.NewDecoder(resp.Body).Decode(&result)
    return result.Data.AccessToken, nil
}

func getDDNSStatus(token string) {
    req, _ := http.NewRequest("GET", BASE_URL+"/ddns/status", nil)
    req.Header.Set("Authorization", "Bearer "+token)
    
    client := &http.Client{}
    resp, err := client.Do(req)
    if err != nil {
        fmt.Println("Error:", err)
        return
    }
    defer resp.Body.Close()
    
    var result map[string]interface{}
    json.NewDecoder(resp.Body).Decode(&result)
    fmt.Println(result)
}

func main() {
    token, err := login()
    if err != nil {
        fmt.Println("Login failed:", err)
        return
    }
    
    getDDNSStatus(token)
}
```

---

## ğŸš€ ç”Ÿäº§éƒ¨ç½²å»ºè®®

### éƒ¨ç½²æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ç”Ÿäº§ç¯å¢ƒæ¶æ„                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   ç”¨æˆ·      â”‚â”€â”€â”€â–¶â”‚   Nginx     â”‚â”€â”€â”€â–¶â”‚  API æœåŠ¡   â”‚      â”‚
â”‚  â”‚             â”‚    â”‚  (åå‘ä»£ç†)  â”‚    â”‚  (Flask)    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                            â”‚                  â”‚              â”‚
â”‚                            â”‚                  â”‚              â”‚
â”‚                            â–¼                  â–¼              â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚                     â”‚   é™æ€æ–‡ä»¶   â”‚    â”‚ PostgreSQL  â”‚      â”‚
â”‚                     â”‚   (CDN)     â”‚    â”‚   (ä¸»åº“)    â”‚      â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                              â”‚              â”‚
â”‚                                              â”‚              â”‚
â”‚                                              â–¼              â”‚
â”‚                                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚                                       â”‚ PostgreSQL  â”‚      â”‚
â”‚                                       â”‚   (ä»åº“)    â”‚      â”‚
â”‚                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                              â”‚              â”‚
â”‚                                              â”‚              â”‚
â”‚                                              â–¼              â”‚
â”‚                                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚                                       â”‚   Redis     â”‚      â”‚
â”‚                                       â”‚   (ç¼“å­˜)    â”‚      â”‚
â”‚                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                              â”‚              â”‚
â”‚                                              â”‚              â”‚
â”‚                                              â–¼              â”‚
â”‚                                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚                                       â”‚ Prometheus  â”‚      â”‚
â”‚                                       â”‚   + Grafana â”‚      â”‚
â”‚                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ç¯å¢ƒé…ç½®

#### ç”Ÿäº§ç¯å¢ƒå˜é‡

```bash
# .env.production

# ========================================
# è¿è¡Œç¯å¢ƒ
# ========================================
ENVIRONMENT=production
DEBUG=false
LOG_LEVEL=warning

# ========================================
# API é…ç½®
# ========================================
API_PORT=8080
WORKERS=4
THREADS=2

# ========================================
# æ•°æ®åº“é…ç½®
# ========================================
POSTGRES_DB=nas_ddns
POSTGRES_USER=nas_admin
POSTGRES_PASSWORD=<strong_password>
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_POOL_SIZE=20
POSTGRES_MAX_OVERFLOW=10

# ========================================
# Redis é…ç½®
# ========================================
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=<strong_password>
REDIS_DB=0
REDIS_MAX_CONNECTIONS=50

# ========================================
# å®‰å…¨é…ç½®
# ========================================
JWT_SECRET_KEY=<very_long_secret_key_min_32_chars>
JWT_ACCESS_TOKEN_EXPIRES=3600
JWT_REFRESH_TOKEN_EXPIRES=2592000
API_RATE_LIMIT=100
CORS_ORIGINS=https://yourdomain.com

# ========================================
# SSL/TLS é…ç½®
# ========================================
SSL_ENABLED=true
SSL_CERT_PATH=/etc/ssl/certs/your_domain.crt
SSL_KEY_PATH=/etc/ssl/private/your_domain.key

# ========================================
# ç›‘æ§é…ç½®
# ========================================
GRAFANA_ADMIN_PASSWORD=<strong_password>
PROMETHEUS_RETENTION=15d
GRAFANA_PORT=3000
PROMETHEUS_PORT=9090

# ========================================
# å‘Šè­¦é…ç½®
# ========================================
ALERT_EMAIL_ENABLED=true
ALERT_EMAIL_SMTP_HOST=smtp.gmail.com
ALERT_EMAIL_SMTP_PORT=587
ALERT_EMAIL_USERNAME=your_email@gmail.com
ALERT_EMAIL_PASSWORD=<email_password>
ALERT_EMAIL_FROM=noreply@yourdomain.com
ALERT_EMAIL_TO=admin@yourdomain.com

# ========================================
# å¤‡ä»½é…ç½®
# ========================================
BACKUP_ENABLED=true
BACKUP_SCHEDULE="0 2 * * *"
BACKUP_RETENTION_DAYS=7
BACKUP_S3_BUCKET=your-backup-bucket
```

### Nginx é…ç½®

```nginx
# /etc/nginx/sites-available/nas-ddns-api

upstream api_backend {
    least_conn;
    server api:8080 max_fails=3 fail_timeout=30s;
    keepalive 32;
}

# HTTP é‡å®šå‘åˆ° HTTPS
server {
    listen 80;
    listen [::]:80;
    server_name ddns.yourdomain.com;

    # Let's Encrypt éªŒè¯
    location /.well-known/acme-challenge/ {
        root /var/www/certbot;
    }

    location / {
        return 301 https://$server_name$request_uri;
    }
}

# HTTPS é…ç½®
server {
    listen 443 ssl http2;
    listen [::]:443 ssl http2;
    server_name ddns.yourdomain.com;

    # SSL è¯ä¹¦
    ssl_certificate /etc/letsencrypt/live/ddns.yourdomain.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/ddns.yourdomain.com/privkey.pem;

    # SSL å®‰å…¨é…ç½®
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384';
    ssl_prefer_server_ciphers off;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;
    ssl_stapling on;
    ssl_stapling_verify on;

    # å®‰å…¨å¤´
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Referrer-Policy "strict-origin-when-cross-origin" always;

    # æ—¥å¿—
    access_log /var/log/nginx/api_access.log;
    error_log /var/log/nginx/api_error.log;

    # å®¢æˆ·ç«¯ä¸Šä¼ å¤§å°é™åˆ¶
    client_max_body_size 10M;

    # è¶…æ—¶é…ç½®
    proxy_connect_timeout 60s;
    proxy_send_timeout 60s;
    proxy_read_timeout 60s;

    # API ä»£ç†
    location / {
        proxy_pass http://api_backend;
        proxy_http_version 1.1;
        
        # ä»£ç†å¤´
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_set_header X-Forwarded-Host $host;
        proxy_set_header X-Forwarded-Port $server_port;
        
        # WebSocket æ”¯æŒ
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        
        # ç¼“å†²é…ç½®
        proxy_buffering on;
        proxy_buffer_size 4k;
        proxy_buffers 8 4k;
        proxy_busy_buffers_size 8k;
        
        # ç¦ç”¨ç¼“å­˜
        add_header Cache-Control "no-cache, no-store, must-revalidate";
    }

    # é™æ€æ–‡ä»¶
    location /static {
        alias /var/www/static;
        expires 30d;
        add_header Cache-Control "public, immutable";
        access_log off;
    }

    # å¥åº·æ£€æŸ¥
    location /health {
        proxy_pass http://api_backend/api/v2/health;
        access_log off;
    }

    # ç›‘æ§ç«¯ç‚¹ï¼ˆä»…å†…ç½‘è®¿é—®ï¼‰
    location /metrics {
        allow 127.0.0.1;
        allow 10.0.0.0/8;
        deny all;
        proxy_pass http://api_backend/metrics;
    }
}
```

### Docker Compose ç”Ÿäº§é…ç½®

```yaml
# docker-compose.prod.yml

version: '3.8'

services:
  api:
    image: nas-ddns-api:latest
    container_name: nas-ddns-api
    restart: unless-stopped
    environment:
      - ENVIRONMENT=production
      - DEBUG=false
      - LOG_LEVEL=warning
    env_file:
      - .env.production
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - nas-network
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/v2/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  postgres:
    image: postgres:15-alpine
    container_name: nas-ddns-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - nas-network
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  redis:
    image: redis:7-alpine
    container_name: nas-ddns-redis
    restart: unless-stopped
    command: redis-server --requirepass ${REDIS_PASSWORD} --maxmemory 512mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    networks:
      - nas-network
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  prometheus:
    image: prom/prometheus:latest
    container_name: nas-ddns-prometheus
    restart: unless-stopped
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'
    networks:
      - nas-network
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  grafana:
    image: grafana/grafana:latest
    container_name: nas-ddns-grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./config/grafana/provisioning:/etc/grafana/provisioning
    networks:
      - nas-network
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  nginx:
    image: nginx:alpine
    container_name: nas-ddns-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./config/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./config/nginx/sites-available:/etc/nginx/sites-available:ro
      - ./certbot/conf:/etc/letsencrypt:ro
      - ./certbot/www:/var/www/certbot:ro
    depends_on:
      - api
    networks:
      - nas-network
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  certbot:
    image: certbot/certbot:latest
    container_name: nas-ddns-certbot
    volumes:
      - ./certbot/conf:/etc/letsencrypt
      - ./certbot/www:/var/www/certbot
    entrypoint: "/bin/sh -c 'trap exit TERM; while :; do certbot renew; sleep 12h & wait $${!}; done;'"
    networks:
      - nas-network

networks:
  nas-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
```

### éƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash

# deploy-production.sh

set -e

echo "ğŸš€ å¼€å§‹éƒ¨ç½²ç”Ÿäº§ç¯å¢ƒ..."

# 1. æ£€æŸ¥ç¯å¢ƒå˜é‡
if [ ! -f .env.production ]; then
    echo "âŒ é”™è¯¯: .env.production æ–‡ä»¶ä¸å­˜åœ¨"
    exit 1
fi

# 2. æ‹‰å–æœ€æ–°é•œåƒ
echo "ğŸ“¥ æ‹‰å–æœ€æ–°é•œåƒ..."
docker-compose -f docker-compose.prod.yml pull

# 3. å¤‡ä»½æ•°æ®åº“
echo "ğŸ’¾ å¤‡ä»½æ•°æ®åº“..."
docker-compose exec postgres pg_dump -U nas_admin nas_ddns > backup_$(date +%Y%m%d_%H%M%S).sql

# 4. åœæ­¢æ—§æœåŠ¡
echo "ğŸ›‘ åœæ­¢æ—§æœåŠ¡..."
docker-compose -f docker-compose.prod.yml down

# 5. å¯åŠ¨æ–°æœåŠ¡
echo "â–¶ï¸  å¯åŠ¨æ–°æœåŠ¡..."
docker-compose -f docker-compose.prod.yml up -d

# 6. ç­‰å¾…æœåŠ¡å°±ç»ª
echo "â³ ç­‰å¾…æœåŠ¡å°±ç»ª..."
sleep 30

# 7. è¿è¡Œæ•°æ®åº“è¿ç§»
echo "ğŸ”„ è¿è¡Œæ•°æ®åº“è¿ç§»..."
docker-compose exec api flask db upgrade

# 8. å¥åº·æ£€æŸ¥
echo "ğŸ¥ æ‰§è¡Œå¥åº·æ£€æŸ¥..."
for i in {1..10}; do
    if curl -f http://localhost:8080/api/v2/health; then
        echo "âœ… å¥åº·æ£€æŸ¥é€šè¿‡"
        break
    fi
    echo "â³ ç­‰å¾…æœåŠ¡å¯åŠ¨... ($i/10)"
    sleep 5
done

# 9. æ¸…ç†æ—§é•œåƒ
echo "ğŸ§¹ æ¸…ç†æ—§é•œåƒ..."
docker image prune -f

echo "âœ… éƒ¨ç½²å®Œæˆï¼"
```

### å¤‡ä»½ç­–ç•¥

#### è‡ªåŠ¨å¤‡ä»½è„šæœ¬

```bash
#!/bin/bash

# backup.sh

set -e

BACKUP_DIR="/backup"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=7

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

# å¤‡ä»½æ•°æ®åº“
echo "ğŸ“¦ å¤‡ä»½æ•°æ®åº“..."
docker-compose exec -T postgres pg_dump -U nas_admin nas_ddns > $BACKUP_DIR/db_backup_$DATE.sql

# å¤‡ä»½é…ç½®æ–‡ä»¶
echo "ğŸ“„ å¤‡ä»½é…ç½®æ–‡ä»¶..."
tar -czf $BACKUP_DIR/config_backup_$DATE.tar.gz .env docker-compose.yml

# å¤‡ä»½ Redis æ•°æ®
echo "ğŸ—„ï¸  å¤‡ä»½ Redis æ•°æ®..."
docker-compose exec redis redis-cli --rdb /data/dump.rdb
docker cp nas-ddns-redis:/data/dump.rdb $BACKUP_DIR/redis_backup_$DATE.rdb

# ä¸Šä¼ åˆ° S3ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
if [ ! -z "$BACKUP_S3_BUCKET" ]; then
    echo "â˜ï¸  ä¸Šä¼ åˆ° S3..."
    aws s3 cp $BACKUP_DIR/db_backup_$DATE.sql s3://$BACKUP_S3_BUCKET/
    aws s3 cp $BACKUP_DIR/config_backup_$DATE.tar.gz s3://$BACKUP_S3_BUCKET/
    aws s3 cp $BACKUP_DIR/redis_backup_$DATE.rdb s3://$BACKUP_S3_BUCKET/
fi

# æ¸…ç†æ—§å¤‡ä»½
echo "ğŸ§¹ æ¸…ç†æ—§å¤‡ä»½..."
find $BACKUP_DIR -name "db_backup_*.sql" -mtime +$RETENTION_DAYS -delete
find $BACKUP_DIR -name "config_backup_*.tar.gz" -mtime +$RETENTION_DAYS -delete
find $BACKUP_DIR -name "redis_backup_*.rdb" -mtime +$RETENTION_DAYS -delete

echo "âœ… å¤‡ä»½å®Œæˆï¼"
```

#### å®šæ—¶ä»»åŠ¡é…ç½®

```bash
# æ·»åŠ åˆ° crontab
crontab -e

# æ¯å¤©å‡Œæ™¨ 2 ç‚¹æ‰§è¡Œå¤‡ä»½
0 2 * * * /path/to/backup.sh >> /var/log/backup.log 2>&1
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### æ•°æ®åº“ä¼˜åŒ–

#### 1. ç´¢å¼•ä¼˜åŒ–

```sql
-- åˆ›å»ºå¿…è¦çš„ç´¢å¼•
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_ddns_records_domain 
ON ddns_records(domain);

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_ddns_records_created_at 
ON ddns_records(created_at DESC);

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_ddns_records_status 
ON ddns_records(status);

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_users_email 
ON users(email);

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_api_logs_timestamp 
ON api_logs(timestamp DESC);

-- åˆ†ææŸ¥è¯¢æ€§èƒ½
EXPLAIN ANALYZE SELECT * FROM ddns_records 
WHERE domain = 'ddns.example.com' 
ORDER BY created_at DESC 
LIMIT 10;
```

#### 2. æŸ¥è¯¢ä¼˜åŒ–

```sql
-- ä½¿ç”¨è¿æ¥æ± 
ALTER SYSTEM SET max_connections = 200;
ALTER SYSTEM SET shared_buffers = '512MB';
ALTER SYSTEM SET effective_cache_size = '2GB';
ALTER SYSTEM SET work_mem = '16MB';
ALTER SYSTEM SET maintenance_work_mem = '128MB';
ALTER SYSTEM SET random_page_cost = 1.1;
ALTER SYSTEM SET effective_io_concurrency = 200;

-- å¯ç”¨æŸ¥è¯¢ç¼“å­˜
ALTER SYSTEM SET shared_preload_libraries = 'pg_stat_statements';

-- é‡æ–°åŠ è½½é…ç½®
SELECT pg_reload_conf();
```

#### 3. å®šæœŸç»´æŠ¤

```sql
-- å®šæœŸæ¸…ç†æ—§æ•°æ®
DELETE FROM ddns_records 
WHERE created_at < NOW() - INTERVAL '90 days';

DELETE FROM api_logs 
WHERE timestamp < NOW() - INTERVAL '30 days';

-- å®šæœŸæ¸…ç†æ­»å…ƒç»„
VACUUM ANALYZE ddns_records;
VACUUM ANALYZE api_logs;

-- é‡å»ºç´¢å¼•
REINDEX TABLE ddns_records;
REINDEX TABLE api_logs;

-- æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
ANALYZE ddns_records;
ANALYZE api_logs;
```

### Redis ä¼˜åŒ–

#### 1. å†…å­˜ä¼˜åŒ–

```bash
# é…ç½®æœ€å¤§å†…å­˜
docker-compose exec redis redis-cli CONFIG SET maxmemory 512mb

# è®¾ç½®å†…å­˜æ·˜æ±°ç­–ç•¥
docker-compose exec redis redis-cli CONFIG SET maxmemory-policy allkeys-lru

# æŸ¥çœ‹å†…å­˜ä½¿ç”¨
docker-compose exec redis redis-cli INFO memory
```

#### 2. è¿æ¥ä¼˜åŒ–

```bash
# é…ç½®æœ€å¤§è¿æ¥æ•°
docker-compose exec redis redis-cli CONFIG SET maxclients 10000

# é…ç½®è¶…æ—¶æ—¶é—´
docker-compose exec redis redis-cli CONFIG SET timeout 300

# æŸ¥çœ‹è¿æ¥ä¿¡æ¯
docker-compose exec redis redis-cli INFO clients
```

#### 3. æŒä¹…åŒ–ä¼˜åŒ–

```bash
# å¯ç”¨ RDB æŒä¹…åŒ–
docker-compose exec redis redis-cli CONFIG SET save "900 1 300 10 60 10000"

# é…ç½® RDB æ–‡ä»¶å
docker-compose exec redis redis-cli CONFIG SET dbfilename dump.rdb

# å¯ç”¨ AOF æŒä¹…åŒ–
docker-compose exec redis redis-cli CONFIG SET appendonly yes

# é…ç½® AOF åˆ·ç›˜ç­–ç•¥
docker-compose exec redis redis-cli CONFIG SET appendfsync everysec
```

### API ä¼˜åŒ–

#### 1. å¯ç”¨ç¼“å­˜

```python
# config/config.py

# Redis ç¼“å­˜é…ç½®
REDIS_CACHE_ENABLED = True
REDIS_CACHE_TTL = 3600  # 1å°æ—¶
REDIS_CACHE_KEY_PREFIX = "nas_ddns:"

# å¯ç”¨æŸ¥è¯¢ç¼“å­˜
SQLALCHEMY_CACHE_ENABLED = True
SQLALCHEMY_CACHE_TTL = 300  # 5åˆ†é’Ÿ
```

#### 2. è¿æ¥æ± ä¼˜åŒ–

```python
# config/config.py

# æ•°æ®åº“è¿æ¥æ± 
SQLALCHEMY_POOL_SIZE = 20
SQLALCHEMY_MAX_OVERFLOW = 10
SQLALCHEMY_POOL_TIMEOUT = 30
SQLALCHEMY_POOL_RECYCLE = 3600

# Redis è¿æ¥æ± 
REDIS_POOL_SIZE = 50
REDIS_SOCKET_TIMEOUT = 5
REDIS_SOCKET_CONNECT_TIMEOUT = 5
```

#### 3. å¼‚æ­¥å¤„ç†

```python
# ä½¿ç”¨ Celery å¤„ç†å¼‚æ­¥ä»»åŠ¡
from celery import Celery

celery = Celery('nas_ddns', 
                broker='redis://redis:6379/0',
                backend='redis://redis:6379/0')

@celery.task
def update_ddns_async():
    """å¼‚æ­¥æ›´æ–° DDNS"""
    from app.utils.aliyun import AliyunDDNS
    ddns = AliyunDDNS()
    return ddns.update_ddns()

# è°ƒç”¨å¼‚æ­¥ä»»åŠ¡
update_ddns_async.delay()
```

### Nginx ä¼˜åŒ–

```nginx
# å¯ç”¨ gzip å‹ç¼©
gzip on;
gzip_vary on;
gzip_min_length 1024;
gzip_types text/plain text/css text/xml text/javascript 
           application/json application/javascript application/xml+rss 
           application/rss+xml font/truetype font/opentype 
           application/vnd.ms-fontobject image/svg+xml;

# å¯ç”¨ç¼“å­˜
proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=api_cache:10m 
                 max_size=1g inactive=60m use_temp_path=off;

# ç¼“å­˜é…ç½®
proxy_cache api_cache;
proxy_cache_valid 200 302 10m;
proxy_cache_valid 404 1m;
proxy_cache_bypass $http_cache_control;
add_header X-Cache-Status $upstream_cache_status;

# è¿æ¥ä¼˜åŒ–
keepalive_timeout 65;
keepalive_requests 100;
client_body_timeout 12;
client_header_timeout 12;
send_timeout 10;
```

### ç›‘æ§ä¼˜åŒ–

#### Prometheus é…ç½®

```yaml
# config/prometheus.yml

global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'nas-ddns-production'
    environment: 'production'

scrape_configs:
  - job_name: 'api'
    static_configs:
      - targets: ['api:8080']
    metrics_path: '/metrics'
    scrape_interval: 10s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']
    scrape_interval: 30s

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    scrape_interval: 30s

  - job_name: 'node'
    static_configs:
      - targets: ['node-exporter:9100']
    scrape_interval: 15s
```

#### å‘Šè­¦è§„åˆ™

```yaml
# config/prometheus/alerts.yml

groups:
  - name: api_alerts
    interval: 30s
    rules:
      - alert: HighErrorRate
        expr: rate(api_errors_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "API é”™è¯¯ç‡è¿‡é«˜"
          description: "API é”™è¯¯ç‡è¶…è¿‡ 10% (å½“å‰å€¼: {{ $value }})"

      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(api_response_time_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "API å“åº”æ—¶é—´è¿‡é•¿"
          description: "API 95% å“åº”æ—¶é—´è¶…è¿‡ 1ç§’ (å½“å‰å€¼: {{ $value }}s)"

      - alert: DatabaseConnectionPoolExhausted
        expr: postgres_connections_active / postgres_connections_max > 0.8
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "æ•°æ®åº“è¿æ¥æ± è€—å°½"
          description: "æ•°æ®åº“è¿æ¥ä½¿ç”¨ç‡è¶…è¿‡ 80% (å½“å‰å€¼: {{ $value }})"

      - alert: RedisMemoryHigh
        expr: redis_memory_used_bytes / redis_memory_max_bytes > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Redis å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "Redis å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡ 80% (å½“å‰å€¼: {{ $value }})"
```

---

## ğŸ”’ å®‰å…¨é…ç½®

### è®¤è¯ä¸æˆæƒ

#### 1. JWT é…ç½®

```python
# config/config.py

import jwt
from datetime import datetime, timedelta

JWT_SECRET_KEY = os.getenv('JWT_SECRET_KEY')
JWT_ALGORITHM = 'HS256'
JWT_ACCESS_TOKEN_EXPIRES = timedelta(hours=1)
JWT_REFRESH_TOKEN_EXPIRES = timedelta(days=30)

def generate_access_token(user_id):
    """ç”Ÿæˆè®¿é—®ä»¤ç‰Œ"""
    payload = {
        'user_id': user_id,
        'exp': datetime.utcnow() + JWT_ACCESS_TOKEN_EXPIRES,
        'iat': datetime.utcnow(),
        'type': 'access'
    }
    return jwt.encode(payload, JWT_SECRET_KEY, algorithm=JWT_ALGORITHM)

def generate_refresh_token(user_id):
    """ç”Ÿæˆåˆ·æ–°ä»¤ç‰Œ"""
    payload = {
        'user_id': user_id,
        'exp': datetime.utcnow() + JWT_REFRESH_TOKEN_EXPIRES,
        'iat': datetime.utcnow(),
        'type': 'refresh'
    }
    return jwt.encode(payload, JWT_SECRET_KEY, algorithm=JWT_ALGORITHM)
```

#### 2. æƒé™æ§åˆ¶

```python
# decorators/auth.py

from functools import wraps
from flask import request, jsonify
import jwt

def require_auth(f):
    """éœ€è¦è®¤è¯çš„è£…é¥°å™¨"""
    @wraps(f)
    def decorated(*args, **kwargs):
        token = request.headers.get('Authorization')
        
        if not token:
            return jsonify({'success': False, 'error': 'Missing token'}), 401
        
        try:
            token = token.replace('Bearer ', '')
            payload = jwt.decode(token, JWT_SECRET_KEY, algorithms=[JWT_ALGORITHM])
            request.user_id = payload['user_id']
        except jwt.ExpiredSignatureError:
            return jsonify({'success': False, 'error': 'Token expired'}), 401
        except jwt.InvalidTokenError:
            return jsonify({'success': False, 'error': 'Invalid token'}), 401
        
        return f(*args, **kwargs)
    return decorated

def require_admin(f):
    """éœ€è¦ç®¡ç†å‘˜æƒé™çš„è£…é¥°å™¨"""
    @wraps(f)
    def decorated(*args, **kwargs):
        token = request.headers.get('Authorization')
        
        if not token:
            return jsonify({'success': False, 'error': 'Missing token'}), 401
        
        try:
            token = token.replace('Bearer ', '')
            payload = jwt.decode(token, JWT_SECRET_KEY, algorithms=[JWT_ALGORITHM])
            
            if payload.get('role') != 'admin':
                return jsonify({'success': False, 'error': 'Insufficient permissions'}), 403
            
            request.user_id = payload['user_id']
        except jwt.ExpiredSignatureError:
            return jsonify({'success': False, 'error': 'Token expired'}), 401
        except jwt.InvalidTokenError:
            return jsonify({'success': False, 'error': 'Invalid token'}), 401
        
        return f(*args, **kwargs)
    return decorated
```

### æ•°æ®ä¿æŠ¤

#### 1. å¯†ç åŠ å¯†

```python
# utils/security.py

import bcrypt
import secrets

def hash_password(password: str) -> str:
    """åŠ å¯†å¯†ç """
    salt = bcrypt.gensalt()
    return bcrypt.hashpw(password.encode('utf-8'), salt).decode('utf-8')

def verify_password(password: str, hashed_password: str) -> bool:
    """éªŒè¯å¯†ç """
    return bcrypt.checkpw(
        password.encode('utf-8'),
        hashed_password.encode('utf-8')
    )

def generate_api_key() -> str:
    """ç”Ÿæˆ API å¯†é’¥"""
    return secrets.token_urlsafe(32)
```

#### 2. æ•æ„Ÿæ•°æ®åŠ å¯†

```python
# utils/encryption.py

from cryptography.fernet import Fernet
import os

class DataEncryption:
    def __init__(self):
        self.key = os.getenv('ENCRYPTION_KEY')
        self.cipher = Fernet(self.key)
    
    def encrypt(self, data: str) -> str:
        """åŠ å¯†æ•°æ®"""
        return self.cipher.encrypt(data.encode()).decode()
    
    def decrypt(self, encrypted_data: str) -> str:
        """è§£å¯†æ•°æ®"""
        return self.cipher.decrypt(encrypted_data.encode()).decode()
```

### è¾“å…¥éªŒè¯

```python
# utils/validation.py

from marshmallow import Schema, fields, validate, ValidationError

class DDNSUpdateSchema(Schema):
    """DDNS æ›´æ–°éªŒè¯"""
    domain = fields.Str(required=True, validate=validate.Length(min=1, max=255))
    sub_domain = fields.Str(required=True, validate=validate.Length(min=1, max=255))
    record_type = fields.Str(required=True, validate=validate.OneOf(['A', 'AAAA', 'CNAME']))
    ttl = fields.Int(required=True, validate=validate.Range(min=60, max=86400))

class UserCreateSchema(Schema):
    """ç”¨æˆ·åˆ›å»ºéªŒè¯"""
    username = fields.Str(required=True, validate=validate.Length(min=3, max=50))
    email = fields.Email(required=True)
    password = fields.Str(required=True, validate=validate.Length(min=8, max=128))
    role = fields.Str(required=True, validate=validate.OneOf(['user', 'admin']))

def validate_request(schema_class):
    """è¯·æ±‚éªŒè¯è£…é¥°å™¨"""
    def decorator(f):
        @wraps(f)
        def decorated(*args, **kwargs):
            try:
                schema = schema_class()
                data = schema.load(request.json)
                return f(data, *args, **kwargs)
            except ValidationError as err:
                return jsonify({
                    'success': False,
                    'error': 'Validation failed',
                    'details': err.messages
                }), 400
        return decorated
    return decorator
```

### é€Ÿç‡é™åˆ¶

```python
# utils/rate_limit.py

from flask import request, jsonify
from functools import wraps
import redis
import time

redis_client = redis.Redis(host='redis', port=6379, db=0)

def rate_limit(max_requests=100, window=60):
    """é€Ÿç‡é™åˆ¶è£…é¥°å™¨"""
    def decorator(f):
        @wraps(f)
        def decorated(*args, **kwargs):
            # è·å–å®¢æˆ·ç«¯ IP
            client_ip = request.remote_addr
            
            # ç”Ÿæˆ Redis é”®
            key = f"rate_limit:{client_ip}:{f.__name__}"
            
            # æ£€æŸ¥è¯·æ±‚æ¬¡æ•°
            current = redis_client.get(key)
            
            if current is None:
                redis_client.setex(key, window, 1)
            else:
                current = int(current)
                if current >= max_requests:
                    return jsonify({
                        'success': False,
                        'error': 'Rate limit exceeded'
                    }), 429
                redis_client.incr(key)
            
            return f(*args, **kwargs)
        return decorated
    return decorator
```

### CORS é…ç½®

```python
# config/cors.py

from flask_cors import CORS

def init_cors(app):
    """åˆå§‹åŒ– CORS"""
    allowed_origins = os.getenv('CORS_ORIGINS', '*').split(',')
    
    CORS(app,
         resources={
             r"/api/*": {
                 "origins": allowed_origins,
                 "methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
                 "allow_headers": ["Content-Type", "Authorization"],
                 "max_age": 3600
             }
         })
```

### å®‰å…¨å¤´

```python
# middleware/security.py

from flask import after_this_request

def add_security_headers(response):
    """æ·»åŠ å®‰å…¨å¤´"""
    response.headers['X-Content-Type-Options'] = 'nosniff'
    response.headers['X-Frame-Options'] = 'SAMEORIGIN'
    response.headers['X-XSS-Protection'] = '1; mode=block'
    response.headers['Strict-Transport-Security'] = 'max-age=31536000; includeSubDomains'
    response.headers['Content-Security-Policy'] = "default-src 'self'"
    response.headers['Referrer-Policy'] = 'strict-origin-when-cross-origin'
    return response
```

---

## ğŸ“– ä¸‹ä¸€æ­¥

### å­¦ä¹ èµ„æº

- [Flask å®˜æ–¹æ–‡æ¡£](https://flask.palletsprojects.com/)
- [Docker å®˜æ–¹æ–‡æ¡£](https://docs.docker.com/)
- [PostgreSQL å®˜æ–¹æ–‡æ¡£](https://www.postgresql.org/docs/)
- [Redis å®˜æ–¹æ–‡æ¡£](https://redis.io/docs/)
- [Prometheus å®˜æ–¹æ–‡æ¡£](https://prometheus.io/docs/)
- [Grafana å®˜æ–¹æ–‡æ¡£](https://grafana.com/docs/)

### è¿›é˜¶åŠŸèƒ½

- [ ] å®ç°å¤šåŸŸå DDNS æ”¯æŒ
- [ ] æ·»åŠ  WebSocket å®æ—¶é€šçŸ¥
- [ ] é›†æˆç¬¬ä¸‰æ–¹ DNS æœåŠ¡å•†
- [ ] å®ç° API ç½‘å…³
- [ ] æ·»åŠ æœºå™¨å­¦ä¹ é¢„æµ‹
- [ ] å®ç°è‡ªåŠ¨åŒ–æµ‹è¯•
- [ ] æ·»åŠ  CI/CD æµæ°´çº¿
- [ ] å®ç°ç°åº¦å‘å¸ƒ

### ç¤¾åŒºè´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜æˆ–æå‡ºå»ºè®®ï¼

- [GitHub Issues](https://github.com/YYC3/nas-ddns-api/issues)
- [Pull Requests](https://github.com/YYC3/nas-ddns-api/pulls)
- [Discussions](https://github.com/YYC3/nas-ddns-api/discussions)

---

## ğŸ’¬ è·å–å¸®åŠ©

### æ–‡æ¡£èµ„æº

- [ä¸» README](README.md) - é¡¹ç›®æ¦‚è¿°å’ŒåŠŸèƒ½ä»‹ç»
- [API æ–‡æ¡£](http://localhost:8080/api/v2/docs) - Swagger API æ–‡æ¡£
- [æ¶æ„æ–‡æ¡£](../docs/ARCHITECTURE.md) - ç³»ç»Ÿæ¶æ„è®¾è®¡
- [éƒ¨ç½²æ–‡æ¡£](../docs/DEPLOYMENT.md) - éƒ¨ç½²æŒ‡å—
- [å¼€å‘æ–‡æ¡£](../docs/DEVELOPMENT.md) - å¼€å‘æŒ‡å—

### æŠ€æœ¯æ”¯æŒ

- **é‚®ç®±**: admin@0379.email
- **GitHub Issues**: https://github.com/YYC3/nas-ddns-api/issues
- **Discussions**: https://github.com/YYC3/nas-ddns-api/discussions

### å¸¸è§é—®é¢˜

#### Q: å¦‚ä½•é‡ç½®ç®¡ç†å‘˜å¯†ç ï¼Ÿ

```bash
# è¿›å…¥æ•°æ®åº“å®¹å™¨
docker-compose exec postgres psql -U nas_admin -d nas_ddns

# é‡ç½®å¯†ç 
UPDATE users SET password_hash = '$2b$12$...' WHERE username = 'admin';
```

#### Q: å¦‚ä½•è¿ç§»æ•°æ®åˆ°æ–°æœåŠ¡å™¨ï¼Ÿ

```bash
# å¤‡ä»½æ—§æœåŠ¡å™¨æ•°æ®
docker-compose exec postgres pg_dump -U nas_admin nas_ddns > backup.sql

# åœ¨æ–°æœåŠ¡å™¨æ¢å¤
docker-compose exec -T postgres psql -U nas_admin -d nas_ddns < backup.sql
```

#### Q: å¦‚ä½•å‡çº§åˆ°æ–°ç‰ˆæœ¬ï¼Ÿ

```bash
# æ‹‰å–æœ€æ–°é•œåƒ
docker-compose pull

# è¿è¡Œæ•°æ®åº“è¿ç§»
docker-compose exec api flask db upgrade

# é‡å¯æœåŠ¡
docker-compose up -d
```

### åé¦ˆä¸å»ºè®®

æˆ‘ä»¬éå¸¸é‡è§†æ‚¨çš„åé¦ˆï¼å¦‚æœæ‚¨æœ‰ä»»ä½•å»ºè®®æˆ–å‘ç°é—®é¢˜ï¼Œè¯·ï¼š

1. æŸ¥çœ‹ [GitHub Issues](https://github.com/YYC3/nas-ddns-api/issues) ç¡®è®¤æ˜¯å¦å·²è¢«æŠ¥å‘Š
2. å¦‚æœæ²¡æœ‰ï¼Œåˆ›å»ºæ–°çš„ Issueï¼Œè¯¦ç»†æè¿°é—®é¢˜
3. å¦‚æœæ‚¨æœ‰è§£å†³æ–¹æ¡ˆï¼Œæ¬¢è¿æäº¤ Pull Request

---

<div align="center">

## ğŸ‰ æ„Ÿè°¢ä½¿ç”¨ YYCÂ³ NAS DDNS APIï¼

**è¨€å¯è±¡é™ | è¯­æ¢æœªæ¥**
**ä¸‡è±¡å½’å…ƒäºäº‘æ¢ | æ·±æ ˆæ™ºå¯æ–°çºªå…ƒ**

[![YYCÂ³](https://img.shields.io/badge/YYCÂ³-äº”é«˜äº”æ ‡äº”åŒ–-blue)](https://github.com/YYC3)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Support](https://img.shields.io/badge/support-active-brightgreen.svg)](https://github.com/YYC3/issues)

**Â© 2025 YYCÂ³ Team. All rights reserved.**

</div>
curl -X POST http://localhost:8080/api/v2/ddns/manual-update

# 3. æ£€æŸ¥ç½‘ç»œè¿æ¥
docker-compose exec api ping -c 3 api.aliyun.com

# 4. æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯
docker-compose logs api | grep -i error

# 5. æµ‹è¯• DNS è§£æ
dig ddns.your_domain.com
```

### API å“åº”ç¼“æ…¢

**ç—‡çŠ¶**ï¼šAPI å“åº”æ—¶é—´è¿‡é•¿æˆ–è¶…æ—¶

**è¯Šæ–­æ­¥éª¤**ï¼š

```bash
# æµ‹è¯• API å“åº”æ—¶é—´
time curl http://localhost:8080/api/v2/health

# æŸ¥çœ‹ç³»ç»Ÿèµ„æºä½¿ç”¨
docker stats

# æ£€æŸ¥æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½
docker-compose exec postgres psql -U nas_admin -d nas_ddns -c "SELECT * FROM pg_stat_activity;"

# æŸ¥çœ‹ Redis ç¼“å­˜å‘½ä¸­ç‡
docker-compose exec redis redis-cli INFO stats | grep keyspace

# åˆ†ææ…¢æŸ¥è¯¢æ—¥å¿—
docker-compose logs postgres | grep "duration:"
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# 1. å¢åŠ  API worker æ•°é‡
docker-compose exec api env | grep WORKERS

# 2. æ¸…ç† Redis ç¼“å­˜
docker-compose exec redis redis-cli FLUSHALL

# 3. ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢
docker-compose exec postgres psql -U nas_admin -d nas_ddns -c "VACUUM ANALYZE;"

# 4. é‡å¯æœåŠ¡
docker-compose restart api

# 5. æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ
docker-compose exec api ping -c 10 postgres
docker-compose exec api ping -c 10 redis
```

### å†…å­˜ä¸è¶³

**ç—‡çŠ¶**ï¼šå®¹å™¨å› å†…å­˜ä¸è¶³è¢«æ€æ­»

**è¯Šæ–­æ­¥éª¤**ï¼š

```bash
# æŸ¥çœ‹å®¹å™¨å†…å­˜ä½¿ç”¨
docker stats --no-stream

# æ£€æŸ¥ç³»ç»Ÿå†…å­˜
free -h

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker-compose logs api | grep "out of memory"

# æ£€æŸ¥ OOM Killer æ—¥å¿—
dmesg | grep -i "killed process"
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# 1. å¢åŠ å®¹å™¨å†…å­˜é™åˆ¶
# ç¼–è¾‘ docker-compose.ymlï¼Œå¢åŠ  memory é™åˆ¶

# 2. æ¸…ç†æœªä½¿ç”¨çš„ Docker èµ„æº
docker system prune -a

# 3. é‡å¯æœåŠ¡
docker-compose restart

# 4. ä¼˜åŒ–åº”ç”¨å†…å­˜ä½¿ç”¨
# å‡å°‘ç¼“å­˜å¤§å°ã€ä¼˜åŒ–æ•°æ®åº“è¿æ¥æ± ç­‰

# 5. å¢åŠ ç³»ç»Ÿäº¤æ¢ç©ºé—´
sudo fallocate -l 2G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

---

## ğŸ“¡ API ä½¿ç”¨ç¤ºä¾‹

### è·å– DDNS çŠ¶æ€

```bash
curl http://localhost:8080/api/v2/ddns/status
```

### åˆ—å‡º DNS è®°å½•

```bash
curl http://localhost:8080/api/v2/ddns/records
```

### æŸ¥çœ‹ç³»ç»Ÿç›‘æ§

```bash
curl http://localhost:8080/api/v2/monitoring/system
```

### æŸ¥çœ‹å‘Šè­¦

```bash
curl http://localhost:8080/api/v2/alerts
```

### æ‰‹åŠ¨è§¦å‘ DDNS æ›´æ–°

```bash
curl -X POST http://localhost:8080/api/v2/ddns/manual-update
```

## ç”Ÿäº§éƒ¨ç½²å»ºè®®

### 1. å®‰å…¨é…ç½®

- ä¿®æ”¹æ‰€æœ‰é»˜è®¤å¯†ç 
- ä½¿ç”¨å¼º JWT å¯†é’¥å’Œ API å¯†é’¥
- é…ç½®é˜²ç«å¢™è§„åˆ™
- å¯ç”¨ HTTPS
- é™åˆ¶ API è®¿é—®

### 2. æ€§èƒ½ä¼˜åŒ–

- è°ƒæ•´æ•°æ®åº“è¿æ¥æ± å¤§å°
- å¯ç”¨ Redis ç¼“å­˜
- é…ç½®é€‚å½“çš„ Gunicorn worker æ•°é‡
- å¯ç”¨ CDNï¼ˆå¦‚æœé€‚ç”¨ï¼‰

### 3. ç›‘æ§å‘Šè­¦

- é…ç½® Prometheus å‘Šè­¦è§„åˆ™
- è®¾ç½® Grafana ä»ªè¡¨æ¿
- é…ç½®é‚®ä»¶/Telegram é€šçŸ¥
- å®šæœŸæ£€æŸ¥å¤‡ä»½

### 4. é«˜å¯ç”¨

- é…ç½®è´Ÿè½½å‡è¡¡
- è®¾ç½®æ•°æ®åº“ä¸»ä»å¤åˆ¶
- é…ç½®å¤šå®ä¾‹éƒ¨ç½²
- å®æ–½ç¾éš¾æ¢å¤è®¡åˆ’

## ä¸‹ä¸€æ­¥

1. é…ç½®åŸŸåå’Œ SSL è¯ä¹¦
2. è®¾ç½®å®šæ—¶å¤‡ä»½
3. é…ç½®ç›‘æ§å‘Šè­¦
4. é›†æˆ CI/CD
5. ç¼–å†™è‡ªåŠ¨åŒ–æµ‹è¯•

## è·å–å¸®åŠ©

- æŸ¥çœ‹å®Œæ•´æ–‡æ¡£ï¼š`README.md`
- æäº¤é—®é¢˜ï¼šGitHub Issues
- æŸ¥çœ‹æ—¥å¿—ï¼š`docker-compose logs -f`
